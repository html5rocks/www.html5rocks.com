{% extends "tutorial.html" %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
.videostream, #cssfilters-stream {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
#screenshot-stream {
  width: initial;
  height: initial;
}
#screenshot {
  vertical-align: top;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1)
  -o-filter: invert(1)
  -ms-filter: invert(1)
  filter: invert(1)
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="この記事は HTML5 Audio/Video を利用しています。" title="この記事は HTML5 Audio/Video を利用しています"  />
{% endblock %}

{% block content %}

<p>{% include "warning.html" %}</p>
<h2 id="toc-into">はじめに</h2>

<p>長い間、Audio/Video capture はウェブ開発にとって<em></em>「到達困難な目標」でした。何年にもわたり、ジョブを実行するにはブラウザ プラグイン（<a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> または <a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a>）を使用する必要がありました。<a href="http://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">勘弁してもらいたい!</a></p>
<p>これを救うのが HTML5 です。目立たないかもしれませんが、HTML5 の登場によってデバイス ハードウェアへのアクセスが急増しました。<a href="/tutorials/geolocation/trip_meter/">Geolocation</a>（GPS）、<a href="/tutorials/device/orientation/">Orientation API</a>（加速度メーター）、<a href="/tutorials/webgl/shaders/">WebGL</a>（GPU）、<a href="/tutorials/webaudio/intro/">Web Audio API</a>（自動車ハードウェア）がわかりやすい例です。これらの機能は驚くほど強力で、システムの基盤になるハードウェア機能の上に置かれる高水準の JavaScript API が公開されています。</p>
<p>このチュートリアルでは、新しい API である <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html"><code>navigator.getUserMedia()</code></a> を紹介します。この API を使用すると、ウェブ アプリケーションでユーザーのカメラとマイクにアクセスできます。</p>
<h2 id="toc-history">getUserMedia() への道</h2>

<p>歴史をご存じない方のために言っておくと、<code>getUserMedia()</code> API には興味深い物語があります。</p>
<p>この数年の間に、「Media Capture API」のいくつかの変形が生まれました。多くの人が、ウェブ上のネイティブ デバイスにアクセスできる機能の必要性を認識していました。それは、さまざまな考えを合わせて 1 つの新しい仕様を作る動きになりました。そこで事態が混乱したため、W3C は最終的に作業グループを設けました。その唯一の目的は、混乱を収拾することです。<a href="http://www.w3.org/2009/dap/">Device API ポリシー（DAP）作業グループ</a>が、大量の提案の統合と標準化を行ってきました。</p>
<p>2011 年に何が行われたかを要約してみます。</p>
<h3 id="toc-round1">ラウンド 1: HTML Media Capture</h3>

<p><a href="http://dev.w3.org/2009/dap/camera/">HTML Media Capture</a> は、ウェブ上のメディア キャプチャ標準化に関する DAP の最初の正式認定でした。この API は <code>&lt;input type="file"&gt;</code> をオーバーロードし、<code>accept</code> パラメータに新しい値を追加することで機能します。</p>
<p>ユーザーがウェブカメラで自分のスナップショットを撮影できるようにする場合は、<code>capture=camera</code> によって可能です。</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>動画または音声の記録も同様です。</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>これはいいですね。特に、ファイル入力を使用するところがいいと思います。セマンティックの面でもかなり意味があります。この特定の「API」に足りない点は、リアルタイムの効果です（たとえば、ライブ ウェブカム データを <code>&lt;canvas&gt;</code> に表示し、WebGL フィルタを適用する）。HTML Media Capture では、時間に合ったメディア ファイルの記録またはスナップショットの取得のみが可能です。</p>
<p><strong>サポート:</strong></p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Android 3.0 ブラウザ</a> - 最初の実装の 1 つ。実際の動作を確認するには、<a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">この動画</a>をご覧ください。</li>
<li>Chrome for Android（0.16）</li>
</ul>
<p>HTML Media Capture は、上記のモバイル ブラウザのいずれかを対象にしているのでない限り、使用を避けることをおすすめします。ベンダーは <code>getUserMedia()</code> に移行しつつあります。長期的に見て、他の方が HTML Media Capture を実装する見込みはないと考えられます。</p>
<h3 id="toc-round2">ラウンド 2: device 要素</h3>

<p>多くのユーザーは、HTML Media Capture は制限が多すぎると感じました。そこで、あらゆる種類の（将来の）デバイスをサポートする新しい仕様が登場しました。予想どおり、その設計では新しい要素が要求されていました。それは <code>getUserMedia()</code> の後継となる <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code> という要素</a>です。</p>
<p>Opera は、<code>&lt;device&gt;</code> に基づくビデオ キャプチャの<a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">初期の実装</a>を作成した最初のブラウザの 1 つです。そのすぐ後（正確には<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">同じ日</a>）に、WhatWG は <code>&lt;device&gt;</code> タグを捨て去り、別の有望なタグを優先することを決定しました。今度は <code>navigator.getUserMedia()</code> と呼ばれる JavaScript API です。1 週間後、Opera は、更新された <code>getUserMedia()</code> 仕様に対応した新しいビルドを公開しました。その年の後半、Microsoft は新しい仕様をサポートした <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">Lab for IE9</a> をリリースして仲間に加わりました。</p>
<p><code>&lt;device&gt;</code> は次のようになっていたはずです。</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>サポート:</strong></p>
<p>残念ながら、これまでリリースされたブラウザの中に <code>&lt;device&gt;</code> を組み込んだものはありません。これで悩まされる API が 1 つ減ったというものです。しかしながら、<code>&lt;device&gt;</code> には確かによいところが 2 つありました。1.）意味がわかるように作られていたこと、2.）音声/動画デバイス以外もサポートするように簡単に拡張できたことです。</p>
<p>一息つきましょう。変化が速すぎます。</p>
<h3 id="toc-round3">ラウンド 3: WebRTC</h3>

<p><code>&lt;device&gt;</code> 要素は最終的に絶滅の道をたどりました。</p>
<p><a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html">WebRTC</a>（Web Real Time Communications）と呼ばれる大規模な取り組みのおかげで、適切なキャプチャ API を探すペースは、最近の数か月で加速しました。仕様は <a href="http://www.w3.org/2011/04/webrtc/">W3C WebRTC 作業グループ</a>によって監督されています。現在、Google、Opera、Mozilla、<a href="http://webrtc.org">その他いくつかのブラウザ</a>が実装の作業中です。</p>
<p><code>getUserMedia()</code> は WebRTC に関係しています。WebRTC が一連の API への入り口であるためです。WebRTC はユーザーのローカル カメラ/マイク ストリームにアクセスする手段を提供します。</p>
<p><strong>サポート:</strong></p>
<p>WebRTC は、Chrome 18.0.1008 以降で <code>about:flags</code> によって有効化することができます。</p>
<h2 id="toc-gettingstarted">いよいよ始動</h2>

<p><code>navigator.getUserMedia()</code> では、最終的にウェブカメラとマイクの入力をプラグインなしで扱えるようになりました。カメラへのアクセスは、インストールではなく呼び出しによって実現可能になりました。ブラウザに直接書き込まれます。すばらしいことではないでしょうか。</p>
<h3 id="toc-enabling">有効化</h3>

<p><code>getUserMedia()</code> API は、まだ非常に新しく、デベロッパー ビルドにこの API を組み込んでいるのは Google と Opera のみです。Chrome 18 以降では、この API は <code>about:flags</code> にアクセスして有効化できます。</p>
<p><figure>
<img src="aboutflags.png">
<figcaption>Chrome の <code>about:flags</code> ページでの <code>getUserMedia()</code> の有効化</figcaption>
</figure></p>
<p>Opera の場合、実験的な <a href="http://dev.opera.com/articles/view/labs-more-fun-using-the-web-with-getusermedia-and-native-pages/">Android 用ビルドとデスクトップ用ビルド</a>のいずれかをダウンロードすることができます。</p>
<h3 id="toc-featuredecting">機能検出</h3>

<p>機能検出は、<code>navigator.getUserMedia</code> が存在するかどうかの簡単なチェックです。</p>
<pre class="prettyprint"><code>function hasGetUserMedia() {
  // Note: Opera builds are unprefixed.
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
}

if (hasGetUserMedia()) {
  // Good to go!
} else {
  alert('getUserMedia() is not supported in your browser');
}
</code></pre>
<h3 id="toc-acccess">入力デバイスへのアクセス権の取得</h3>

<p>ウェブカメラやマイクを使用するには、アクセス許可を要求する必要があります。<code>getUserMedia()</code> の最初のパラメータでは、アクセスするメディアのタイプを指定します。たとえば、ウェブカメラを要求する場合、最初のパラメータは <code>"video"</code> になります。マイクとカメラの両方を使用するには、<code>"video, audio"</code> を指定します。</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var onFailSoHard = function(e) {
    console.log('Reeeejected!', e);
  };

  // Not showing vendor prefixes.
  navigator.getUserMedia('video, audio', function(localMediaStream) {
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(localMediaStream);

    // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
    // See crbug.com/110938.
    video.onloadedmetadata = function(e) {
      // Ready to go. Do some stuff.
    };
  }, onFailSoHard);
&lt;/script&gt;
</code></pre>
<p>先に進みましょう。何が起きているのでしょうか。メディア キャプチャは、新しい HTML5 API の連携動作の優れた例です。<code>&lt;audio&gt;</code> および <code>&lt;video&gt;</code> という他の HTML5 タグと連携して動作します。<code>&lt;video&gt;</code> 要素に <code>src</code> 属性を設定したり <code>&lt;source&gt;</code> 要素を指定するのではないことに注意してください。メディア ファイルへの URL に動画をフィードするのではなく、ウェブカメラを表す <code>LocalMediaStream</code> オブジェクトから取得した <a href="/tutorials/workers/basics/#toc-inlineworkers-bloburis">Blob URL</a> にフィードします。</p>
<p>また、<code>&lt;video&gt;</code> に <code>autoplay</code> を指示します。これを指示しないと、最初のフレームでフリーズします。<code>controls</code> を追加しても、期待どおりに動作します。</p>
<p class="notice" style="text-align:center">
<strong>注:</strong> Chrome にはバグがあり、「audio」のみを渡しても無効です（<a href="http://crbug.com/112367">crbug.com/112367</a>）。Opera でも <code>&lt;audio&gt;</code> を動作させることはできませんでした。
</p>

<p>Opera と Chrome のどちらも、実装している<a href="getusermedia-spec">仕様</a>のバージョンが異なります。このため、実際の使い方は少し難しくなります。</p>
<p><strong>Chrome の場合:</strong></p>
<p>このスニペットは <span class="browser chrome supported" style="float:none;display:inline-block;"><span class="browser_name">Chrome</span></span> 18 以降（<code>about:flags</code> で有効化）で動作します。</p>
<pre class="prettyprint"><code>navigator.webkitGetUserMedia('audio, video', function(localMediaStream) {
  var video = document.querySelector('video');
  video.src = window.webkitURL.createObjectURL(localMediaStream);
}, onFailSoHard);
</code></pre>
<p><strong>Opera の場合:</strong></p>
<p>Opera デベロッパー ビルドは、更新されたバージョンの仕様に対して有効です。このスニペットは <span class="browser opera supported" style="float:none;display:inline-block;"><span class="browser_name">Opera</span></span> で動作します。</p>
<pre class="prettyprint"><code>navigator.getUserMedia({audio: true, video: true}, function(localMediaStream) {
  video.src = localMediaStream;
}, onFailSoHard);
</code></pre>
<p>主な相違点は次のとおりです。</p>
<ul>
<li><code>getUserMedia()</code> はプレフィックスなしです。</li>
<li>オブジェクトは文字列リストではなく第 1 引数として渡されます。</li>
<li><code>video.src</code> は、Blob URL ではなく <code>LocalMediaStream</code> オブジェクトに直接設定します。Opera はいずれこれを更新して、Blob URL が必須になるようです。</li>
</ul>
<p><strong>共通:</strong></p>
<p>ブラウザ間で動作する（ただし非常に不安定）機能が必要な場合は、以下を試してみてください。</p>
<pre class="prettyprint"><code>var video = document.querySelector('video');

if (navigator.getUserMedia) {
  navigator.getUserMedia({audio: true, video: true}, function(stream) {
    video.src = stream;
  }, onFailSoHard);
} else if (navigator.webkitGetUserMedia) {
  navigator.webkitGetUserMedia('audio, video', function(stream) {
    video.src = window.webkitURL.createObjectURL(stream);
  }, onFailSoHard);
} else {
  video.src = 'somevideo.webm'; // fallback.
}
</code></pre>
<p><a href="http://twitter.com/miketaylr">Mike Taylor</a> と <a href="http://twitter.com/akamike">Mike Robinson</a> の <a href="https://gist.github com/f2ac64ed7fc467ccdfe3">gUM Shield</a> を確認してください。ブラウザ実装間の不統一をうまく「標準化」しています。</p>
<h3 id="toc-security">セキュリティ</h3>

<p>将来的には、ブラウザは <code>getUserMedia()</code> の呼び出し時点で情報バーを破棄する可能性があります。これにより、カメラやマイクへのアクセスを許可または拒否するオプションがユーザーに与えられます。セキュリティに関しては、残念ながらめぼしい仕様はありません。現時点で、アクセス許可バーは実装されていません。</p>
<h3 id="toc-fallback">フォールバックの提供</h3>

<p><code>getUserMedia()</code> をサポートしていないユーザーについて、1 つのオプションは、API がサポートされていない場合や呼び出しが何らかの理由で失敗する場合は、既存の動画ファイルにフォールバックすることです。</p>
<pre class="prettyprint"><code>// Not showing vendor prefixes or code that works cross-browser:

function fallback(e) {
  video.src = 'fallbackvideo.webm';
}

function success(stream) {
  video.src = window.URL.createObjectURL(stream);
}

if (!navigator.getUserMedia) {
  fallback();
} else {
  navigator.getUserMedia({video: true}, success, fallback);
}
</code></pre>
<h3 id="toc-basic-demo">基本的なデモ</h3>

<div style="text-align:center;">
  <video id="basic-stream" class="videostream" autoplay></video>
  <p><button id="capture-button">動画のキャプチャ</button> <button id="stop-button">停止</button></p>
</div>

<h2 id="toc-screenshot">スクリーンショットの取得</h2>

<p><code>&lt;canvas&gt;</code> API の <code>ctx.drawImage(video, 0, 0)</code> メソッドにより、<code>&lt;canvas&gt;</code> への <code>&lt;video&gt;</code> フレームの描画が簡単に行えるようになりました。もちろん、<code>getUserMedia()</code> から動画入力を受け取るようになったことで、リアルタイムの動画を使って写真撮影ブースのようなアプリケーションを簡単に作成できます。</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

var video = document.querySelector('video');
var canvas = document.querySelector('canvas');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function snapshot() {
  if (localMediaStream) {
    ctx.drawImage(video, 0, 0);
    // "image/webp" works in Chrome 18. In other browsers, this will fall back to image/png.
    document.querySelector('img').src = canvas.toDataURL('image/webp');
  }
}

video.addEventListener('click', snapshot, false);

// Not showing vendor prefixes or code that works cross-browser.
navigator.getUserMedia({video: true}, function(stream) {
  video.src = window.URL.createObjectURL(stream);
  localMediaStream = stream;
}, onFailSoHard);
</code></pre>
<div style="text-align:center;">
  <video id="screenshot-stream" class="videostream" autoplay></video>
  <img id="screenshot" src="">
  <canvas id="screenshot-canvas" style="display:none;"></canvas>
  <p><button id="screenshot-button">キャプチャ</button> <button id="screenshot-stop-button">停止</button></p>
</div>

<h2 id="toc-effects">効果の適用</h2>

<h3 id="toc-effects-css">CSS フィルタ</h3>

<p class="notice" style="text-align:center">
CSS フィルタは、現在のところ WebKit ナイトリー ビルドと Chrome 18 以降でサポートされています。
</p>

<p><a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">CSS フィルタ</a>を使用して、キャプチャしながらすばらしい効果を <code>&lt;video&gt;</code> に適用できます。</p>
<pre class="prettyprint"><code>&lt;style&gt;
video {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.grayscale {
  {% mixin filter: grayscale(1); %}
}
.sepia {
  {% mixin filter: sepia(1); %}
}
.blur {
  {% mixin filter: blur(3px); %}
}
...
&lt;/style&gt;

&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
var idx = 0;
var filters = ['grayscale', 'sepia', 'blur', 'brightness', 'contrast', 'hue-rotate',
               'hue-rotate2', 'hue-rotate3', 'saturate', 'invert', ''];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length]; // loop through filters.
  if (effect) {
    el.classList.add(effect);
  }
}

document.querySelector('video').addEventListener('click', changeFilter, false);
&lt;/script&gt;
</code></pre>
<div style="text-align:center;">
  <video id="cssfilters-stream" class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p>動画をクリックすると、CSS フィルタが順に切り替わります</p>
  <p><button id="capture-button2">動画のキャプチャ</button> <button id="stop-button2">停止</button></p>
</div>

<h3 id="toc-effects-webgl">WebGL テクスチャ</h3>

<p>動画キャプチャの優れた使用例の 1 つは、ライブ入力を WebGL テクスチャとしてレンダリングすることです。WebGL については、私はまったく何も（すばらしいものだということ以外）知らないので、Jerome Etienne の <a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">チュートリアル</a>と<a href="http://learningthreejs.com/data/live-video-in-webgl/">デモ</a>をご覧になることをおすすめします。<code>getUserMedia()</code> と <a href="/tutorials/three/intro/">Three.js</a> を使用してライブ動画を WebGL にレンダリングする方法が示されています。</p>
<h2 id="toc-webaudio-api">Web Audio API と getUserMedia の使用</h2>

<p class="notice" style="text-align:center">
このセクションでは、現在の API に対して考えられる今後の改良と機能拡張について説明します。
</p>

<p>私の夢の 1 つは、オープンなウェブ テクノロジーだけを使ってブラウザで AutoTune を作成することです。実際、その実現はそう遠くありません。マイク入力用の <code>getUserMedia()</code> は既にできています。<a href="/tutorials/webaudio/intro/">Web Audio API</a> にリアルタイム効果のための多少の追加を行えば準備完了です。両者の統合には部品が足りません（<a href="http://crbug.com/112404">crbug.com/112404</a>）。ただし、統合を実現するための<a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html">暫定提案</a>が進行中です。</p>
<p>マイク入力を Web Audio API にパイプでつなぐ処理は、そのうち次のような形になる可能性があります。<em></em></p>
<pre class="prettyprint"><code>var context = new window.webkitAudioContext();

navigator.webkitGetUserMedia({audio: true}, function(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();

  // microphone -&gt; filter -&gt; destination.
  microphone.connect(filter);
  filter.connect(context.destination);
}, onFailSoHard);
</code></pre>
<p>Web Audio API に <code>getUserMedia()</code> を組み合わせる必要がある場合は、<a href="http://crbug.com/112404">crbug.com/112404</a> を確認してください。</p>
<h2 id="toc-conclusion">まとめ</h2>

<p>総じて、ウェブ上のデバイス アクセスは手ごわい問題でした。多くの人たちが<a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">トライ</a>しましたが、成功した人はほとんどいません。初期の考え方のほとんどは、それ独自の環境以外で支配的になることはなく、広い範囲で採用されることもありませんでした。</p>
<p>本当の問題は、ウェブのセキュリティ モデルがネイティブの世界とは大きく異なることです。<em></em>たとえば、誰ともわからぬ多くの人のウェブ サイトから自分のビデオ カメラにランダムにアクセスされるのはごめんこうむりたいものです。正しく処理することが難しい問題です。</p>
<p><a href="http://phonegap.com/">PhoneGap</a> のようなブリッジ フレームワークは境界を低くするのに役立ちましたが、基盤の問題に対する初期の一時的な解決策にすぎません。ウェブ アプリケーションをデスクトップ アプリケーションと競争できるようにするためには、ネイティブ デバイスにアクセスする必要があります。</p>
<p><code>getUserMedia()</code> は新しいタイプのデバイスへのアクセスに関する、まさに最初の波です。ごく近い将来に引き続き追加があることを期待します。</p>
<h2 id="toc-resources">その他のリソース</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">W3C 仕様</a></li>
<li>Bruce Lawson の <a href="http://html5doctor.com/getusermedia/">HTML5Doctor の記事</a></li>
<li>Bruce Lawson の <a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">dev.opera.com の記事</a></li>
</ul>
<h3 id="toc-demos">デモ</h3>

<ul>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">ライブ写真ブース</a></li>
<li><a href="http://people.opera.com/danield/webapps/instant-camera/">インスタント カメラ</a></li>
<li><a href="http://people.opera.com/danield/html5/explode/">発展する動画</a></li>
<li>Paul Neave の <a href="http://neave.com/webcam/html5/">WebGL カメラ効果</a></li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">WebGL でのライブの動画</a></li>
</ul>
<script>
function onFailSoHard(e) {
  alert('getUserMedia() not supported in your browser.');
  e.target.src = 'http://www.html5rocks.com/en/tutorials/video/basics/Chrome_ImF.ogv';
}

(function() {
var video = document.querySelector('#basic-stream');
var button = document.querySelector('#capture-button');
var localMediaStream = null;

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#screenshot-stream');
var button = document.querySelector('#screenshot-button');
var canvas = document.querySelector('#screenshot-canvas');
var img = document.querySelector('#screenshot');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function sizeCanvas() {
  // video.onloadedmetadata not firing in Chrome. See crbug.com/110938.
  setTimeout(function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    img.height = video.videoHeight;
    img.width = video.videoWidth;
  }, 50);
}

function snapshot() {
  ctx.drawImage(video, 0, 0);
  img.src = canvas.toDataURL('image/webp');
}

button.addEventListener('click', function(e) {
  if (localMediaStream) {
    snapshot();
    return;
  }

if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

video.addEventListener('click', snapshot, false);

document.querySelector('#screenshot-stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#cssfilters-stream');
var button = document.querySelector('#capture-button2');
var localMediaStream = null;

var idx = 0;
var filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate', 'hue-rotate2', 'hue-rotate3',
  'saturate',
  'invert',
  ''
];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length];
  if (effect) {
    el.classList.add(effect);
  }
}

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video, audio', function(stream) {
      video.src = stream;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button2').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);

video.addEventListener('click', changeFilter, false);
})();
</script>
{% endblock %}