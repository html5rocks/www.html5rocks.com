{% extends "tutorial.html" %}
{% load mixin from templatefilters %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
video, #cssfilters-video, #screenshot-img {
  width: 400px;
  height: 300px;
}
video, #cssfilters-stream {
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1);
  -o-filter: invert(1);
  -ms-filter: invert(1);
  filter: invert(1);
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="This article is powered by HTML5 Audio/Video" title="This article is powered by HTML5 Audio?/Video" />
{% endblock %}

{% block content %}

<h2 id="toc-into">Introduction</h2>

<p>Audio/Video capture has been <em>the</em> "Holy Grail" of web development for a long time.
For many years we had to rely on browser plugins (<a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> or
<a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a>)
to get the job done. <a href="https://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">Come on!</a></p>
<p>HTML5 to the rescue. It might not be apparent, but the rise of HTML5 has brought
a surge of access to device hardware. <a href="/tutorials/geolocation/trip_meter/">Geolocation</a> (GPS),
the <a href="/tutorials/device/orientation/">Orientation API</a> (accelerometer), <a href="/tutorials/webgl/shaders/">WebGL</a> (GPU),
and the <a href="/tutorials/webaudio/intro/">Web Audio API</a> (audio hardware) are perfect examples. These features
are ridiculously powerful, exposing high level JavaScript APIs that sit
on top of the system's underlying hardware capabilities.</p>
<p>This tutorial introduces <a href="https://www.w3.org/TR/mediacapture-streams/"><code>navigator.mediaDevices.getUserMedia()</code></a>, which allows
web apps to access a user's camera and microphone.</p>
<h2 id="toc-history">The road to getUserMedia()</h2>

<p>If you're not aware of its history, the way we arrived at the <code>getUserMedia()</code> API is an interesting tale.</p>
<p>Several variants of "Media Capture APIs" have evolved over the past few years.
Many folks recognized the need to be able to access native devices on the web, but
that led everyone and their mom to put together a new spec. Things got
so messy that the W3C finally decided to form a working group. Their sole purpose?
Make sense of the madness! The <a href="http://www.w3.org/2009/dap/">Device APIs Policy (DAP) Working Group</a>
has been tasked to consolidate + standardize the plethora of proposals.</p>
<p>I'll try to summarize what happened in 2011...</p>
<h3 id="toc-round1">Round 1: HTML Media Capture</h3>

<p><a href="http://dev.w3.org/2009/dap/camera/">HTML Media Capture</a> was the DAP's first go at
standardizing media capture on the web. It works by overloading the <code>&lt;input type="file"&gt;</code>
and adding new values for the <code>accept</code> parameter.</p>
<p>If you wanted to let users take a snapshot of themselves with the webcam,
that's possible with <code>capture=camera</code>:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>Recording a video or audio is similar:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>Kinda nice right? I particularly like that it reuses a file input. Semantically,
it makes a lot of sense. Where this particular "API" falls short is the ability to do realtime effects
(e.g. render live webcam data to a <code>&lt;canvas&gt;</code> and apply WebGL filters).
HTML Media Capture only allows you to record a media file or take a snapshot in time.</p>
<p><strong>Support:</strong></p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Android 3.0 browser</a> -
one of the first implementations. Check out <a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">this video</a> to see it in action.</li>
<li>Chrome for Android (0.16)</li>
<li>Firefox Mobile 10.0</li>
<li>iOS6 Safari and Chrome (partial support)</li>
</ul>
<h3 id="toc-round2">Round 2: device element</h3>

<p>Many thought HTML Media Capture was too limiting, so a new spec
emerged that supported any type of (future) device. Not surprisingly, the design called
for a new element, the <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code> element</a>,
which became the predecessor to <code>getUserMedia()</code>.</p>
<p>Opera was among the first browsers to create <a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">initial implementations</a>
of video capture based on the <code>&lt;device&gt;</code> element. Soon after
(<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">the same day</a> to be precise),
the WhatWG decided to scrap the <code>&lt;device&gt;</code> tag in favor of another up and comer, this time a JavaScript API called
<code>navigator.getUserMedia()</code>. A week later, Opera put out new builds that included
support for the updated <code>getUserMedia()</code> spec. Later that year,
Microsoft joined the party by releasing a <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">Lab for IE9</a>
supporting the new spec.</p>
<p>Here's what <code>&lt;device&gt;</code> would have looked like:</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>Support:</strong></p>
<p>Unfortunately, no released browser ever included <code>&lt;device&gt;</code>.
One less API to worry about I guess :) <code>&lt;device&gt;</code> did have two great things going
for it though: 1.) it was semantic, and 2.) it was easily extendible to support
more than just audio/video devices.</p>
<p>Take a breath. This stuff moves fast!</p>
<h3 id="toc-round3">Round 3: WebRTC</h3>

<p>The <code>&lt;device&gt;</code> element eventually went the way of the Dodo.</p>
<p>The pace to find a suitable capture API accelerated thanks to the larger <a href="https://www.w3.org/TR/webrtc/">WebRTC</a> (Web Real Time Communications) effort. That spec is overseen by the <a href="http://www.w3.org/2011/04/webrtc/">W3C WebRTC Working Group</a>. Google, Opera, Mozilla, and <a href="http://webrtc.org">a few others</a> have
implementations.</p>
<p><code>getUserMedia()</code> is related to WebRTC because it's the gateway into that set of APIs.
It provides the means to access the user's local camera/microphone stream.</p>

<p><strong>Support:</strong></p>
<p><code>getUserMedia()</code> has been available since Chrome 21, Opera 18, and Firefox 17. Support was initially provided by the <code>Navigator.getUserMedia()</code> method, but this <a href="https://developer.mozilla.org/en-US/docs/Web/API/Navigator/getUserMedia" title="Mozilla Developer Network documentation for Navigator.getUserMedia()">has been deprecated</a>.</p>
<p>You should now use the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia" title="Mozilla Developer Network documentation for MediaDevices.getUserMedia()"><code>navigator.MediaDevices.getUserMedia()</code></a> method, which is <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia#Browser_compatibility" title="MDN browser compatibility chart for MediaDevices.getUserMedia()">widely supported</a>.</p>

<h2 id="toc-gettingstarted">Getting started</h2>

<p>With <code>getUserMedia()</code>, we can finally tap into webcam and microphone input without a plugin.
Camera access is now a call away, not an install away. It's baked directly into the browser. Excited yet?</p>

<h3 id="toc-acccess">Gaining access to an input device</h3>

<p>To use the webcam or microphone, we need to request permission.
The parameter to <code>getUserMedia()</code> is an object specifying the details and
requirements for each type of media you want to access. For example, if you want to access the webcam, the parameter should be <code>{video: true}</code>. To use both the microphone and camera,
pass <code>{video: true, audio: true}</code>:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
const constraints = {
  video: true
};

const video = document.querySelector('video');

navigator.mediaDevices.getUserMedia(constraints).
  then((stream) => {video.srcObject = stream});
&lt;/script&gt;
</code></pre>
<p>OK. So what's going on here? Media capture is a perfect example of HTML5 APIs
working together. It works in conjunction with our other HTML5 buddies, <code>&lt;audio&gt;</code> and <code>&lt;video&gt;</code>.
Notice that we're not setting a <code>src</code> attribute or including <code>&lt;source&gt;</code> elements
on the <code>&lt;video&gt;</code> element. Instead of feeding the video the URL of a media file, we're giving it a <code>MediaStream</code> from the webcam.</p>
<p>I'm also telling the <code>&lt;video&gt;</code> to <code>autoplay</code>, otherwise it would be frozen on
the first frame. Adding <code>controls</code> also works as you'd expected.</p>

<h3 id="toc-constraints">Setting media constraints (resolution, height, width)</h3>

<p>The parameter to <code>getUserMedia()</code> can also be used to specify more requirements
(or constraints) on the returned media stream. For example, instead of just indicating you want basic access to video (e.g. <code>{video: true}</code>), you can additionally require the stream
to be HD:</p>
<pre class="prettyprint"><code>const hdConstraints = {
  video: {width: {min: 1280}, height: {min: 720}}
};

navigator.mediaDevices.getUserMedia(hdConstraints).
  then((stream) => {video.srcObject = stream}).
  catch((error) => {console.error('Reeeejected!', error)});

...

const vgaConstraints = {
  video: {width: {exact: 640}, height: {exact: 480}}
};

navigator.mediaDevices.getUserMedia(vgaConstraints).
  then((stream) => {video.srcObject = stream});
</code></pre>
<p>If the resolution isn't supported by the currently selected camera, <code>getUserMedia()</code>will be rejected with an <code>OverconstrainedError</code> and the user will not be prompted to grant permission to access their camera.</p>
<p>For more configurations, see the <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#idl-def-MediaTrackConstraints">constraints API</a></p>
<h3 id="toc-source">Selecting a media source</h3>

<p>The <code>navigator.mediaDevices.enumerateDevices()</code> method provides information about available input and output devices, and makes it possible to select a camera or microphone. (The <code>MediaStreamTrack.getSources()</code> API <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack#Browser_compatibility" title="Mozilla Developer network browser compatibility table for MediaStreamTrack.getSources()">has been deprecated</a>.)</p>

<p>This example enables the user to choose an audio and video source:</p>
<pre class="prettyprint"><code>const videoElement = document.querySelector('video');
const audioSelect = document.querySelector('select#audioSource');
const videoSelect = document.querySelector('select#videoSource');

navigator.mediaDevices.enumerateDevices()
  .then(gotDevices).then(getStream).catch(handleError);

audioSelect.onchange = getStream;
videoSelect.onchange = getStream;

function gotDevices(deviceInfos) {
  for (let i = 0; i !== deviceInfos.length; ++i) {
    const deviceInfo = deviceInfos[i];
    let option = document.createElement('option');
    option.value = deviceInfo.deviceId;
    if (deviceInfo.kind === 'audioinput') {
      option.text = deviceInfo.label ||
        'microphone ' + (audioSelect.length + 1);
      audioSelect.appendChild(option);
    } else if (deviceInfo.kind === 'videoinput') {
      option.text = deviceInfo.label || 'camera ' +
        (videoSelect.length + 1);
      videoSelect.appendChild(option);
    } else {
      console.log('Found another kind of device: ', deviceInfo);
    }
  }
}

function getStream() {
  if (window.stream) {
    window.stream.getTracks().forEach(function(track) {
      track.stop();
    });
  }

  const constraints = {
    audio: {
      deviceId: {exact: audioSelect.value}
    },
    video: {
      deviceId: {exact: videoSelect.value}
    }
  };

  navigator.mediaDevices.getUserMedia(constraints).
    then(gotStream).catch(handleError);
}

function gotStream(stream) {
  window.stream = stream; // make stream available to console
  videoElement.srcObject = stream;
}

function handleError(error) {
  console.error('Error: ', error);
}

</code></pre>
<p>Check out Sam Dutton's <a href="https://simpl.info/getusermedia/sources/">great demo</a> of how to let users select the media source.</p>

<h3 id="toc-security">Security</h3>

<p>All browsers throw up an infobar upon calling <code>getUserMedia()</code>,
which gives users the option to grant or deny access to their camera/mic.
The spec unfortunately is very quiet when it comes to security. For example, here
is Chrome's permission dialog:</p>
<figure>
<img src="permission.png" alt="Permission dialog in Chrome" title="Permission dialog in Chrome">
<figcaption>Permission dialog in Chrome</figcaption>
</figure>

<p>If your app is running from SSL (<code>https://</code>), this permission will be persistent.
That is, users won't have to grant/deny access every time.</p>

<h3 id="toc-basic-demo">Basic demo</h3>

<div id="basic" style="text-align:center;">
  <video class="videostream" autoplay></video>
  <p><button class="capture-button">Capture video</button> <button id="stop-button">Stop</button></p>
</div>

<h2 id="toc-screenshot">Taking screenshots</h2>

<p>The <code>&lt;canvas&gt;</code> API's <code>ctx.drawImage(video, 0, 0)</code> method makes it trivial to draw
<code>&lt;video&gt;</code> frames to <code>&lt;canvas&gt;</code>. Of course, now that we have video
input via <code>getUserMedia()</code>, it's just as easy to create a photo booth application
with realtime video:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

&lt;script&gt;
const captureVideoButton =
  document.querySelector('#screenshot .capture-button');
const screenshotButton = document.querySelector('#screenshot-button');
const img = document.querySelector('#screenshot img');
const video = document.querySelector('#screenshot video');

const canvas = document.createElement('canvas');

captureVideoButton.onclick = function() {
  navigator.mediaDevices.getUserMedia(constraints).
    then(handleSuccess).catch(handleError);
};

screenshotButton.onclick = video.onclick = function() {
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  canvas.getContext('2d').drawImage(video, 0, 0);
  // Other browsers will fall back to image/png
  img.src = canvas.toDataURL('image/webp');
};

function handleSuccess(stream) {
  screenshotButton.disabled = false;
  video.srcObject = stream;
}
&lt;/script&gt;
</code></pre>
<div id="screenshot" style="text-align:center;">
  <video class="videostream" autoplay></video>
  <img id="screenshot-img">
  <p><button class="capture-button">Capture video</button>
  <p><button id="screenshot-button" disabled>Take screenshot</button></p>
</div>

<h2 id="toc-effects">Applying Effects</h2>

<h3 id="toc-effects-css">CSS Filters</h3>

<p>Using <a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">CSS Filters</a>, we can apply some gnarly effects to the <code>&lt;video&gt;</code>
as it is captured:</p>
<pre class="prettyprint"><code>
&lt;video autoplay&gt;&lt;/video&gt;
&lt;p&gt;&lt;button class="capture-button"&gt;Capture video&lt;/button&gt;
&lt;p&gt;&lt;button id="cssfilters-apply"&gt;Apply CSS filter&lt;/button&gt;&lt;/p&gt;

&lt;script&gt;
const captureVideoButton =
  document.querySelector('#cssfilters .capture-button');
const cssFiltersButton =
  document.querySelector('#cssfilters-apply');
const video =
  document.querySelector('#cssfilters video');

let filterIndex = 0;
const filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate',
  'hue-rotate2',
  'hue-rotate3',
  'saturate',
  'invert',
  ''
];

captureVideoButton.onclick = function() {
  navigator.mediaDevices.getUserMedia(constraints).
    then(handleSuccess).catch(handleError);
};

cssFiltersButton.onclick = video.onclick = function() {
  video.className = filters[filterIndex++ % filters.length];
};

function handleSuccess(stream) {
  video.srcObject = stream;
}
&lt;/script&gt;
</code></pre>
<div id="cssfilters" style="text-align:center;">
  <video class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p><button class="capture-button">Capture video</button>
  <p><button id="cssfilters-apply">Apply CSS filter</button></p>
</div>

<h3 id="toc-effects-webgl">WebGL Textures</h3>

<p>One amazing use case for video capture is to render live input as a WebGL texture.
Since I know absolutely nothing about WebGL (other than it's sweet), I'm going
to suggest you give Jerome Etienne's <a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">tutorial</a>
and <a href="http://learningthreejs.com/data/live-video-in-webgl/">demo</a> a look.
It talks about how to use <code>getUserMedia()</code> and <a href="/tutorials/three/intro/">Three.js</a>
to render live video into WebGL.</p>
<h2 id="toc-webaudio-api">Using getUserMedia with the Web Audio API</h2>

<p>One of my dreams is to build AutoTune in the browser with nothing more than open web technology! </p>
<p>Chrome supports live microphone input from <code>getUserMedia()</code> to the <a href="/tutorials/webaudio/intro/">Web Audio API</a> for real-time effects. Piping microphone input to the Web Audio API looks like this:</p>
<pre class="prettyprint"><code>window.AudioContext = window.AudioContext ||
                      window.webkitAudioContext;

const context = new AudioContext();

navigator.mediaDevices.getUserMedia({audio: true}).
  then((stream) => {
    const microphone = context.createMediaStreamSource(stream);
    const filter = context.createBiquadFilter();
    // microphone -> filter -> destination
    microphone.connect(filter);
    filter.connect(context.destination);
});
</code></pre>
<p>Demos:</p>
<ul>
<li><a href="http://webaudiodemos.appspot.com/input/index.html">Live Input Visualizer</a></li>
<li><a href="http://webaudiodemos.appspot.com/AudioRecorder/index.html">Audio Recorder</a></li>
<li><a href="http://webaudiodemos.appspot.com/pitchdetect/index.html">Pitch Detector</a></li>
</ul>
<p>For more information, see <a href="http://updates.html5rocks.com/2012/09/Live-Web-Audio-Input-Enabled">Chris Wilson's post</a>.</p>
<h2 id="toc-conclusion">Conclusion</h2>

<p>In general, device access on the web has been a tough cookie to crack. Many
<a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">people have tried</a>,
few have succeeded. Most of the early ideas have never taken hold outside of a
proprietary environment nor have they gained widespread adoption.</p>
<p>The real problem is that the web's security model is <em>very</em> different from the native world.
For example, I probably don't want every Joe Shmoe web site to have random access to my
video camera. It's a tough problem to get right.</p>
<p>Bridging frameworks like <a href="http://phonegap.com/">PhoneGap</a> have helped push the boundary,
but they're only a start and a temporary solution to an underlying problem. To make web
apps competitive to their desktop counterparts, we need access to native devices.</p>
<p><code>getUserMedia()</code> is but the first wave of access to new types of devices. I hope
we'll continue to see more in the very near future!</p>
<h2 id="toc-resources">Additional resources</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">W3C specification</a></li>
<li>Bruce Lawson's <a href="http://html5doctor.com/getusermedia/">HTML5Doctor article</a></li>
<li>Bruce Lawson's <a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">dev.opera.com article</a></li>
<li><a href="https://www.html5rocks.com/en/tutorials/webrtc/basics/#toc-mediastream" title="HTML5 Rocks intro to WebRTC">Getting Started with WebRTC</a></li>
</ul>
<h3 id="toc-demos">Demos</h3>

<ul>
<li><a href="https://webrtc.github.io/samples/" title="WebRTC samples GitHub Pages">WebRTC Samples</a>: canonical demos and code repo</li>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">Live Photo booth</a></li>
<li>Paul Neave's <a href="http://neave.com/webcam/html5/">WebGL Camera Effects</a></li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">Live video in WebGL</a></li>
<li><a href="http://www.soundstep.com/blog/experiments/jsdetection/">Play Xylophone with your hands</a></li>
</ul>
<script>
function handleError(error) {
  console.error('navigator.getUserMedia error: ', error);
}
const constraints = {video: true};

(function() {
  const video = document.querySelector('#basic video');
  const captureVideoButton = document.querySelector('#basic .capture-button');
  let localMediaStream;

  function handleSuccess(stream) {
    localMediaStream = stream;
    video.srcObject = stream;
  }

  captureVideoButton.onclick = function() {
    navigator.mediaDevices.getUserMedia(constraints).
      then(handleSuccess).catch(handleError);
  };

  document.querySelector('#stop-button').onclick = function() {
    video.pause();
    localMediaStream.stop();
  };
})();

(function() {
  const captureVideoButton =
    document.querySelector('#screenshot .capture-button');
  const screenshotButton = document.querySelector('#screenshot-button');
  const img = document.querySelector('#screenshot img');
  const video = document.querySelector('#screenshot video');

  const canvas = document.createElement('canvas');

  captureVideoButton.onclick = function() {
    navigator.mediaDevices.getUserMedia(constraints).
      then(handleSuccess).catch(handleError);
  };

  screenshotButton.onclick = video.onclick = function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    canvas.getContext('2d').drawImage(video, 0, 0);
    // Other browsers will fall back to image/png
    img.src = canvas.toDataURL('image/webp');
  };

  function handleSuccess(stream) {
    screenshotButton.disabled = false;
    video.srcObject = stream;
  }
})();

(function() {
  const captureVideoButton =
    document.querySelector('#cssfilters .capture-button');
  const cssFiltersButton = document.querySelector('#cssfilters-apply');
  const video = document.querySelector('#cssfilters video');

  let filterIndex = 0;
  const filters = [
    'grayscale',
    'sepia',
    'blur',
    'brightness',
    'contrast',
    'hue-rotate',
    'hue-rotate2',
    'hue-rotate3',
    'saturate',
    'invert',
    ''
  ];

  captureVideoButton.onclick = function() {
    navigator.mediaDevices.getUserMedia(constraints).
      then(handleSuccess).catch(handleError);
  };

  cssFiltersButton.onclick = video.onclick = function() {
    video.className = filters[filterIndex++ % filters.length];
  };

  function handleSuccess(stream) {
    video.srcObject = stream;
  }
})();
</script>
{% endblock %}
