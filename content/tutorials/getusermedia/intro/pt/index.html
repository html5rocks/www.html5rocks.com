{% extends "tutorial.html" %}
{% load mixin from templatefilters %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
.videostream, #cssfilters-stream {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
#screenshot-stream {
  width: initial;
  height: initial;
}
#screenshot {
  vertical-align: top;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1)
  -o-filter: invert(1)
  -ms-filter: invert(1)
  filter: invert(1)
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="Este artigo tem tecnologia de áudio/vídeo HTML5" title="Este artigo tem tecnologia de áudio/vídeo HTML5"  />
{% endblock %}

{% block content %}

<p>{% include "warning.html" %}</p>
<h2 id="toc-into">Introdução</h2>

<p>A captura de áudio/vídeo tem sido <em>o</em> "Santo Graal" do desenvolvimento da web há muito tempo. Por muitos anos, temos usado plug-ins de navegadores (<a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> ou <a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a>) para fazer isso. <a href="https://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">Vamos lá!</a></p>
<p>HTML5 para nos resgatar. Talvez não seja aparente, mas o surgimento do HTML5 trouxe um pico de acesso ao hardware do dispositivo. <a href="/tutorials/geolocation/trip_meter/">localização geográfica</a> (GPS), <a href="/tutorials/device/orientation/">API de orientação</a> (acelerômetro), <a href="/tutorials/webgl/shaders/">WebGL</a> (GPU) e <a href="/tutorials/webaudio/intro/">API de áudio da web</a> (hardware de áudio) são exemplos perfeitos. Esses recursos são incrivelmente poderosos, expondo APIs JavaScript de alto nível que se sobrepõem aos recursos de hardware subjacentes do sistema.</p>
<p>Este tutorial introduz uma nova API, <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html"><code>navigator.getUserMedia()</code></a>, que permite aos aplicativos da web acessar a câmera e o microfone do usuário.</p>
<h2 id="toc-history">O histórico de getUserMedia()</h2>

<p>Se você não conhece a história, vale dizer que o modo como chegamos à API <code>getUserMedia()</code> é um conto interessante.</p>
<p>Nos últimos anos, foram desenvolvidas diversas variações de "APIs de captura de mídia". Muitos colegas reconheceram a necessidade de conseguir acessar dispositivos nativos na web, mas isso levou ao desenvolvimento de uma nova especificação. As coisas ficaram tão confusas que o W3C finalmente decidiu formar um grupo de trabalho. O objetivo? Arrumar a bagunça. O <a href="http://www.w3.org/2009/dap/">grupo de trabalho DAP (política de APIs de dispositivo)</a> tinha a tarefa de consolidar e padronizar a variedade de propostas.</p>
<p>Tentarei resumir o que aconteceu em 2011...</p>
<h3 id="toc-round1">Round 1: captura de mídia HTML</h3>

<p>A <a href="http://dev.w3.org/2009/dap/camera/">captura de mídia HTML</a> foi a primeira tentativa do DAP de padronizar a captura de mídia na web. Ela funciona sobrepondo <code>&lt;input type="file"&gt;</code> e adicionando novos valores para o parâmetro <code>accept</code>.</p>
<p>Os usuários possam fazer uma captura de tela por conta própria com a webcam usando <code>capture=camera</code>:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>A gravação de um vídeo ou áudio é semelhante:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>Muito bom, não é? Particularmente, gosto da reutilização de uma entrada de arquivo. Semanticamente, isso faz muito sentido. O ponto fraco dessa "API" específica está em sua capacidade de criar efeitos em tempo real (por exemplo, processar dados ao vivo da webcam em um <code>&lt;canvas&gt;</code> e aplicar filtros WebGL). A captura de mídia HTML só permite gravar um arquivo de mídia ou fazer uma captura de tela por vez.</p>
<p><strong>Suporte:</strong></p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Navegador Android 3.0</a> - uma das primeiras implementações. Confira <a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">este vídeo</a> para vê-lo em ação.</li>
<li>Google Chrome para Android (0.16)</li>
</ul>
<p>Minha recomendação é não utilizá-lo, a não ser que você esteja trabalhando com um dos navegadores para celular acima. Os fornecedores estão migrando para <code>getUserMedia()</code>. É muito improvável que mais alguém implemente a captura de mídia HTML em longo prazo.</p>
<h3 id="toc-round2">Round 2: elemento device</h3>

<p>Como muitos pensavam que a captura de mídia HTML era muito limitada, uma nova especificação surgiu para dar suporte a qualquer tipo de dispositivo (futuro). Como era de se esperar, o projeto precisava de um novo elemento, o elemento <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code></a>, que se tornou o antecessor de <code>getUserMedia()</code>.</p>
<p>O Opera foi um dos primeiros navegadores a criar <a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">implementações iniciais</a> de captura de vídeo com base no elemento <code>&lt;device&gt;</code>. Logo depois (<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">no mesmo dia</a> para ser exato), o WhatWG decidiu usar a tag <code>&lt;device&gt;</code> em outro projeto, dessa vez, uma API JavaScript chamada <code>navigator.getUserMedia()</code>. Uma semana depois, o Opera criou novas versões que incluíam suporte para a especificação <code>getUserMedia()</code> atualizada. Mais tarde nesse mesmo ano, a Microsoft se juntou ao projeto lançando um <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">Lab for IE9</a> com suporte para a nova especificação.</p>
<p>Veja como seria o <code>&lt;device&gt;</code>:</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>Suporte:</strong></p>
<p>Infelizmente, nenhum navegador lançado nunca incluiu <code>&lt;device&gt;</code>. Uma API a menos para se preocupar, eu acho :) <code>&lt;device&gt;</code> tinha duas grandes vantagens: 1.) era semântico e 2.) podia ser facilmente estendido para oferecer suporte a mais do que simplesmente dispositivos de áudio/vídeo.</p>
<p>Respire fundo. As coisas mudam rapidamente.</p>
<h3 id="toc-round3">Round 3: WebRTC</h3>

<p>O elemento <code>&lt;device&gt;</code> acabou se tornando o método de Dodo.</p>
<p>O ritmo para encontrar uma API de captura adequada acelerou nos últimos meses graças a uma iniciativa mais abrangente chamada <a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html">WebRTC</a> (Comunicação on-line em tempo real). A especificação é supervisionada pelo <a href="http://www.w3.org/2011/04/webrtc/">grupo de trabalho WebRTC do W3C</a>. Google, Opera, Mozilla e <a href="http://webrtc.org">alguns outros navegadores</a> estão trabalhando no momento para trazer as implementações para seus navegadores.</p>
<p><code>getUserMedia()</code> está relacionado ao WebRTC porque é a porta de acesso para esse conjunto de APIs. Ele fornece o meio para acessar o fluxo da câmera/microfone local do usuário.</p>
<p><strong>Suporte:</strong></p>
<p>WebRTC pode ser ativado no Google Chrome 18.0.1008+ em <code>about:flags</code>.</p>
<h2 id="toc-gettingstarted">Primeiros passos</h2>

<p>Com <code>navigator.getUserMedia()</code>, podemos finalmente trabalhar com a entrada da webcam e do microfone sem um plug-in. O acesso da câmera agora está a uma chamada, não a uma instalação de distância. Ele ocorre diretamente no navegador. Já se interessou?</p>
<h3 id="toc-enabling">Ativando</h3>

<p>A API <code>getUserMedia()</code> ainda é muito recente, e somente Google e Opera têm versões de desenvolvedor que a incluem. No Google Chrome 18+, a API pode ser ativada em <code>about:flags</code>.</p>
<p><figure>
<img src="aboutflags.png">
<figcaption>Ativação de <code>getUserMedia()</code> na página <code>about:flags</code> do Google Chrome.</figcaption>
</figure></p>
<p>Para o Opera, faça download das <a href="http://dev.opera.com/articles/view/labs-more-fun-using-the-web-with-getusermedia-and-native-pages/">versões experimentais para Android e computador</a>.</p>
<h3 id="toc-featuredecting">Detecção de recursos</h3>

<p>A detecção de recursos é uma simples verificação da existência de <code>navigator.getUserMedia</code>:</p>
<pre class="prettyprint"><code>function hasGetUserMedia() {
  // Note: Opera builds are unprefixed.
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
}

if (hasGetUserMedia()) {
  // Good to go!
} else {
  alert('getUserMedia() is not supported in your browser');
}
</code></pre>
<h3 id="toc-acccess">Obtenção de acesso a um dispositivo de entrada</h3>

<p>Para usar a webcam ou o microfone, precisamos solicitar permissão. O primeiro parâmetro de <code>getUserMedia()</code> serve para especificar o tipo de mídia que você deseja acessar. Por exemplo, para solicitar a webcam, o primeiro parâmetro deverá ser <code>"video"</code>. Para usar o microfone e a câmera, transmita <code>"video, audio"</code>:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var onFailSoHard = function(e) {
    console.log('Reeeejected!', e);
  };

  // Not showing vendor prefixes.
  navigator.getUserMedia('video, audio', function(localMediaStream) {
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(localMediaStream);

    // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
    // See crbug.com/110938.
    video.onloadedmetadata = function(e) {
      // Ready to go. Do some stuff.
    };
  }, onFailSoHard);
&lt;/script&gt;
</code></pre>
<p>OK. O que está acontecendo aqui? A captura de mídia é um exemplo perfeito de novas APIs HTML5 funcionando juntas. Ela funciona junto com os outros elementos HTML5, <code>&lt;audio&gt;</code> e <code>&lt;video&gt;</code>. Observe que não estamos definindo um atributo <code>src</code> nem incluindo elementos <code>&lt;source&gt;</code> no elemento <code>&lt;video&gt;</code>. Em vez de direcionar o vídeo para um URL de um arquivo de mídia, estamos direcionando-o para um <a href="/tutorials/workers/basics/#toc-inlineworkers-bloburis">URL de blob</a> obtido a partir de um objeto <code>LocalMediaStream</code> que representa a webcam.</p>
<p>Também estou instruindo o <code>&lt;video&gt;</code> a <code>ser reproduzido automaticamente</code>; caso contrário, ele seria congelado no primeiro quadro. A adição de <code>controles</code> também funciona conforme esperado.</p>
<p class="notice" style="text-align:center">
<strong>Observação:</strong> há um bug no Google Chrome porque a transmissão de apenas "audio" não funciona: <a href="http://crbug.com/112367">crbug.com/112367</a>. O elemento <code>&lt;audio&gt;</code> também não funcionaria no Opera.
</p>

<p>O Opera e o Chrome implementam versões diferentes da <a href="getusermedia-spec">especificação</a>. Isso deixa o uso prático um pouco mais "desafiador" do que normalmente seria.</p>
<p><strong>No Chrome:</strong></p>
<p>Esse snippet funciona no <span class="browser chrome supported" style="float:none;display:inline-block;"><span class="browser_name">Chrome</span></span> 18+ (ative em <code>about:flags</code>):</p>
<pre class="prettyprint"><code>navigator.webkitGetUserMedia('audio, video', function(localMediaStream) {
  var video = document.querySelector('video');
  video.src = window.webkitURL.createObjectURL(localMediaStream);
}, onFailSoHard);
</code></pre>
<p><strong>No Opera:</strong></p>
<p>As versões de desenvolvedor do Opera funcionam com uma versão atualizada da especificação. Esse snippet funciona no <span class="browser opera supported" style="float:none;display:inline-block;"><span class="browser_name">Opera</span></span>:</p>
<pre class="prettyprint"><code>navigator.getUserMedia({audio: true, video: true}, function(localMediaStream) {
  video.src = localMediaStream;
}, onFailSoHard);
</code></pre>
<p>As principais diferenças são:</p>
<ul>
<li><code>getUserMedia()</code> não tem prefixo.</li>
<li>Um objeto é transmitido como o primeiro argumento em vez de uma lista de strings.</li>
<li><code>video.src</code> é definido diretamente como o objeto <code>LocalMediaStream</code> em vez de um URL de blob. Soube que o Opera acabará atualizando isso para exigir um URL de blob.</li>
</ul>
<p><strong>Nos dois:</strong></p>
<p>Se desejar que algo funcione em vários navegadores (mas isso é muito delicado), tente fazer isso:</p>
<pre class="prettyprint"><code>var video = document.querySelector('video');

if (navigator.getUserMedia) {
  navigator.getUserMedia({audio: true, video: true}, function(stream) {
    video.src = stream;
  }, onFailSoHard);
} else if (navigator.webkitGetUserMedia) {
  navigator.webkitGetUserMedia('audio, video', function(stream) {
    video.src = window.webkitURL.createObjectURL(stream);
  }, onFailSoHard);
} else {
  video.src = 'somevideo.webm'; // fallback.
}
</code></pre>
<p>Confira o trabalho de <a href="http://twitter.com/miketaylr">Mike Taylor</a> e <a href="http://twitter.com/akamike">Mike Robinson</a> <a href="https://gist.github.com/f2ac64ed7fc467ccdfe3">gUM Shield</a>. Eles fazem um trabalho excelente de "normalização" das inconsistências entre implementações de navegadores.</p>
<h3 id="toc-security">Segurança</h3>

<p>No futuro, os navegadores podem lançar uma barra de informações chamando <code>getUserMedia()</code>, o que daria aos usuários a opção de conceder ou negar o acesso à câmera ou ao microfone. Infelizmente, a especificação não traz muitos detalhes sobre segurança. No momento, ninguém implementa uma barra de permissão.</p>
<h3 id="toc-fallback">Fornecimento de fallback</h3>

<p>Para usuários que não têm suporte para <code>getUserMedia()</code>, uma opção seria executar fallback para um arquivo de vídeo já existente se a API não fosse compatível e/ou a chamada falhasse por algum motivo:</p>
<pre class="prettyprint"><code>// Not showing vendor prefixes or code that works cross-browser:

function fallback(e) {
  video.src = 'fallbackvideo.webm';
}

function success(stream) {
  video.src = window.URL.createObjectURL(stream);
}

if (!navigator.getUserMedia) {
  fallback();
} else {
  navigator.getUserMedia({video: true}, success, fallback);
}
</code></pre>
<h3 id="toc-basic-demo">Demonstração básica</h3>

<div style="text-align:center;">
  <video id="basic-stream" class="videostream" autoplay></video>
  <p><button id="capture-button">Capturar vídeo</button> <button id="stop-button">Parar</button></p>
</div>

<h2 id="toc-screenshot">Como fazer capturas de tela</h2>

<p>O método <code>ctx.drawImage(video, 0, 0)</code> da API <code>&lt;canvas&gt;</code> simplifica o desenho de quadros de <code>&lt;video&gt;</code> no <code>&lt;canvas&gt;</code>. Obviamente, agora que temos a entrada de vídeo via <code>getUserMedia()</code>, ficou fácil criar um aplicativo para tirar foto com vídeo em tempo real:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

var video = document.querySelector('video');
var canvas = document.querySelector('canvas');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function snapshot() {
  if (localMediaStream) {
    ctx.drawImage(video, 0, 0);
    // "image/webp" works in Chrome 18. In other browsers, this will fall back to image/png.
    document.querySelector('img').src = canvas.toDataURL('image/webp');
  }
}

video.addEventListener('click', snapshot, false);

// Not showing vendor prefixes or code that works cross-browser.
navigator.getUserMedia({video: true}, function(stream) {
  video.src = window.URL.createObjectURL(stream);
  localMediaStream = stream;
}, onFailSoHard);
</code></pre>
<div style="text-align:center;">
  <video id="screenshot-stream" class="videostream" autoplay></video>
  <img id="screenshot" src="">
  <canvas id="screenshot-canvas" style="display:none;"></canvas>
  <p><button id="screenshot-button">Capturar</button> <button id="screenshot-stop-button">Parar</button></p>
</div>

<h2 id="toc-effects">Aplicação de efeitos</h2>

<h3 id="toc-effects-css">Filtros do CSS</h3>

<p class="notice" style="text-align:center">
Atualmente, os filtros do CSS são aceitos no WebKit nightlies e no Chrome 18+.
</p>

<p>Usando os <a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">filtros do CSS</a>, podemos aplicar alguns efeitos de nós ao <code>&lt;video&gt;</code> conforme ele é capturado:</p>
<pre class="prettyprint"><code>&lt;style&gt;
video {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.grayscale {
  {% mixin filter: grayscale(1); %}
}
.sepia {
  {% mixin filter: sepia(1); %}
}
.blur {
  {% mixin filter: blur(3px); %}
}
...
&lt;/style&gt;

&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
var idx = 0;
var filters = ['grayscale', 'sepia', 'blur', 'brightness', 'contrast', 'hue-rotate',
               'hue-rotate2', 'hue-rotate3', 'saturate', 'invert', ''];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length]; // loop through filters.
  if (effect) {
    el.classList.add(effect);
  }
}

document.querySelector('video').addEventListener('click', changeFilter, false);
&lt;/script&gt;
</code></pre>
<div style="text-align:center;">
  <video id="cssfilters-stream" class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p>Clique no vídeo para percorrer os filtros do CSS</p>
  <p><button id="capture-button2">Capturar vídeo</button> <button id="stop-button2">Parar</button></p>
</div>

<h3 id="toc-effects-webgl">Texturas de WebGL</h3>

<p>Um caso de uso incrível para captura de vídeo é processar a entrada ao vivo como uma textura de WebGL. Como eu não sei absolutamente nada sobre WebGL (a não ser que é bom), vou sugerir que vocês confiram o <a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">tutorial</a> e a <a href="http://learningthreejs.com/data/live-video-in-webgl/">demonstração</a> de Jerome Etienne. Eles mostram como usar <code>getUserMedia()</code> e <a href="/tutorials/three/intro/">Three.js</a> para processar vídeo ao vivo no WebGL.</p>
<h2 id="toc-webaudio-api">Como usar getUserMedia com a API de áudio da web</h2>

<p class="notice" style="text-align:center">
Esta seção discute os possíveis aprimoramentos e extensões futuros para a API atual.
</p>

<p>Um dos meus sonhos é criar o AutoTune no navegador tendo apenas apenas a tecnologia da web aberta. Não estamos muito longes dessa realidade. Já temos <code>getUserMedia()</code> para entrada de microfone. Use a <a href="/tutorials/webaudio/intro/">API de áudio da web</a> para obter efeitos em tempo real e pronto. Ainda falta a integração dos dois (<a href="http://crbug.com/112404">crbug.com/112404</a>), embora haja uma <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html">proposta preliminar</a> nos trabalhos para que isso aconteça.</p>
<p>Algum dia, a execução da entrada de microfone na API de áudio da web <em>poderia</em> ser parecida com:</p>
<pre class="prettyprint"><code>var context = new window.webkitAudioContext();

navigator.webkitGetUserMedia({audio: true}, function(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();

  // microphone -&gt; filter -&gt; destination.
  microphone.connect(filter);
  filter.connect(context.destination);
}, onFailSoHard);
</code></pre>
<p>Se desejar ver <code>getUserMedia()</code> associado à API de áudio da web, marque <a href="http://crbug.com/112404">crbug.com/112404</a> com uma estrela.</p>
<h2 id="toc-conclusion">Conclusão</h2>

<p>Em geral, o acesso do dispositivo na web tem sido um grande problema. Muitas <a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">pessoas tentaram</a>, mas poucas conseguiram. A maioria das primeiras ideias nunca saiu de um ambiente reservado, nem foi adotada de modo abrangente.</p>
<p>O verdadeiro problema é que o modelo de segurança da web é <em>muito</em> diferente do mundo nativo. Por exemplo, eu provavelmente não quero que todos os sites de Joe Shmoe tenham acesso aleatório à minha câmera de vídeo. É um grande problema fazer isso.</p>
<p>A associação de estruturas como <a href="http://phonegap.com/">PhoneGap</a> tem ajudado a ultrapassar a barreira, mas ela é apenas um ponto de partida e uma solução temporária para um problema subjacente. Para que os aplicativos da web sejam competitivos com seus correspondentes de computador, precisamos acessar os dispositivos nativos.</p>
<p><code>getUserMedia()</code> é a primeira onda de acesso a novos tipos de dispositivo. Espero que haja outros em um futuro próximo.</p>
<h2 id="toc-resources">Recursos adicionais</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">Especificação W3C</a></li>
<li><a href="http://html5doctor.com/getusermedia/">Artigo sobre HTML5Doctor</a> de Bruce Lawson</li>
<li><a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">Artigo sobre dev.opera.com</a> de Bruce Lawson</li>
</ul>
<h3 id="toc-demos">Demonstrações</h3>

<ul>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">Tirar fotos ao vivo</a></li>
<li><a href="http://neave.com/webcam/html5/">Efeitos de câmera WebGL</a> de Paul Neave</li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">Vídeo ao vivo no WebGL</a></li>
</ul>
<script>
function onFailSoHard(e) {
  alert('getUserMedia() not supported in your browser.');
  e.target.src = 'http://www.html5rocks.com/en/tutorials/video/basics/Chrome_ImF.ogv';
}

(function() {
var video = document.querySelector('#basic-stream');
var button = document.querySelector('#capture-button');
var localMediaStream = null;

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#screenshot-stream');
var button = document.querySelector('#screenshot-button');
var canvas = document.querySelector('#screenshot-canvas');
var img = document.querySelector('#screenshot');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function sizeCanvas() {
  // video.onloadedmetadata not firing in Chrome. See crbug.com/110938.
  setTimeout(function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    img.height = video.videoHeight;
    img.width = video.videoWidth;
  }, 50);
}

function snapshot() {
  ctx.drawImage(video, 0, 0);
  img.src = canvas.toDataURL('image/webp');
}

button.addEventListener('click', function(e) {
  if (localMediaStream) {
    snapshot();
    return;
  }

if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

video.addEventListener('click', snapshot, false);

document.querySelector('#screenshot-stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#cssfilters-stream');
var button = document.querySelector('#capture-button2');
var localMediaStream = null;

var idx = 0;
var filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate', 'hue-rotate2', 'hue-rotate3',
  'saturate',
  'invert',
  ''
];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length];
  if (effect) {
    el.classList.add(effect);
  }
}

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video, audio', function(stream) {
      video.src = stream;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button2').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);

video.addEventListener('click', changeFilter, false);
})();
</script>
{% endblock %}
