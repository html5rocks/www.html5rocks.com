{% extends "tutorial.html" %}
{% load mixin from templatefilters %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
.videostream, #cssfilters-stream {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
#screenshot-stream {
  width: initial;
  height: initial;
}
#screenshot {
  vertical-align: top;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1)
  -o-filter: invert(1)
  -ms-filter: invert(1)
  filter: invert(1)
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="This article is powered by HTML5 Audio/Video" title="This article is powered by HTML5 Audio?/Video"  />
{% endblock %}

{% block content %}

<p>{% include "warning.html" %}</p>
<h2 id="toc-into">Введение</h2>

<p>Захват потокового видео и аудио является <em>приоритетным направлением</em> в разработке веб-приложений на протяжении многих лет. В течение долгого времени для выполнения этих задач мы полагались на плагины (<a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> и <a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a>). <a href="https://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">Come on!</a></p>
<p>На помощь пришел HTML5. Возможно, этот момент не очевиден, но распространение HTML5 подняло вопрос доступа к аппаратным ресурсам. Прекрасными примерами этого являются функции <a href="/tutorials/geolocation/trip_meter/">Geolocation</a> (GPS), <a href="/tutorials/device/orientation/">Orientation API</a> (акселерометр), <a href="/tutorials/webgl/shaders/">WebGL</a> (графические процессоры) и <a href="/tutorials/webaudio/intro/">API веб-аудио</a> (звуковое оборудование). Эти разработки очень функциональны. Они созданы на основе API JavaScript высокого уровня и опираются на аппаратные возможности исходного устройства.</p>
<p>Эта статья посвящена новому API под названием <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html"><code>navigator.getUserMedia()</code></a>, который предоставляет веб-приложениям доступ к видеокамере и микрофону.</p>
<h2 id="toc-history">История появления getUserMedia()</h2>

<p>История появления API <code>getUserMedia()</code> довольно интересна.</p>
<p>За последние несколько лет появилось несколько разных API захвата медиаданных. Многие осознали необходимость доступа к аппаратным ресурсам из веб-приложений, и это привело к созданию различных спецификаций. Ситуация окончательно запуталась, и тогда консорциум W3C решил сформировать рабочую группу. Ее единственной задачей стало навести порядок в этой сфере. Для этого <a href="http://www.w3.org/2009/dap/">рабочая группа по созданию правил для API устройств (DAP)</a> должна была объединить и стандартизировать существующие предложения.</p>
<p>Сейчас можно подвести итоги того, что было сделано в 2011 г.</p>
<h3 id="toc-round1">Этап 1: захват медиаданных в HTML</h3>

<p>Спецификация <a href="http://dev.w3.org/2009/dap/camera/">захвата медиаданных в HTML</a> стала первым стандартом захвата мультимедийной информации в веб-приложениях, созданным группой DAP. Его работа основана на переопределении функции <code>&lt;input type="file"&gt;</code> и добавлении новых значений для параметра <code>accept</code>.</p>
<p>Чтобы дать пользователям возможность сфотографировать себя на веб-камеру, можно добавить строку <code>capture=camera</code>.</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>Точно так же происходит запись видео и звука.</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>Это довольно удобно. В частности, мне нравится, что в этом методе используется файловый ввод. С точки зрения семантики это имеет большое значение. Единственный недостаток этого API – невозможность добавления эффектов в реальном времени (например, нельзя выводить данные с веб-камеры на элемент <code>&lt;canvas&gt;</code> и применять фильтры WebGL). С помощью захвата медиаданных в HTML можно только записывать файлы мультимедиа или делать снимки.</p>
<p><strong>Поддержка</strong></p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Браузер Android 3.0</a> – один из первых примеров реализации этого API. Чтобы увидеть его в действии, посмотрите <a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">это видео</a>.</li>
<li>Chrome для Android (0.16)</li>
</ul>
<p>Я не рекомендую использовать этот API, если только вы не работаете с одним из перечисленных выше браузеров. Разработчики постепенно переходят к <code>getUserMedia()</code>, и в перспективе вряд ли кто-нибудь захочет заниматься реализацией захвата медиаданных с помощью HTML.</p>
<h3 id="toc-round2">Этап 2: элемент устройства</h3>

<p>Многие считали, что в API захвата медиаданных в HTML слишком много ограничений, поэтому появилась новая спецификация, поддерживающая любые устройства, включая те, что появятся в будущем. Неудивительно, что эта разработка потребовала введения нового элемента <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code></a>, который стал шагом на пути к созданию API <code>getUserMedia()</code>.</p>
<p>Одним из первых браузеров, в котором была <a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">реализована поддержка</a> захвата видео с помощью элемента <code>&lt;device&gt;</code>, стала Opera. Вскоре после этого (<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">точнее, в тот же день</a>), сообщество WhatWG решило отказаться от тега <code>&lt;device&gt;</code> в пользу более успешного API JavaScript под названием <code>navigator.getUserMedia()</code>. Через неделю в новую сборку Opera была добавлена поддержка обновленной спецификации <code>getUserMedia()</code>. В конце этого года компания Майкрософт присоединилась к разработке, выпустив <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">экспериментальный пакет для IE9</a> с поддержкой этой спецификации.</p>
<p>Вот так мог выглядеть тег <code>&lt;device&gt;</code>:</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>Поддержка</strong></p>
<p>К сожалению, тег <code>&lt;device&gt;</code> не был реализован ни в одном браузере. Таким образом, его можно не принимать в расчет, хотя у тега <code>&lt;device&gt;</code> все же было два преимущества. Во-первых, он имел семантический характер, а во-вторых, позволял не ограничиваться аудио- и видеоустройствами.</p>
<p>Переходим к следующей технологии.</p>
<h3 id="toc-round3">Этап 3: WebRTC</h3>

<p>Элемент <code>&lt;device&gt;</code> в конечном счете полностью исчез.</p>
<p>В последние несколько месяцев попытки создания API для захвата данных мультимедиа начали приносить ощутимые результаты – во многом благодаря проекту <a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html">WebRTC</a> (передача данных в Интернете в реальном времени). Разработку этой спецификации курирует специальная рабочая группа <a href="http://www.w3.org/2011/04/webrtc/">W3C WebRTC</a>. В настоящее время над реализацией ее поддержки в браузерах работают такие известные компании, как Google, Opera, Mozilla, а также <a href="http://webrtc.org">ряд других</a>.</p>
<p>WebRTC имеет прямое отношение к <code>getUserMedia()</code> – первому API в этом наборе. Эта технология обеспечивает доступ к потоковым данным с микрофона и видеокамеры.</p>
<p><strong>Поддержка</strong></p>
<p>WebRTC можно включить в браузере Chrome 18.0.1008 и его более поздних версиях на странице <code>about:flags</code>.</p>
<h2 id="toc-gettingstarted">Начало работы</h2>

<p>Благодаря <code>navigator.getUserMedia()</code> наконец появилась возможность перехватывать данные с веб-камер и микрофонов непосредственно, то есть без помощи плагинов. Доступ к камере теперь осуществляется по запросу, и для этого ничего не нужно устанавливать. Эта возможность встроена в браузер, и это довольно интересно.</p>
<h3 id="toc-enabling">Включение</h3>

<p>API <code>getUserMedia()</code> появился совсем недавно, поэтому он реализован только в сборках для разработчиков Google и Opera. В Chrome 18+ его можно включить на странице <code>about:flags</code>.</p>
<p><figure>
<img src="aboutflags.png">
<figcaption>Включение <code>getUserMedia()</code> на странице <code>about:flags</code> браузера Chrome.</figcaption>
</figure></p>
<p>Для Opera вы можете загрузить одну из экспериментальных <a href="http://dev.opera.com/articles/view/labs-more-fun-using-the-web-with-getusermedia-and-native-pages/">сборок для Android или обычных компьютеров</a>.</p>
<h3 id="toc-featuredecting">Определение возможностей</h3>

<p>Эта проверка позволяет убедиться в поддержке браузером функции <code>navigator.getUserMedia</code>.</p>
<pre class="prettyprint"><code>function hasGetUserMedia() {
  // Note: Opera builds are unprefixed.
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
}

if (hasGetUserMedia()) {
  // Good to go!
} else {
  alert('getUserMedia() is not supported in your browser');
}
</code></pre>
<h3 id="toc-acccess">Получение доступа к устройству ввода</h3>

<p>Для доступа к веб-камере или микрофону необходимо запросить разрешение. Первый параметр метода <code>getUserMedia()</code> определяет тип данных, к которым запрашивается доступ. Например, если чтобы обратиться к веб-камере, необходимо задать для него значение <code>video</code>. Чтобы использовать одновременно камеру и микрофон, нужно указать <code>video, audio</code>.</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var onFailSoHard = function(e) {
    console.log('Reeeejected!', e);
  };

  // Not showing vendor prefixes.
  navigator.getUserMedia('video, audio', function(localMediaStream) {
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(localMediaStream);

    // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
    // See crbug.com/110938.
    video.onloadedmetadata = function(e) {
      // Ready to go. Do some stuff.
    };
  }, onFailSoHard);
&lt;/script&gt;
</code></pre>
<p>Итак, что же происходит далее? Функция захвата данных мультимедиа – прекрасный пример совместной работы различных API в HTML5. Она используется вместе с другими элементами HTML5: <code>&lt;audio&gt;</code> и <code>&lt;video&gt;</code>. Обратите внимание: мы не добавляем атрибут <code>src</code> или элементы <code>&lt;source&gt;</code> в тег <code>&lt;video&gt;</code>. Вместо того чтобы указывать URL файла мультимедиа, мы передаем <a href="/tutorials/workers/basics/#toc-inlineworkers-bloburis">URL элемента Blob</a> из объекта <code>LocalMediaStream</code>, который представляет веб-камеру.</p>
<p>Мы также добавляем для тега <code>&lt;video&gt;</code> атрибут автовоспроизведения <code>autoplay</code>, чтобы видео не остановилось на первом же кадре. Добавить <code>элементы управления</code> также несложно.</p>
<p class="notice" style="text-align:center">
<strong>Внимание!</strong> В Chrome есть неполадка: если передать в качестве значения параметра только audio, код не работает (<a href="http://crbug.com/112367">crbug.com/112367</a>). Та же проблема с тегом <code>&lt;audio&gt;</code> обнаружена и в Opera.
</p>

<p>В Opera и Chrome реализованы различные версии этой <a href="getusermedia-spec">спецификации</a>, что несколько усложняет ее практическое использование на данном этапе.</p>
<p><strong>Chrome</strong></p>
<p>Ниже приведен фрагмент кода для <span class="browser chrome supported" style="float:none;display:inline-block;"><span class="browser_name">Chrome</span></span> 18+ (необходимо сначала включить эту функцию на странице <code>about:flags</code>).</p>
<pre class="prettyprint"><code>navigator.webkitGetUserMedia('audio, video', function(localMediaStream) {
  var video = document.querySelector('video');
  video.src = window.webkitURL.createObjectURL(localMediaStream);
}, onFailSoHard);
</code></pre>
<p><strong>Opera:</strong></p>
<p>Сборки Opera для разработчиков основаны на обновленной версии спецификации. Ниже приведен фрагмент кода для <span class="browser opera supported" style="float:none;display:inline-block;"><span class="browser_name">Opera</span></span>.</p>
<pre class="prettyprint"><code>navigator.getUserMedia({audio: true, video: true}, function(localMediaStream) {
  video.src = localMediaStream;
}, onFailSoHard);
</code></pre>
<p>Существует несколько ключевых различий.</p>
<ul>
<li>В <code>getUserMedia()</code> не используются префиксы.</li>
<li>Объект передается как первый аргумент, а не список строк.</li>
<li>Значение <code>video.src</code> присваивается непосредственно объекту <code>LocalMediaStream</code>, а не URL данного Blob. Насколько мне известно, в Opera в конечном итоге будет использоваться URL объекта Blob.</li>
</ul>
<p><strong>Кросс-браузерная поддержка</strong></p>
<p>Ниже приведен пример (довольно ненадежный), который поддерживается в обоих браузерах.</p>
<pre class="prettyprint"><code>var video = document.querySelector('video');

if (navigator.getUserMedia) {
  navigator.getUserMedia({audio: true, video: true}, function(stream) {
    video.src = stream;
  }, onFailSoHard);
} else if (navigator.webkitGetUserMedia) {
  navigator.webkitGetUserMedia('audio, video', function(stream) {
    video.src = window.webkitURL.createObjectURL(stream);
  }, onFailSoHard);
} else {
  video.src = 'somevideo.webm'; // fallback.
}
</code></pre>
<p>Обязательно ознакомьтесь со статьей <a href="http://twitter.com/miketaylr">Майка Тейлора (Mike Taylor)</a> и <a href="http://twitter.com/akamike">Майка Робинсона (Mike Robinson)</a> <a href="https://gist.github.com/f2ac64ed7fc467ccdfe3">gUM Shield</a>. Она поможет устранить противоречия в вариантах кода для разных браузеров.</p>
<h3 id="toc-security">Безопасность</h3>

<p>В будущем в браузерах при вызове метода <code>getUserMedia()</code>, возможно, будет появляться информационная панель, позволяющая пользователю предоставлять или запретить доступ к камере или микрофону. К сожалению, в спецификации уделено мало внимания вопросам безопасности. Пока что такая панель с разрешениями не реализована.</p>
<h3 id="toc-fallback">Обеспечение обратной совместимости</h3>

<p>Для тех, кто не может воспользоваться методом <code>getUserMedia()</code> (например, если этот API не поддерживается или по какой-то причине произошел сбой запроса), единственное решение – использовать существующие видеофайлы.</p>
<pre class="prettyprint"><code>// Not showing vendor prefixes or code that works cross-browser:

function fallback(e) {
  video.src = 'fallbackvideo.webm';
}

function success(stream) {
  video.src = window.URL.createObjectURL(stream);
}

if (!navigator.getUserMedia) {
  fallback();
} else {
  navigator.getUserMedia({video: true}, success, fallback);
}
</code></pre>
<h3 id="toc-basic-demo">Демонстрация основных возможностей</h3>

<div style="text-align:center;">
  <video id="basic-stream" class="videostream" autoplay></video>
  <p><button id="capture-button">Захват видео</button> <button id="stop-button">Остановить</button></p>
</div>

<h2 id="toc-screenshot">Снимки экрана</h2>

<p>В API <code>&lt;canvas&gt;</code> есть метод <code>ctx.drawImage(video, 0, 0)</code>, который позволяет легко выводить кадры <code>&lt;video&gt;</code> на элемент <code>&lt;canvas&gt;</code>. Конечно, теперь, когда появилась возможность ввода видео с помощью API <code>getUserMedia()</code>, можно легко создать приложение типа "фотокиоск" для работы с потоковым видео.</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

var video = document.querySelector('video');
var canvas = document.querySelector('canvas');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function snapshot() {
  if (localMediaStream) {
    ctx.drawImage(video, 0, 0);
    // "image/webp" works in Chrome 18. In other browsers, this will fall back to image/png.
    document.querySelector('img').src = canvas.toDataURL('image/webp');
  }
}

video.addEventListener('click', snapshot, false);

// Not showing vendor prefixes or code that works cross-browser.
navigator.getUserMedia({video: true}, function(stream) {
  video.src = window.URL.createObjectURL(stream);
  localMediaStream = stream;
}, onFailSoHard);
</code></pre>
<div style="text-align:center;">
  <video id="screenshot-stream" class="videostream" autoplay></video>
  <img id="screenshot" src="">
  <canvas id="screenshot-canvas" style="display:none;"></canvas>
  <p><button id="screenshot-button">Захват</button> <button id="screenshot-stop-button">Остановить</button></p>
</div>

<h2 id="toc-effects">Применение эффектов</h2>

<h3 id="toc-effects-css">Фильтры CSS</h3>

<p class="notice" style="text-align:center">
Фильтры CSS в настоящее время поддерживаются в "ночных" сборках WebKit и Chrome 18+.
</p>

<p>С помощью <a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">фильтров CSS</a> к элементу <code>&lt;video&gt;</code> при захвате можно применить некоторые эффекты.</p>
<pre class="prettyprint"><code>&lt;style&gt;
video {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.grayscale {
  {% mixin filter: grayscale(1); %}
}
.sepia {
  {% mixin filter: sepia(1); %}
}
.blur {
  {% mixin filter: blur(3px); %}
}
...
&lt;/style&gt;

&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
var idx = 0;
var filters = ['grayscale', 'sepia', 'blur', 'brightness', 'contrast', 'hue-rotate',
              'hue-rotate2', 'hue-rotate3', 'saturate', 'invert', ''];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length]; // loop through filters.
  if (effect) {
    el.classList.add(effect);
  }
}

document.querySelector('video').addEventListener('click', changeFilter, false);
&lt;/script&gt;
</code></pre>
<div style="text-align:center;">
  <video id="cssfilters-stream" class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p>Нажмите видео, чтобы ознакомиться с фильтрами CSS</p>
  <p><button id="capture-button2">Захват видео</button> <button id="stop-button2">Остановить</button></p>
</div>

<h3 id="toc-effects-webgl">Текстуры WebGL</h3>

<p>Один из замечательных примеров использования функций захвата видео – вывод получаемых в режиме реального времени данных в качестве текстуры WebGL. Я абсолютно не разбираюсь в WebGL, поэтому предлагаю вам ознакомиться с <a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">руководством</a> и <a href="http://learningthreejs.com/data/live-video-in-webgl/">демонстрационным примером</a> Джерома Этьена (Jerome Etienne). В нем идет речь о том, как с помощью метода <code>getUserMedia()</code> и скрипта <a href="/tutorials/three/intro/">Three.js</a> выводить потоковое видео в WebGL.</p>
<h2 id="toc-webaudio-api">Использование getUserMedia с API веб-аудио</h2>

<p class="notice" style="text-align:center">
В этом разделе описаны возможные усовершенствования и улучшения этого API.
</p>

<p>У меня есть мечта: встроить AutoTune в браузер, используя только открытые веб-технологии. Она почти осуществима. Уже есть API <code>getUserMedia()</code> для ввода звука с микрофона. Достаточно добавить эффекты реального времени с помощью <a href="/tutorials/webaudio/intro/">API веб-аудио</a>, и все будет готово. Недостает лишь интеграции этих двух решений (<a href="http://crbug.com/112404">crbug.com/112404</a>), хотя <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html">предварительное предложение</a> уже разрабатывается.</p>
<p>Передача сигнала микрофона в API веб-аудио, <em>возможно</em>, будет когда-нибудь происходить так, как показано ниже.</p>
<pre class="prettyprint"><code>var context = new window.webkitAudioContext();

navigator.webkitGetUserMedia({audio: true}, function(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();

  // microphone -&gt; filter -&gt; destination.
  microphone.connect(filter);
  filter.connect(context.destination);
}, onFailSoHard);
</code></pre>
<p>Чтобы увидеть, как API <code>getUserMedia()</code> связывается с API веб-аудио, зайдите на сайт <a href="http://crbug.com/112404">crbug.com/112404</a>.</p>
<h2 id="toc-conclusion">Выводы</h2>

<p>В целом удаленный доступ к устройствам через Интернет всегда был достаточно сложной задачей. Многие <a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">пробовали</a> решить ее, но мало кому удавалось это сделать. Большинство решений никогда не выходило за рамки проприетарного программного обеспечения, поэтому они не получили широкого распространения.</p>
<p>Настоящая проблема заключается в том, что модель безопасности для веб-приложений <em>сильно</em> отличается от традиционной. Лично мне не хотелось бы, чтобы доступ к моей камере был у первого попавшегося сайта. Решить этот вопрос довольно сложно.</p>
<p>Объединенные платформы, например <a href="http://phonegap.com/">PhoneGap</a>, помогли раздвинуть границы возможного, но это лишь начало, и такое решение является временным. Чтобы веб-приложения могли успешно конкурировать с традиционными решениями, им необходим доступ к аппаратному обеспечению компьютеров.</p>
<p>API <code>getUserMedia()</code> является первой попыткой доступа к новому типу устройств. Надеюсь, что в ближайшем будущем появятся и другие решения.</p>
<h2 id="toc-resources">Дополнительные ресурсы</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">Спецификация W3C</a>.</li>
<li>Статья Брюса Лоусона (Bruce Lawson) <a href="http://html5doctor.com/getusermedia/">HTML5Doctor</a>.</li>
<li>Статья Брюса Лоусона (Bruce Lawson) <a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">dev.opera.com</a>.</li>
</ul>
<h3 id="toc-demos">Демонстрационные примеры</h3>

<ul>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">Фотокиоск</a></li>
<li>Пол Нив. <a href="http://neave.com/webcam/html5/">Эффекты камеры WebGL</a></li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">Потоковое видео в WebGL</a></li>
</ul>
<script>
function onFailSoHard(e) {
  alert('getUserMedia() not supported in your browser.');
  e.target.src = 'http://www.html5rocks.com/en/tutorials/video/basics/Chrome_ImF.ogv';
}

(function() {
var video = document.querySelector('#basic-stream');
var button = document.querySelector('#capture-button');
var localMediaStream = null;

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#screenshot-stream');
var button = document.querySelector('#screenshot-button');
var canvas = document.querySelector('#screenshot-canvas');
var img = document.querySelector('#screenshot');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function sizeCanvas() {
  // video.onloadedmetadata not firing in Chrome. See crbug.com/110938.
  setTimeout(function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    img.height = video.videoHeight;
    img.width = video.videoWidth;
  }, 50);
}

function snapshot() {
  ctx.drawImage(video, 0, 0);
  img.src = canvas.toDataURL('image/webp');
}

button.addEventListener('click', function(e) {
  if (localMediaStream) {
    snapshot();
    return;
  }

if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

video.addEventListener('click', snapshot, false);

document.querySelector('#screenshot-stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#cssfilters-stream');
var button = document.querySelector('#capture-button2');
var localMediaStream = null;

var idx = 0;
var filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate', 'hue-rotate2', 'hue-rotate3',
  'saturate',
  'invert',
  ''
];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length];
  if (effect) {
    el.classList.add(effect);
  }
}

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video, audio', function(stream) {
      video.src = stream;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button2').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);

video.addEventListener('click', changeFilter, false);
})();
</script>
{% endblock %}
