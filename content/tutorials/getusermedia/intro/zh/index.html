{% extends "tutorial.html" %}
{% load mixin from templatefilters %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
.videostream, #cssfilters-stream {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
#screenshot-stream {
  width: initial;
  height: initial;
}
#screenshot {
  vertical-align: top;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1)
  -o-filter: invert(1)
  -ms-filter: invert(1)
  filter: invert(1)
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="本文由 HTML5 音频/视频强力驱动" title="本文由 HTML5 音频/视频强力驱动"  />
{% endblock %}

{% block content %}

<p>{% include "warning.html" %}</p>
<h2 id="toc-into">简介</h2>

<p>长久以来，音频/视频捕获都是网络开发中的“圣杯”。<em></em>多年来，我们总是依赖于浏览器插件（<a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> 或 <a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a>）实现这一点。<a href="https://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">快来看看吧</a>！</p>
<p>现在轮到 HTML5 大显身手了。也许看起来不是很显眼，但是 HTML5 的崛起引发了对设备硬件访问的激增。<a href="/tutorials/geolocation/trip_meter/">地理位置</a> (GPS)、<a href="/tut rials/device/orientation/">Orientation API</a>（加速计）、<a href="/tutorials/webgl/shaders/">WebGL</a> (GPU) 和 <a href="/tutorials/webaudio/intro/">Web Audio API</a>（视频硬件）都是很好的例子。这些功能非常强大，展示了基于系统底层硬件功能之上的高级 JavaScript API。</p>
<p>本教程介绍了一种新 API：<a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html"><code>navigator.getUserMedia()</code></a>，可让网络应用访问用户的相机和麦克风。</p>
<h2 id="toc-history">getUserMedia() 的历史</h2>

<p>如果您还不知道，<code>getUserMedia()</code> 的历史可谓一段有趣的故事。</p>
<p>过去几年中出现过好几种“Media Capture API”的变体。很多人意识到，需要能够在网络上访问本地设备，但这要所有人合力开发出一种新的规范。局面一片混乱，以至于 W3C 最终决定成立一个工作组。他们只有一个目的：理清混乱的局面！<a href="http://www.w3.org/2009/dap/">设备 API 政策 (DAP) 工作组</a>负责对过剩的提议进行统一和标准化。</p>
<p>我会试着总结一下 2011 所发生的事情...</p>
<h3 id="toc-round1">第 1 轮：HTML 媒体捕获</h3>

<p><a href="http://dev.w3.org/2009/dap/camera/">HTML 媒体捕获</a>是 DAP 在网络媒体捕获标准化上迈出的第一步。具体方法是超载 <code>&lt;input type="file"&gt;</code> 并为 <code>accept</code> 参数添加新值。</p>
<p>如果您要让用户通过网络摄像头拍摄自己的快照，就可以使用 <code>capture=camera</code>：</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>录制视频或音频也是类似的：</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>挺不错吧？它可以重复使用文件输入，这点我特别喜欢。这在语义上非常有意义。这种特定“API”的不足之处在于，无法处理即时效果（例如将实时网络摄像头数据呈现到 <code>&lt;canvas&gt;</code> 并应用 WebGL 过滤器）。HTML 媒体捕获只能让您录制媒体文件或及时拍摄快照。</p>
<p><strong>支持</strong>：</p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Android 3.0 浏览器</a> - 首次实施的一个例子。请观看<a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">此视频</a>，了解其实际使用情况。</li>
<li>Android 版 Chrome 浏览器 (0.16)</li>
</ul>
<p>除非您使用的是以上某个移动浏览器，否则我建议您不要使用该 API。供应商纷纷转向 <code>getUserMedia()</code>。其他任何人都不太可能会长期实施 HTML 媒体捕获。</p>
<h3 id="toc-round2">第 2 轮：设备元素</h3>

<p>很多人认为 HTML 媒体捕获的局限性太大，因此一种新的规范应运而生，可以支持任何类型的（未来）设备。不出意料地，该设计需要新的 <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code> 元素</a>，也就是 <code>getUserMedia()</code> 的前身。</p>
<p>Opera 是第一批根据 <code>&lt;device&gt;</code> 元素创建视频捕获的<a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">初始实施</a>的浏览器之一。不久之后（准确地说是<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">同一天</a>），WhatWG 决定废止 <code>&lt;device&gt;</code> 标记，以支持称为 <code>navigator.getUserMedia()</code> 的新兴 JavaScript API。一周后，Opera 推出的新版本中加入了对更新的 <code>getUserMedia()</code> 规范的支持。当年年底，Microsoft 也加入这一行列，发布了 <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">IE9 实验室</a>以支持新规范。</p>
<p><code>&lt;device&gt;</code> 的效果如下：</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>支持</strong>：</p>
<p>很遗憾，已发布的浏览器中没有任何一款曾经包含 <code>&lt;device&gt;</code>。我猜这是一个不太需要担心的 API。但是 <code>&lt;device&gt;</code> 确实有两大优点：一是语义方面，二是可以轻松进行扩展，而不仅仅是支持音频/视频设备。</p>
<p>现在深吸一口气。这玩意儿速度飞快！</p>
<h3 id="toc-round3">第 3 轮：WebRTC</h3>

<p><code>&lt;device&gt;</code> 元素最终还是像渡渡鸟一样销声匿迹了。</p>
<p>依靠 <a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html">WebRTC</a>（网络即时通信）的大力协助，最近几个月寻找合适捕获 API 的步伐加快了很多。该规范由 <a href="http://www.w3.org/2011/04/webrtc/">W3C WebRTC 工作组</a>负责监管。Google、Opera、Mozilla 和<a href="http://webrtc.org">其他一些公司</a>目前正致力于在自己的浏览器中实施该 API。</p>
<p><code>getUserMedia()</code> 与 WebRTC 相关，因为它是通向这组 API 的门户。它提供了访问用户本地相机/麦克风媒体流的手段。</p>
<p><strong>支持</strong>：</p>
<p>在 Chrome 浏览器 18.0.1008 和更高版本中，可在 <code>about:flags</code> 下启用 WebRTC。</p>
<h2 id="toc-gettingstarted">使用入门</h2>

<p>利用 <code>navigator.getUserMedia()</code>，我们最终实现了在没有插件的情况下访问网络摄像头和麦克风输入内容。相机访问权限现在和调用有关，而不是和安装有关。它直接内嵌在浏览器中。感到兴奋了吗？</p>
<h3 id="toc-enabling">启用</h3>

<p><code>getUserMedia()</code> API 还很新，只有 Google 和 Opera 在开发人员版本中加入了它。在 Chrome 18 和更高版本中，可通过访问 <code>about:flags</code> 启用该 API。</p>
<p><figure>
<img src="aboutflags.png">
<figcaption>在 Chrome 浏览器的 <code>about:flags</code> 页中启用 <code>getUserMedia()</code>。</figcaption>
</figure></p>
<p>对于 Opera，请下载某个实验性 <a href="http://dev.opera.com/articles/view/labs-more-fun-using-the-web-with-getusermedia-and-native-pages/">Android 和桌面计算机版本</a>。</p>
<h3 id="toc-featuredecting">功能检测</h3>

<p>功能检测是简单地检查是否存在 <code>navigator.getUserMedia</code>：</p>
<pre class="prettyprint"><code>function hasGetUserMedia() {
  // Note: Opera builds are unprefixed.
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
}

if (hasGetUserMedia()) {
  // Good to go!
} else {
  alert('getUserMedia() is not supported in your browser');
}
</code></pre>
<h3 id="toc-acccess">获取输入设备的访问权限：</h3>

<p>要使用网络摄像头或麦克风，我们需要请求权限。<code>getUserMedia()</code> 的第一个参数用于指定您要访问的媒体类型。例如，如果您要请求访问网络摄像头，第一个参数就应该是 <code>"video"</code>。要同时使用麦克风和相机，则传递 <code>"video, audio"</code>：</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var onFailSoHard = function(e) {
    console.log('Reeeejected!', e);
  };

  // Not showing vendor prefixes.
  navigator.getUserMedia('video, audio', function(localMediaStream) {
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(localMediaStream);

    // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
    // See crbug.com/110938.
    video.onloadedmetadata = function(e) {
      // Ready to go. Do some stuff.
    };
  }, onFailSoHard);
&lt;/script&gt;
</code></pre>
<p>好吧，这到底是怎么一回事呢？媒体捕获是各种新 HTML5 API 进行协作的绝佳示例。参与协作的还有其他一些 HTML 元素，例如 <code>&lt;audio&gt;</code> 和 <code>&lt;video&gt;</code>。请注意，我们不是要设置 <code>src</code> 属性或在 <code>&lt;video&gt;</code> 元素中加入 <code>&lt;source&gt;</code> 元素。我们不会向视频馈入媒体文件的网址，而是馈入从代表网络摄像头的 <code>LocalMediaStream</code> 对象获得的 <a href="/tutorials/workers/basics/#toc-inlineworkers-bloburis">Blob 网址</a>。</p>
<p>我还会将 <code>&lt;video&gt;</code> 设置为 <code>autoplay</code>，否则它会停在第一帧。添加 <code>controls</code> 也能达到您预期的效果。</p>
<p class="notice" style="text-align:center">
<strong>请注意</strong>：在 Chrome 浏览器中存在一个错误，导致仅仅传递“audio”无效：<a href="http://crbug.com/112367">crbug.com/112367</a>。我也无法在 Opera 中正常使用 <code>&lt;audio&gt;</code>。
</p>

<p>Opera 和 Chrome 浏览器实施的是<a href="getusermedia-spec">该规范</a>的不同版本。这导致实际使用起来要比预期的更有“挑战性”。</p>
<p><strong>在 Chrome 浏览器中</strong>：</p>
<p>该代码段适用于 <span class="browser chrome supported" style="float:none;display:inline-block;"><span class="browser_name">Chrome</span></span> 18 和更高版本（在 <code>about:flags</code> 中启用）：</p>
<pre class="prettyprint"><code>navigator.webkitGetUserMedia('audio, video', function(localMediaStream) {
  var video = document.querySelector('video');
  video.src = window.webkitURL.createObjectURL(localMediaStream);
}, onFailSoHard);
</code></pre>
<p><strong>在 Opera 中</strong>：</p>
<p>Opera 开发人员版本不支持该规范的更新版本。该代码段适用于 <span class="browser opera supported" style="float:none;display:inline-block;"><span class="browser_name">Opera</span></span>：</p>
<pre class="prettyprint"><code>navigator.getUserMedia({audio: true, video: true}, function(localMediaStream) {
  video.src = localMediaStream;
}, onFailSoHard);
</code></pre>
<p>关键的区别之处在于：</p>
<ul>
<li><code>getUserMedia()</code> 是无前缀的。</li>
<li>对象作为第一个参数而不是字符串列表进行传递。</li>
<li>将 <code>video.src</code> 直接设置为 <code>LocalMediaStream</code> 对象，而不是 Blob 网址。据我所知，Opera 最终会更新此设置，改为要求 Blob 网址。</li>
</ul>
<p><strong>对于这两者</strong>：</p>
<p>如果您希望能跨浏览器通用（但是这样很容易出问题），请尝试如下方法：</p>
<pre class="prettyprint"><code>var video = document.querySelector('video');

if (navigator.getUserMedia) {
  navigator.getUserMedia({audio: true, video: true}, function(stream) {
    video.src = stream;
  }, onFailSoHard);
} else if (navigator.webkitGetUserMedia) {
  navigator.webkitGetUserMedia('audio, video', function(stream) {
    video.src = window.webkitURL.createObjectURL(stream);
  }, onFailSoHard);
} else {
  video.src = 'somevideo.webm'; // fallback.
}
</code></pre>
<p>请务必查看 <a href="http://twitter.com/miketaylr">Mike Taylor</a> 和 <a href="http://twitter.com/akamike">Mike Robinson</a> 的 <a href="https://gist.github.com/f2ac64ed7fc467ccdfe3">gUM Shield</a>。它可以很好地将各浏览器实施之间的不一致“标准化”。</p>
<h3 id="toc-security">安全</h3>

<p>将来，浏览器在调用 <code>getUserMedia()</code> 时可能会弹出信息栏，让用户选择授予还是拒绝对其相机/麦克风的访问权限。很遗憾，该规范在安全方面非常薄弱。目前，没有任何浏览器实施了权限栏。</p>
<h3 id="toc-fallback">提供回退</h3>

<p>对于无法获得 <code>getUserMedia()</code> 支持的用户，如果 API 不受支持且/或由于某些原因而调用失败，可以选择回退到现有的视频文件：</p>
<pre class="prettyprint"><code>// Not showing vendor prefixes or code that works cross-browser:

function fallback(e) {
  video.src = 'fallbackvideo.webm';
}

function success(stream) {
  video.src = window.URL.createObjectURL(stream);
}

if (!navigator.getUserMedia) {
  fallback();
} else {
  navigator.getUserMedia({video: true}, success, fallback);
}
</code></pre>
<h3 id="toc-basic-demo">基本演示</h3>

<div style="text-align:center;">
  <video id="basic-stream" class="videostream" autoplay></video>
  <p><button id="capture-button">捕获视频</button> <button id="stop-button">停止</button></p>
</div>

<h2 id="toc-screenshot">截取屏幕截图：</h2>

<p><code>&lt;canvas&gt;</code> API 的 <code>ctx.drawImage(video, 0, 0)</code> 方法可以轻松地将 <code>&lt;video&gt;</code> 帧绘制到 <code>&lt;canvas&gt;</code> 上。当然，既然我们通过 <code>getUserMedia()</code> 获得了视频输入，就可轻松地使用即时视频创建照相亭应用了。</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

var video = document.querySelector('video');
var canvas = document.querySelector('canvas');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function snapshot() {
  if (localMediaStream) {
    ctx.drawImage(video, 0, 0);
    // "image/webp" works in Chrome 18. In other browsers, this will fall back to image/png.
    document.querySelector('img').src = canvas.toDataURL('image/webp');
  }
}

video.addEventListener('click', snapshot, false);

// Not showing vendor prefixes or code that works cross-browser.
navigator.getUserMedia({video: true}, function(stream) {
  video.src = window.URL.createObjectURL(stream);
  localMediaStream = stream;
}, onFailSoHard);
</code></pre>
<div style="text-align:center;">
  <video id="screenshot-stream" class="videostream" autoplay></video>
  <img id="screenshot" src="">
  <canvas id="screenshot-canvas" style="display:none;"></canvas>
  <p><button id="screenshot-button">捕获</button> <button id="screenshot-stop-button">停止</button></p>
</div>

<h2 id="toc-effects">应用效果</h2>

<h3 id="toc-effects-css">CSS 过滤器</h3>

<p class="notice" style="text-align:center">
目前，WebKit Nightlies 版以及 Chrome 浏览器 18 和更高版本支持 CSS 过滤器。
</p>

<p>使用 <a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">CSS 过滤器</a>，我们可以在捕获 <code>&lt;video&gt;</code> 时应用一些很棒的效果：</p>
<pre class="prettyprint"><code>&lt;style&gt;
video {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.grayscale {
  {% mixin filter: grayscale(1); %}
}
.sepia {
  {% mixin filter: sepia(1); %}
}
.blur {
  {% mixin filter: blur(3px); %}
}
...
&lt;/style&gt;

&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
var idx = 0;
var filters = ['grayscale', 'sepia', 'blur', 'brightness', 'contrast', 'hue-rotate',
               'hue-rotate2', 'hue-rotate3', 'saturate', 'invert', ''];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length]; // loop through filters.
  if (effect) {
    el.classList.add(effect);
  }
}

document.querySelector('video').addEventListener('click', changeFilter, false);
&lt;/script&gt;
</code></pre>
<div style="text-align:center;">
  <video id="cssfilters-stream" class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p>点击视频可在各 CSS 过滤器之间循环</p>
  <p><button id="capture-button2">捕获视频</button> <button id="stop-button2">停止</button></p>
</div>

<h3 id="toc-effects-webgl">WebGL 纹理</h3>

<p>视频捕获的一个精彩用例就是以 WebGL 纹理的形式呈现实时输入。由于我对 WebGL 一无所知（除了知道它很好），我建议您看看杰罗姆·艾蒂安 (Jerome Etienne) 的<a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">教程</a>和<a href="http://learningthreejs.com/data/live-video-in-webgl/">演示</a>。其中介绍了如何使用 <code>getUserMedia()</code> 和 <a href="/tutorials/three/intro/">Three.js</a> 将直播视频呈现到 WebGL 中。</p>
<h2 id="toc-webaudio-api">通过 Web Audio API 使用 getUserMedia</h2>

<p class="notice" style="text-align:center">
这部分介绍了当前 API 可能在未来做出的改进和扩展。
</p>

<p>我有一个梦想，就是只通过开放网络技术在浏览器中构建 AutoTune！这个梦想很快就要实现了。对于麦克风输入，我们已经有了 <code>getUserMedia()</code>。通过 <a href="/tutorials/webaudio/intro/">Web Audio API</a> 加入即时效果，我们就大功告成了。将以上两者结合就完成了拼图的最后一块 (<a href="http://crbug.com/112404">crbug.com/112404</a>)，但是在工作中还要实现一个<a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html">初步提议</a>。</p>
<p>有朝一日，将麦克风输入输送到 Web Audio API 可能会是这样的：<em></em></p>
<pre class="prettyprint"><code>var context = new window.webkitAudioContext();

navigator.webkitGetUserMedia({audio: true}, function(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();

  // microphone -&gt; filter -&gt; destination.
  microphone.connect(filter);
  filter.connect(context.destination);
}, onFailSoHard);
</code></pre>
<p>如果您希望将 <code>getUserMedia()</code> 与 Web Audio API 结合在一起，请访问 <a href="http://crbug.com/112404">crbug.com/112404</a>。</p>
<h2 id="toc-conclusion">总结</h2>

<p>总体而言，网络上的设备访问向来是一大难题。很多<a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">人曾经尝试过</a>，但是没什么人取得成功。大多数早期的思路从未在专有环境之外占据主导地位，也从未广泛采用过。</p>
<p>真正的问题在于，网络的安全模式与本地系统有天壤之别。<em></em>例如，我可能不希望随便什么网站都有权访问我的摄像机，但是这个问题很难解决。</p>
<p><a href="http://phonegap.com/">PhoneGap</a> 等桥接框架有助于突破这方面的限制，但这种临时性的解决方案对于深层的根本问题而言还远远不够。要让网络应用具备与桌面计算机应用一较高下的实力，我们需要能够访问本地设备。</p>
<p><code>getUserMedia()</code> 仅仅是对新设备类型的第一波访问。我希望在不久的将来能看到更多。</p>
<h2 id="toc-resources">其他资源</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">W3C 规范</a></li>
<li>布鲁斯·劳森 (Bruce Lawson) 的 <a href="http://html5doctor.com/getusermedia/">HTML5Doctor 文章</a></li>
<li>布鲁斯·劳森的 <a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">dev.opera.com 文章</a></li>
</ul>
<h3 id="toc-demos">演示</h3>

<ul>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">实时照相亭</a></li>
<li>保罗·尼夫 (Paul Neave) 的 <a href="http://neave.com/webcam/html5/">WebGL 相机效果</a></li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">WebGL 中的直播视频</a></li>
</ul>
<script>
function onFailSoHard(e) {
  alert('getUserMedia() not supported in your browser.');
  e.target.src = 'http://www.html5rocks.com/en/tutorials/video/basics/Chrome_ImF.ogv';
}

(function() {
var video = document.querySelector('#basic-stream');
var button = document.querySelector('#capture-button');
var localMediaStream = null;

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#screenshot-stream');
var button = document.querySelector('#screenshot-button');
var canvas = document.querySelector('#screenshot-canvas');
var img = document.querySelector('#screenshot');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function sizeCanvas() {
  // video.onloadedmetadata not firing in Chrome. See crbug.com/110938.
  setTimeout(function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    img.height = video.videoHeight;
    img.width = video.videoWidth;
  }, 50);
}

function snapshot() {
  ctx.drawImage(video, 0, 0);
  img.src = canvas.toDataURL('image/webp');
}

button.addEventListener('click', function(e) {
  if (localMediaStream) {
    snapshot();
    return;
  }

if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

video.addEventListener('click', snapshot, false);

document.querySelector('#screenshot-stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#cssfilters-stream');
var button = document.querySelector('#capture-button2');
var localMediaStream = null;

var idx = 0;
var filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate', 'hue-rotate2', 'hue-rotate3',
  'saturate',
  'invert',
  ''
];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length];
  if (effect) {
    el.classList.add(effect);
  }
}

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video, audio', function(stream) {
      video.src = stream;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button2').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);

video.addEventListener('click', changeFilter, false);
})();
</script>
{% endblock %}
