{% extends "tutorial.html" %}
{% load mixin from templatefilters %}
{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
.videostream, #cssfilters-stream {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
#screenshot-stream {
  width: initial;
  height: initial;
}
#screenshot {
  vertical-align: top;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1)
  -o-filter: invert(1)
  -ms-filter: invert(1)
  filter: invert(1)
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="Dieser Artikel wird unterstützt von HTML5 Audio/Video" title="Dieser Artikel wird unterstützt von HTML5 Audio?/Video"  />
{% endblock %}

{% block content %}

<p>{% include "warning.html" %}</p>
<h2 id="toc-into">Einführung</h2>

<p>Die Aufnahme von Audio und Video ist bereits seit längerem <em>das</em> Nonplusultra in der Webentwicklung. Viele Jahre lang mussten wir uns auf die Browser-Plug-ins <a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> oder <a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a> verlassen, um unsere Aufgaben zu erledigen. <a href="https://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">Come on!</a></p>
<p>Aber jetzt kommt HTML5. Vielleicht ist es nicht offensichtlich, aber der Anstieg bei HTML5 hat zu einem gesteigerten Zugriff auf Gerätehardware geführt. <a href="/tutorials/geolocation/trip_meter/">Geolocation</a> (GPS), das <a href="/tutorials/device/orientation/">Orientation API</a> (Beschleunigungsmesser), <a href="/tutorials/webgl/shaders/">WebGL</a> (GPU) sowie das <a href="/tutorials/webaudio/intro/">Web Audio API</a> (Audio-Hardware) sind hierfür die perfekten Beispiele. Diese Funktionen sind enorm leistungsstark und nutzen anspruchsvolle JavaScript-APIs, die auf den grundlegenden Hardwarefähigkeiten des Systems beruhen.</p>
<p>In dieser Anleitung wird ein neues API vorgestellt, <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html"><code>navigator.getUserMedia()</code></a>, mit der Webanwendungen auf die Kamera und das Mikrofon eines Nutzers zugreifen können.</p>
<h2 id="toc-history">Der Weg zu getUserMedia()</h2>

<p>Wenn Sie die bisherige Geschichte nicht kennen, wird es Sie bestimmt interessieren, wie wir zum <code>getUserMedia()</code>-API gelangt sind.</p>
<p>Über die letzten Jahre hinweg wurden mehrere "Media Capture APIs" entwickelt. Viele Leute erkannten, dass es notwendig ist, auf native Geräte im Web zugreifen zu können. Dadurch entwickelte dann aber jeder neue Spezifikationen. Das Durcheinander war so groß, dass sich W3C schließlich zur Gründung einer Arbeitsgruppe entschloss. Deren Aufgabe war es einzig und allein, ein wenig Ordnung in dieses Chaos zu bringen. Die <a href="http://www.w3.org/2009/dap/">Device APIs Policy (DAP) Working Group</a> macht sich die Standardisierung einer Vielzahl von Vorschlägen zur Aufgabe.</p>
<p>Ich versuche zusammenzufassen, was im Jahr 2011 passierte...</p>
<h3 id="toc-round1">1. Runde: HTML Media Capture</h3>

<p><a href="http://dev.w3.org/2009/dap/camera/">HTML Media Capture</a> war der erste Versuch der DAP zur Standardisierung der Medienaufnahme im Internet. Dabei wird <code>&lt;input type="file"&gt;</code> überlastet und es werden neue Werte für den Parameter <code>accept</code> hinzugefügt.</p>
<p>Wenn Sie zulassen möchten, dass Nutzer mit der Webcam einen Schnappschuss von sich selbst machen, ist das mit <code>capture=camera</code> möglich:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>Ebenso gelingt das Aufzeichnen von Video oder Audio:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>Ganz nett, oder? Mir gefällt vor allem, dass eine Dateieingabe verwendet wird. Semantisch ist das sehr sinnvoll. Leider bietet dieses bestimmte API keine Möglichkeit für Echtzeiteffekte, z. B. das Darstellen von Live-Webcam-Daten in einem <code>&lt;canvas&gt;</code> und die Anwendung von WebGL-Filtern. HTML Media Capture ermöglicht lediglich die Aufnahme einer Mediendatei oder das Erstellen einer Momentaufnahme.</p>
<p><strong>Support:</strong></p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Android 3.0-Browser</a> &ndash; eine der ersten Implementierungen. Sehen Sie sich in <a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">diesem Video</a> an, wie das funktioniert.</li>
<li>Chrome für Android (0.16)</li>
</ul>
<p>Ich empfehle Ihnen, diese Option nicht zu nutzen, es sei denn, sie arbeiten mit einem der zuvor erwähnten mobilen Browser. Immer mehr Anbieter entscheiden sich für <code>getUserMedia()</code>. Es ist sehr unwahrscheinlich, dass HTML Media Capture langfristig weiterhin eingesetzt wird.</p>
<h3 id="toc-round2">2. Runde: device-Element</h3>

<p>Viele waren der Ansicht, dass HTML Media Capture zu viele Einschränkungen mit sich brachte. Daher erschien eine neue Spezifikation, die alle künftigen Geräte unterstützen sollte. Natürlich verlangte das neue Design nach einem neuen Element, dem <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code>-Element</a>, das zum Vorgänger von <code>getUserMedia()</code> wurde.</p>
<p>Opera war der erste Browser, der <a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">anfängliche Implementierungen</a> von Videoaufnahmen auf Grundlage des <code>&lt;device&gt;</code>-Elements erstellte. Kurz danach (<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">am selben Tag,</a> um genau zu sein) entschied die WhatWG, das <code>&lt;device&gt;</code>-Tag aufzugeben und stattdessen einen Newcomer zu verwenden. Hierbei handelte es sich um ein JavaScript-API mit dem Namen <code>navigator.getUserMedia()</code>. Eine Woche später veröffentlichte Opera neue Builds, die die aktualisierte <code>getUserMedia()</code>-Spezifikation unterstützten. Später in diesem Jahr stieß Microsoft hinzu und veröffentlichte ein <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">Lab for IE9</a>, das die neue Spezifikation unterstützte.</p>
<p>So hätte die <code>&lt;device&gt;</code> ausgesehen:</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>Support:</strong></p>
<p>Leider hat kein veröffentlichter Browser jemals <code>&lt;device&gt;</code> enthalten. Nun ja, eigentlich ist es ein API weniger, über das man sich Gedanken machen muss. :) <code>&lt;device&gt;</code> bot jedoch zwei herausragende Vorteile: 1.) Es war semantisch und 2.) es ließ sich ganz leicht erweitern, um mehr als lediglich Audio- und Videogeräte zu unterstützen.</p>
<p>Atmen Sie mal tief durch. Diese Entwicklung geht wirklich in rasender Geschwindigkeit voran.</p>
<h3 id="toc-round3">3. Runde: WebRTC</h3>

<p>Das <code>&lt;device&gt;</code>-Element ging schließlich den Weg alles Irdischen.</p>
<p>In den letzten Monaten wurde die Suche nach einem passenden Capture API aufgrund einer größeren Initiative namens <a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html">WebRTC</a> (Web Real Time Communications) noch weiter vorangetrieben. Die Spezifikation wird von der <a href="http://www.w3.org/2011/04/webrtc/">W3C WebRTC Working Group</a> überwacht. Google, Opera, Mozilla und <a href="http://webrtc.org">ein paar andere</a> arbeiten aktuell an Implementationen in ihren Browsern.</p>
<p><code>getUserMedia()</code> bezieht sich auf WebRTC, da es das Gateway in diesem Satz von APIs darstellt. Es bietet die Möglichkeit für den Zugriff auf den lokalen Kamera-/Mikrofon-Stream des Nutzers.</p>
<p><strong>Support:</strong></p>
<p>WebRTC kann in Chrome 18.0.1008+ unter <code>about:flags</code> aktiviert werden.</p>
<h2 id="toc-gettingstarted">Erste Schritte</h2>

<p>Durch <code>navigator.getUserMedia()</code>, kann endlich die Webcam- und die Mikrofoneingabe ohne Plug-in genutzt werden. Der Kamerazugriff ist nun nur noch einen Abruf entfernt und es ist keine Installation erforderlich. Alles ist direkt im Browser enthalten. Das gefällt Ihnen, stimmt's?</p>
<h3 id="toc-enabling">Aktivieren</h3>

<p>Das <code>getUserMedia()</code>-API ist immer noch sehr neu. Nur Google und Opera verfügen über Entwickler-Builds, die es enthalten. In Chrome 18+ kann das API unter <code>about:flags</code> aktiviert werden.</p>
<p><figure>
<img src="aboutflags.png">
<figcaption><code>getUserMedia()</code> auf der Chrome-Seite <code>about:flags</code> aktivieren</figcaption>
</figure></p>
<p>Laden Sie für Opera einen der experimentellen <a href="http://dev.opera.com/articles/view/labs-more-fun-using-the-web-with-getusermedia-and-native-pages/">Android- und Desktop-Builds</a> herunter.</p>
<h3 id="toc-featuredecting">Funktionserkennung</h3>

<p>Die Funktionserkennung ist eine einfache Überprüfung des Vorhandenseins von <code>navigator.getUserMedia</code>:</p>
<pre class="prettyprint"><code>function hasGetUserMedia() {
  // Note: Opera builds are unprefixed.
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
}

if (hasGetUserMedia()) {
  // Good to go!
} else {
  alert('getUserMedia() is not supported in your browser');
}
</code></pre>
<h3 id="toc-acccess">Auf ein Eingabegerät zugreifen</h3>

<p>Für die Verwendung der Webcam oder des Mikrofons muss eine Berechtigung angefordert werden. Der erste Parameter für <code>getUserMedia()</code> ist für die Angabe des Medientyps gedacht, auf den Sie zugreifen möchten. Wenn Sie beispielsweise die Webcam anfordern möchten, sollte der erste Parameter <code>"video"</code> lauten. Wenn Sie sowohl das Mikrofon als auch die Kamera verwenden möchten, übergeben Sie <code>"video, audio"</code>:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var onFailSoHard = function(e) {
    console.log('Reeeejected!', e);
  };

  // Not showing vendor prefixes.
  navigator.getUserMedia('video, audio', function(localMediaStream) {
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(localMediaStream);

    // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
    // See crbug.com/110938.
    video.onloadedmetadata = function(e) {
      // Ready to go. Do some stuff.
    };
  }, onFailSoHard);
&lt;/script&gt;
</code></pre>
<p>OK. Was passiert hier also? Die Medienerfassung ist ein ideales Beispiel für die Zusammenarbeit der neuen HTML5-APIs. Sie funktioniert gemeinsam mit den anderen HTML5-Elementen <code>&lt;audio&gt;</code> und <code>&lt;video&gt;</code>. Beachten Sie, dass wir weder ein <code>src</code>-Attribut festlegen, noch <code>&lt;source&gt;</code>-Elemente für das <code>&lt;video&gt;</code>-Element einschließen. Statt einem Video eine URL für eine Mediendatei zuzuweisen, weisen wir eine <a href="/tutorials/workers/basics/#toc-inlineworkers-bloburis">Blob-URL</a> von einem <code>LocalMediaStream</code>-Objekt zu, das die Webcam repräsentiert.</p>
<p>Ich lege für das <code>&lt;video&gt;</code> außerdem <code>autoplay</code> fest, sonst friert es im ersten Frame ein. Das Hinzufügen von <code>controls</code> funktioniert auch wie erwartet.</p>
<p class="notice" style="text-align:center">
<strong>Hinweis:</strong> In Chrome gibt es einen Fehler, durch den die Übergabe von ausschließlich "audio" nicht funktioniert: <a href="http://crbug.com/112367">crbug.com/112367</a>. Ich konnte <code>&lt;audio&gt;</code> auch in Opera nicht zum Funktionieren bringen.
</p>

<p>Sowohl Opera als auch Chrome implementieren verschiedene Versionen der <a href="getusermedia-spec">Spezifikation</a>. Dadurch wird die praktische Verwendung ein wenig "schwieriger" als es letztendlich sein wird.</p>
<p><strong>In Chrome:</strong></p>
<p>Dieses Snippet funktioniert in <span class="browser chrome supported" style="float:none;display:inline-block;"><span class="browser_name">Chrome</span></span> 18+ und wird in <code>about:flags</code> aktiviert:</p>
<pre class="prettyprint"><code>navigator.webkitGetUserMedia('audio, video', function(localMediaStream) {
  var video = document.querySelector('video');
  video.src = window.webkitURL.createObjectURL(localMediaStream);
}, onFailSoHard);
</code></pre>
<p><strong>In Opera:</strong></p>
<p>Die Opera-Entwickler-Builds richten sich gegen eine aktualisierte Version der Spezifikation. Dieses Snippet funktioniert in <span class="browser opera supported" style="float:none;display:inline-block;"><span class="browser_name">Opera</span></span>:</p>
<pre class="prettyprint"><code>navigator.getUserMedia({audio: true, video: true}, function(localMediaStream) {
  video.src = localMediaStream;
}, onFailSoHard);
</code></pre>
<p>Die hauptsächlichen Unterschiede lauten:</p>
<ul>
<li><code>getUserMedia()</code> ist ohne Präfix.</li>
<li>Als erstes Argument wird ein Objekt statt einer Stringliste übergeben.</li>
<li><code>video.src</code> wird direkt auf das <code>LocalMediaStream</code>-Objekt festgelegt statt auf eine Blob-URL. Ich habe erfahren, dass Opera schließlich eine Aktualisierung vornehmen wird, so dass eine Blob-URL erforderlich wird.</li>
</ul>
<p><strong>Bei beiden:</strong></p>
<p>Wenn Sie an einer Lösung interessiert sind, die zwar sehr instabil ist, aber browserübergreifend funktioniert, versuchen Sie Folgendes:</p>
<pre class="prettyprint"><code>var video = document.querySelector('video');

if (navigator.getUserMedia) {
  navigator.getUserMedia({audio: true, video: true}, function(stream) {
    video.src = stream;
  }, onFailSoHard);
} else if (navigator.webkitGetUserMedia) {
  navigator.webkitGetUserMedia('audio, video', function(stream) {
    video.src = window.webkitURL.createObjectURL(stream);
  }, onFailSoHard);
} else {
  video.src = 'somevideo.webm'; // fallback.
}
</code></pre>
<p>Überprüfen Sie unbedingt das <a href="https://gist.github.com/f2ac64ed7fc467ccdfe3">gUM Shield</a> von <a href="http://twitter.com/miketaylr">Mike Taylor</a> und <a href="http://twitter.com/akamike">Mike Robinson</a>. Es "normalisiert" die Inkonsistenzen zwischen Browser-Implementierungen.</p>
<h3 id="toc-security">Sicherheit</h3>

<p>Künftig werden Browser vielleicht eine Infoleiste anzeigen, die <code>getUserMedia()</code> aufruft. So könnten die Nutzer den Zugriff auf ihre Kamera/ihr Mikrofon erlauben oder verweigern. Die Spezifikation ist leider bei der Sicherheit sehr zurückhaltend. Aktuell implementiert niemand eine Berechtigungsleiste.</p>
<h3 id="toc-fallback">Fallback anbieten</h3>

<p>Nutzer, die keine Unterstützung für <code>getUserMedia()</code> haben, können auf eine vorhandene Videodatei zurückgreifen, falls das API nicht unterstützt wird oder wenn die Abfrage aus irgendeinem Grund fehlschlägt:</p>
<pre class="prettyprint"><code>// Not showing vendor prefixes or code that works cross-browser:

function fallback(e) {
  video.src = 'fallbackvideo.webm';
}

function success(stream) {
  video.src = window.URL.createObjectURL(stream);
}

if (!navigator.getUserMedia) {
  fallback();
} else {
  navigator.getUserMedia({video: true}, success, fallback);
}
</code></pre>
<h3 id="toc-basic-demo">Einfache Demo</h3>

<div style="text-align:center;">
  <video id="basic-stream" class="videostream" autoplay></video>
  <p><button id="capture-button">Video aufnehmen</button> <button id="stop-button">Stopp</button></p>
</div>

<h2 id="toc-screenshot">Screenshots erstellen</h2>

<p>Die <code>&lt;canvas&gt;</code> API <code>ctx.drawImage(video, 0, 0)</code>-Methode macht das Zeichnen von <code>&lt;video&gt;</code>-Frames in <code>&lt;canvas&gt;</code> kinderleicht. Jetzt, da wir eine Video-Eingabe über <code>getUserMedia()</code> haben, ist es natürlich genauso einfach, eine Photo Booth-Anwendung mit Videos in Echtzeit zu erstellen:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

var video = document.querySelector('video');
var canvas = document.querySelector('canvas');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function snapshot() {
  if (localMediaStream) {
    ctx.drawImage(video, 0, 0);
    // "image/webp" works in Chrome 18. In other browsers, this will fall back to image/png.
    document.querySelector('img').src = canvas.toDataURL('image/webp');
  }
}

video.addEventListener('click', snapshot, false);

// Not showing vendor prefixes or code that works cross-browser.
navigator.getUserMedia({video: true}, function(stream) {
  video.src = window.URL.createObjectURL(stream);
  localMediaStream = stream;
}, onFailSoHard);
</code></pre>
<div style="text-align:center;">
  <video id="screenshot-stream" class="videostream" autoplay></video>
  <img id="screenshot" src="">
  <canvas id="screenshot-canvas" style="display:none;"></canvas>
  <p><button id="screenshot-button">Aufnehmen</button> <button id="screenshot-stop-button">Stopp</button></p>
</div>

<h2 id="toc-effects">Effekte anwenden</h2>

<h3 id="toc-effects-css">CSS-Filter</h3>

<p class="notice" style="text-align:center">
CSS-Filter werden aktuell in WebKit-Nightly-Versionen und in Chrome 18+ unterstützt.
</p>

<p>Anhand von <a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">CSS-Filtern</a> können Sie dem <code>&lt;video&gt;</code> bei der Aufnahme ein paar raue Effekte hinzufügen:</p>
<pre class="prettyprint"><code>&lt;style&gt;
video {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.grayscale {
  {% mixin filter: grayscale(1); %}
}
.sepia {
  {% mixin filter: sepia(1); %}
}
.blur {
  {% mixin filter: blur(3px); %}
}
...
&lt;/style&gt;

&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
var idx = 0;
var filters = ['grayscale', 'sepia', 'blur', 'brightness', 'contrast', 'hue-rotate',
               'hue-rotate2', 'hue-rotate3', 'saturate', 'invert', ''];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length]; // loop through filters.
  if (effect) {
    el.classList.add(effect);
  }
}

document.querySelector('video').addEventListener('click', changeFilter, false);
&lt;/script&gt;
</code></pre>
<div style="text-align:center;">
  <video id="cssfilters-stream" class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p>Klicken Sie auf das Video, um durch die CSS-Filter zu wechseln.</p>
  <p><button id="capture-button2">Video aufnehmen</button> <button id="stop-button2">Stopp</button></p>
</div>

<h3 id="toc-effects-webgl">WebGL-Texturen</h3>

<p>Ein besonders beeindruckender Einsatzbereich für die Videoaufnahme ist die Darstellung von Live-Aufnahmen als WebGL-Textur. Da ich absolut nichts über WebGL weiß (außer dass es klasse ist), schlage ich vor, Sie sehen sich Jerome Etiennes <a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">Anleitung</a> und <a href="http://learningthreejs.com/data/live-video-in-webgl/">Demo</a> an. Hier wird erläutert, wie Sie mit <code>getUserMedia()</code> und <a href="/tutorials/three/intro/">Three.js</a> Live-Videos in WebGL darstellen.</p>
<h2 id="toc-webaudio-api">getUserMedia mit dem Web Audio API nutzen</h2>

<p class="notice" style="text-align:center">
In diesem Abschnitt werden künftige Verbesserungen und Erweiterungen für das aktuelle API besprochen.
</p>

<p>Ein Traum von mir ist die Integration von AutoTune im Browser ausschließlich mit Open-Web-Technologie! Von dieser Möglichkeit sind wir gar nicht so weit entfernt. Wir nutzen bereits <code>getUserMedia()</code> für die Mikrofoneingabe. Jetzt brauchen wir nur noch das <a href="/tutorials/webaudio/intro/">Web Audio API</a> für die Echtzeit-Effekte &ndash; fertig! Die Integration dieser beiden Elemente fehlt hierbei noch (<a href="http://crbug.com/112404">crbug.com/112404</a>). Aber es gibt bereits einen <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html">vorläufigen Vorschlag</a> für deren Umsetzung.</p>
<p>Die Weiterleitung der Mikrofoneingabe an das Web Audio API <em>könnte</em> künftig wie folgt aussehen:</p>
<pre class="prettyprint"><code>var context = new window.webkitAudioContext();

navigator.webkitGetUserMedia({audio: true}, function(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();

  // microphone -&gt; filter -&gt; destination.
  microphone.connect(filter);
  filter.connect(context.destination);
}, onFailSoHard);
</code></pre>
<p>Wenn Sie <code>getUserMedia()</code> in Verbindung mit dem Web Audio API sehen möchten, markieren Sie <a href="http://crbug.com/112404">crbug.com/112404</a>.</p>
<h2 id="toc-conclusion">Fazit</h2>

<p>Im Allgemeinen kann man sagen, dass der Gerätezugriff im Web ein schwieriges Unterfangen ist. Viele <a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">Nutzer haben es versucht</a>; nur wenige waren dabei erfolgreich. Die meisten der anfänglichen Ideen gelangten niemals an die Öffentlichkeit.</p>
<p>Das eigentliche Problem ist, dass sich das Sicherheitsmodell des Internets <em>sehr</em> stark von der tatsächlichen Welt unterscheidet. Schließlich möchte man wahrscheinlich eher nicht, dass Max Mustermann beliebig Zugriff auf die eigene Videokamera hat. Das ist wirklich ein schwieriges Problem.</p>
<p>Überbrückungs-Frameworks, wie <a href="http://phonegap.com/">PhoneGap</a> tragen dazu bei, neue Möglichkeiten zu schaffen. Sie sind jedoch nur der Anfang und bieten eine vorübergehende Lösung für ein grundlegendes Problem. Damit Webanwendungen mit ihren Desktopentsprechungen mithalten können, benötigen wir Zugriff auf native Geräte.</p>
<p><code>getUserMedia()</code> ist nur die erste Zugriffswelle auf neue Gerätetypen. Ich hoffe, dass wir bald mehr davon sehen!</p>
<h2 id="toc-resources">Zusätzliche Ressourcen</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">W3C-Spezifikation</a></li>
<li>Bruce Lawsons <a href="http://html5doctor.com/getusermedia/">HTML5Doctor-Artikel</a></li>
<li>Bruce Lawsons <a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">dev.opera.com-Artikel</a></li>
</ul>
<h3 id="toc-demos">Demos</h3>

<ul>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">Live Photo Booth</a></li>
<li>Paul Neaves <a href="http://neave.com/webcam/html5/">WebGL Camera Effects</a></li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">Live video in WebGL</a></li>
</ul>
<script>
function onFailSoHard(e) {
  alert('getUserMedia() not supported in your browser.');
  e.target.src = 'http://www.html5rocks.com/en/tutorials/video/basics/Chrome_ImF.ogv';
}

(function() {
var video = document.querySelector('#basic-stream');
var button = document.querySelector('#capture-button');
var localMediaStream = null;

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#screenshot-stream');
var button = document.querySelector('#screenshot-button');
var canvas = document.querySelector('#screenshot-canvas');
var img = document.querySelector('#screenshot');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function sizeCanvas() {
  // video.onloadedmetadata not firing in Chrome. See crbug.com/110938.
  setTimeout(function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    img.height = video.videoHeight;
    img.width = video.videoWidth;
  }, 50);
}

function snapshot() {
  ctx.drawImage(video, 0, 0);
  img.src = canvas.toDataURL('image/webp');
}

button.addEventListener('click', function(e) {
  if (localMediaStream) {
    snapshot();
    return;
  }

if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

video.addEventListener('click', snapshot, false);

document.querySelector('#screenshot-stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#cssfilters-stream');
var button = document.querySelector('#capture-button2');
var localMediaStream = null;

var idx = 0;
var filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate', 'hue-rotate2', 'hue-rotate3',
  'saturate',
  'invert',
  ''
];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length];
  if (effect) {
    el.classList.add(effect);
  }
}

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video, audio', function(stream) {
      video.src = stream;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button2').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);

video.addEventListener('click', changeFilter, false);
})();
</script>
{% endblock %}
