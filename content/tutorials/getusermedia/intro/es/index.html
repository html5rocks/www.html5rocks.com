{% extends "tutorial.html" %}
{% load mixin from templatefilters %}

{% block pagebreadcrumb %}{{ tut.title }}{% endblock %}

{% block head %}
<style>
.videostream, #cssfilters-stream {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
#screenshot-stream {
  width: initial;
  height: initial;
}
#screenshot {
  vertical-align: top;
}
.blur {
  -webkit-filter: blur(3px);
  -moz-filter: blur(3px);
  -o-filter: blur(3px);
  -ms-filter: blur(3px);
  filter: blur(3px);
}
.brightness {
  -webkit-filter: brightness(5);
  -moz-filter: brightness(5);
  -o-filter: brightness(5);
  -ms-filter: brightness(5);
  filter: brightness(5);
}
.contrast {
  -webkit-filter: contrast(8);
  -moz-filter: contrast(8);
  -o-filter: contrast(8);
  -ms-filter: contrast(8);
  filter: contrast(8);
}
.hue-rotate {
  -webkit-filter: hue-rotate(90deg);
  -moz-filter: hue-rotate(90deg);
  -o-filter: hue-rotate(90deg);
  -ms-filter: hue-rotate(90deg);
  filter: hue-rotate(90deg);
}
.hue-rotate2 {
  -webkit-filter: hue-rotate(180deg);
  -moz-filter: hue-rotate(180deg);
  -o-filter: hue-rotate(180deg);
  -ms-filter: hue-rotate(180deg);
  filter: hue-rotate(180deg);
}
.hue-rotate3 {
  -webkit-filter: hue-rotate(270deg);
  -moz-filter: hue-rotate(270deg);
  -o-filter: hue-rotate(270deg);
  -ms-filter: hue-rotate(270deg);
  filter: hue-rotate(270deg);
}
.saturate {
  -webkit-filter: saturate(10);
  -moz-filter: saturate(10);
  -o-filter: saturate(10);
  -ms-filter: saturate(10);
  filter: saturate(10);
}
.grayscale {
  -webkit-filter: grayscale(1);
  -moz-filter: grayscale(1);
  -o-filter: grayscale(1);
  -ms-filter: grayscale(1);
  filter: grayscale(1);
}
.sepia {
  -webkit-filter: sepia(1);
  -moz-filter: sepia(1);
  -o-filter: sepia(1);
  -ms-filter: sepia(1);
  filter: sepia(1);
}
.invert {
  -webkit-filter: invert(1);
  -moz-filter: invert(1)
  -o-filter: invert(1)
  -ms-filter: invert(1)
  filter: invert(1)
}
</style>
{% endblock %}

{% block iscompatible %}
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
{% endblock %}

{% block html5badge %}
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="This article is powered by HTML5 Audio/Video" title="This article is powered by HTML5 Audio?/Video"  />
{% endblock %}

{% block content %}

<p>{% include "warning.html" %}</p>
<h2 id="toc-into">Introducción</h2>

<p>La captura de audio y vídeo ha sido <em>el</em> "Santo Grial" del desarrollo web durante mucho tiempo. Durante muchos años, hemos dependido de los complementos de los navegadores (<a href="http://www.kevinmusselman.com/2009/02/access-webcam-with-flash/">Flash</a> o <a href="http://www.silverlightshow.net/items/Capturing-the-Webcam-in-Silverlight-4.aspx">Silverlight</a>) para hacer el trabajo. <a href="https://www.youtube.com/watch?v=SP_9zH9Q44o" target="_blank">¡Vamos!</a></p>
<p>¡HTML5 al rescate! Puede que no resulte evidente, pero la llegada del HTML5 ha ocasionado un repentino aumento del acceso a dispositivos de hardware. La <a href="/tutorials/geolocation/trip_meter/">geolocalización</a> (GPS), el <a href="/tutorials/device/orientation/">API de orientación</a> (acelerómetro), <a href="/tutorials/webgl/shaders/">WebGL</a> (GPU) y el <a href="/tutorials/webaudio/intro/">API de audio web</a> (hardware de audio) son ejemplos perfectos. Estas funciones son terriblemente potentes, dejando al descubierto las API JavaScript de alto nivel que hay encima de las funciones de hardware subyacentes del sistema.</p>
<p>En este tutorial presentamos una nueva API, <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html"><code>navigator.getUserMedia()</code></a>, que permite a las aplicaciones acceder al micrófono y a la cámara del usuario.</p>
<h2 id="toc-history">El camino hacia getUserMedia()</h2>

<p>La historia sobre cómo llegamos hasta el API <code>getUserMedia()</code> es muy interesante.</p>
<p>Durante los últimos años, han evolucionado varias variantes de las "API de captura multimedia". Muchos compañeros reconocieron la necesidad de poder acceder a dispositivos nativos en la Web, pero eso llevó a muchos a crear nuevas especificaciones. Las cosas se enredaron tanto que al final el W3C decidió formar un grupo de trabajo. ¿Y cuál era su único objetivo? ¡Poner un poco de cordura en toda la locura que se formó! El <a href="http://www.w3.org/2009/dap/">grupo de trabajo de la Política de API de dispositivos</a> recibió la tarea de consolidar y estandarizar ese gran número de propuestas.</p>
<p>Intentaré resumir qué ocurrió en 2011...</p>
<h3 id="toc-round1">Asalto 1: captura multimedia HTML</h3>

<p>La <a href="http://dev.w3.org/2009/dap/camera/">captura multimedia HTML</a> fue el primer intento de la política de API de dispositivos de estandarizar la captura multimedia en Internet. Funciona sobrecargando <code>&lt;input type="file"&gt;</code> y añadiendo nuevos valores para el parámetro <code>accept</code>.</p>
<p><code>capture=camera</code> permite a los usuarios tomar una a instantánea de sí mismos con la cámara web:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="image/*;capture=camera"&gt;
</code></pre>
<p>Para grabar audio o vídeo, el procedimiento es similar:</p>
<pre class="prettyprint"><code>&lt;input type="file" accept="video/*;capture=camcorder"&gt;
&lt;input type="file" accept="audio/*;capture=microphone"&gt;
</code></pre>
<p>No está mal, ¿verdad? Particularmente me gusta que reutilice una entrada de archivo. Semánticamente, tiene mucho sentido. En lo que esta "API" en particular se queda corta es en la capacidad de aplicar efectos en tiempo real (por ejemplo, transferir los datos de la cámara web en directo a <code>&lt;canvas&gt;</code> y aplicar filtros WebGL). La captura multimedia HTML solo permite grabar un archivo multimedia o tomar una instantánea en tiempo real.</p>
<p><strong>Compatibilidad:</strong></p>
<ul>
<li><a href="http://developer.android.com/sdk/android-3.0.html">Navegador Android 3.0</a>, una de las primeras implementaciones. Consulta <a href="http://davidbcalhoun.com/2011/android-3-0-honeycomb-is-first-to-implement-the-device-api">este vídeo</a> para verlo en acción.</li>
<li>Chrome para Android (0.16)</li>
</ul>
<p>Mi recomendación es que te mantengas alejado de esta API, a menos que utilices uno de estos navegadores. Los proveedores se están decantando por <code>getUserMedia()</code>. Es poco probable que nadie más implemente la captura multimedia HTML a largo plazo.</p>
<h3 id="toc-round2">Asalto 2: elemento de dispositivo</h3>

<p>Muchos pensaron que la captura multimedia HTML estaba demasiado limitada, así que surgió una nueva especificación compatible con cualquier tipo de dispositivo (futuro). No es de extrañar que el diseño necesitara un nuevo elemento, <a href="http://dev.w3.org/html5/html-device/"><code>&lt;device&gt;</code></a>, que se convirtió en el predecesor de <code>getUserMedia()</code>.</p>
<p>Opera fue uno de los primeros navegadores en <a href="http://my.opera.com/core/blog/2011/03/14/web-meet-device">implementar</a> capturas de vídeo basadas en el elemento  <code>&lt;device&gt;</code>. Poco después (<a href="http://my.opera.com/core/blog/2011/03/23/webcam-orientation-preview">el mismo día</a> para ser exactos), el WhatWG decidió desechar la etiqueta <code>&lt;device&gt;</code> en favor de otra promesa, esta vez un API JavaScript llamada <code>navigator.getUserMedia()</code>. Una semana después, Opera sacó nuevas compilaciones compatibles con la especificación <code>getUserMedia()</code> actualizada. Más tarde ese año, Microsoft se unió a la fiesta con el lanzamiento de una <a href="http://blogs.msdn.com/b/ie/archive/2011/12/09/media-capture-api-helping-web-developers-directly-import-image-video-and-sound-data-into-web-apps.aspx">implementación para Internet Explorer 9</a> compatible con la nueva especificación.</p>
<p>Este es el aspecto que hubiera tenido <code>&lt;device&gt;</code>:</p>
<pre class="prettyprint"><code>&lt;device type="media" onchange="update(this.data)"&gt;&lt;/device&gt;
&lt;video autoplay&gt;&lt;/video&gt;
&lt;script&gt;
  function update(stream) {
    document.querySelector('video').src = stream.url;
  }
&lt;/script&gt;
</code></pre>
<p><strong>Compatibilidad:</strong></p>
<p>Lamentablemente, ninguno de los navegadores del mercado incluyó nunca <code>&lt;device&gt;</code>. Un API menos de la que preocuparse, supongo :) Pero <code>&lt;device&gt;</code> sí tenía dos grandes cualidades para el éxito: era semántico y se podía ampliar fácilmente para admitir más que solo dispositivos de audio y vídeo.</p>
<p>Respira. ¡Esto va rápido!</p>
<h3 id="toc-round3">Asalto 3: WebRTC</h3>

<p>El elemento <code>&lt;device&gt;</code> terminó quedándose obsoleto.</p>
<p>La carrera por encontrar un API de captura adecuado se ha acelerado en los últimos meses gracias a un proyecto de mayor envergadura llamado <a href="http://dev.w3.org/2011/webrtc/editor/webrtc.html">WebRTC</a> (comunicaciones web en tiempo real). La especificación está supervisada por el <a href="http://www.w3.org/2011/04/webrtc/">grupo de trabajo WebRTC de W3C</a>. Google, Opera, Mozilla y <a href="http://webrtc.org">unos pocos más</a> están trabajando actualmente para incorporar implementaciones en sus navegadores.</p>
<p><code>getUserMedia()</code> está relacionado con WebRTC porque es la puerta de entrada a ese conjunto de API. Proporciona la forma de acceder al flujo de datos de la cámara y del micrófono del usuario.</p>
<p><strong>Compatibilidad:</strong></p>
<p>WebRTC se puede habilitar en Chrome 18.0.1008 y versiones posteriores en la página <code>about:flags</code>.</p>
<h2 id="toc-gettingstarted">Cómo empezar</h2>

<p>Con <code>navigator.getUserMedia()</code>, al fin podemos conectarnos a la entrada del micrófono y de la cámara web sin necesidad de ningún complemento. Ahora se puede acceder a la cámara con solo realizar una llamada, sin tener que instalar nada. Los datos se procesan y se envían directamente al navegador. Emocionante, ¿verdad?</p>
<h3 id="toc-enabling">Dónde se puede habilitar</h3>

<p>El API <code>getUserMedia()</code> aún es muy reciente y se incluye en algunas compilaciones para desarrolladores de Google y Opera. En Chrome 18 y versiones posteriores, el API se puede habilitar en la página <code>about:flags</code>.</p>
<p><figure>
<img src="aboutflags.png">
<figcaption>Opción para habilitar <code>getUserMedia()</code> en la página <code>about:flags</code> de Chrome</figcaption>
</figure></p>
<p>En Opera, descarga una de las <a href="http://dev.opera.com/articles/view/labs-more-fun-using-the-web-with-getusermedia-and-native-pages/">compilaciones experimentales para escritorio y para Android</a>.</p>
<h3 id="toc-featuredecting">Detección de funciones</h3>

<p>La detección de funciones es simplemente una comprobación de la existencia de <code>navigator.getUserMedia</code>:</p>
<pre class="prettyprint"><code>function hasGetUserMedia() {
  // Note: Opera builds are unprefixed.
  return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
}

if (hasGetUserMedia()) {
  // Good to go!
} else {
  alert('getUserMedia() is not supported in your browser');
}
</code></pre>
<h3 id="toc-acccess">Acceso a un dispositivo de entrada</h3>

<p>Para utilizar una cámara web o un micrófono, necesitamos solicitar permiso. El primer parámetro de <code>getUserMedia()</code> es para especificar el tipo de medio al que se quiere acceder. Por ejemplo, si quieres solicitar la cámara web, el primer parámetro debe ser <code>video</code>. Para usar tanto el micrófono como la cámara, utiliza <code>video, audio</code>:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
  var onFailSoHard = function(e) {
    console.log('Reeeejected!', e);
  };

  // Not showing vendor prefixes.
  navigator.getUserMedia('video, audio', function(localMediaStream) {
    var video = document.querySelector('video');
    video.src = window.URL.createObjectURL(localMediaStream);

    // Note: onloadedmetadata doesn't fire in Chrome when using it with getUserMedia.
    // See crbug.com/110938.
    video.onloadedmetadata = function(e) {
      // Ready to go. Do some stuff.
    };
  }, onFailSoHard);
&lt;/script&gt;
</code></pre>
<p>De acuerdo. Entonces, ¿qué está pasando aquí? La captura multimedia es un ejemplo perfecto de nuevas API HTML5 en colaboración. Funciona en combinación con otros miembros de la familia HTML5: <code>&lt;audio&gt;</code> y <code>&lt;video&gt;</code>. Ten en cuenta que no se establece un atributo <code>src</code> ni se incluyen elementos <code>&lt;source&gt;</code> en el elemento <code>&lt;video&gt;</code>. En lugar de dar al vídeo una URL a un archivo multimedia, le estamos dando una <a href="/tutorials/workers/basics/#toc-inlineworkers-bloburis">URL Blob</a> obtenida a partir de un objeto <code>LocalMediaStream</code> que representa a la cámara web.</p>
<p>También le estoy dando al elemento <code>&lt;video&gt;</code> la orden <code>autoplay</code> (reproducción automática), ya que de lo contrario se quedaría congelado en el primer fotograma. Añadir <code>controls</code> también funciona como cabría esperar.</p>
<p class="notice" style="text-align:center">
<strong>Nota:</strong> un error en Chrome hace que no se pueda transmitir solo "audio": <a href="http://crbug.com/112367">crbug.com/112367</a>. Tampoco pude hacer que <code>&lt;audio&gt;</code> funcionara en Opera.
</p>

<p>Tanto Opera como Chrome implementan diferentes versiones de <a href="getusermedia-spec">la especificación</a>. Esto hace que el uso práctico resulte un poco más "desafiante" de lo que será en realidad.</p>
<p><strong>En Chrome:</strong></p>
<p>Este fragmento funciona en <span class="browser chrome supported" style="float:none;display:inline-block;"><span class="browser_name">Chrome</span></span> 18 y en versiones posteriores (se habilita en la página <code>about:flags</code>):</p>
<pre class="prettyprint"><code>navigator.webkitGetUserMedia('audio, video', function(localMediaStream) {
  var video = document.querySelector('video');
  video.src = window.webkitURL.createObjectURL(localMediaStream);
}, onFailSoHard);
</code></pre>
<p><strong>En Opera:</strong></p>
<p>Las compilaciones para desarrolladores de Opera funcionan con una versión actualizada de la especificación. Este fragmento funciona en <span class="browser opera supported" style="float:none;display:inline-block;"><span class="browser_name">Opera</span></span>:</p>
<pre class="prettyprint"><code>navigator.getUserMedia({audio: true, video: true}, function(localMediaStream) {
  video.src = localMediaStream;
}, onFailSoHard);
</code></pre>
<p>Las diferencias clave son:</p>
<ul>
<li><code>getUserMedia()</code> no tiene prefijo.</li>
<li>Un objeto se transmite como el primer argumento en lugar de como una lista de cadenas.</li>
<li><code>video.src</code> se establece directamente en el objeto <code>LocalMediaStream</code> en lugar de en la URL Blob. Me han dicho que Opera terminará por actualizarlo para que requiera una URL Blob.</li>
</ul>
<p><strong>En ambos:</strong></p>
<p>Si quieres algo que funcione en ambos navegadores (pero es muy delicado), prueba esto:</p>
<pre class="prettyprint"><code>var video = document.querySelector('video');

if (navigator.getUserMedia) {
  navigator.getUserMedia({audio: true, video: true}, function(stream) {
    video.src = stream;
  }, onFailSoHard);
} else if (navigator.webkitGetUserMedia) {
  navigator.webkitGetUserMedia('audio, video', function(stream) {
    video.src = window.webkitURL.createObjectURL(stream);
  }, onFailSoHard);
} else {
  video.src = 'somevideo.webm'; // fallback.
}
</code></pre>
<p>No olvides consultar el <a href="https://gist.github.com/f2ac64ed7fc467ccdfe3">gUM Shieldr</a> de <a href="http://twitter.com/akamike">Mike Robinson</a> y <a href="http://twitter.com/miketaylr">Mike Taylor</a>. Realiza un gran trabajo a la hora de "normalizar" las inconsistencias entre las implementaciones de los navegadores.</p>
<h3 id="toc-security">Seguridad</h3>

<p>En el futuro, los navegadores podrían mostrar una barra de información al ejecutar <code>getUserMedia()</code>, lo que daría a los usuarios la opción de otorgar o denegar el permiso a su cámara y su micrófono. Lamentablemente, la especificación es muy reservada en lo referente a seguridad. En estos momentos nadie implementa una barra de permiso.</p>
<h3 id="toc-fallback">Opción alternativa</h3>

<p>Para aquellos usuarios que no pueden utilizar <code>getUserMedia()</code>, una opción es reproducir un archivo de vídeo existente si el API no es compatible o si la llamada falla por algún motivo:</p>
<pre class="prettyprint"><code>// Not showing vendor prefixes or code that works cross-browser:

function fallback(e) {
  video.src = 'fallbackvideo.webm';
}

function success(stream) {
  video.src = window.URL.createObjectURL(stream);
}

if (!navigator.getUserMedia) {
  fallback();
} else {
  navigator.getUserMedia({video: true}, success, fallback);
}
</code></pre>
<h3 id="toc-basic-demo">Demo básica</h3>

<div style="text-align:center;">
  <video id="basic-stream" class="videostream" autoplay></video>
  <p><button id="capture-button">Capturar vídeo</button> <button id="stop-button">Detener</button></p>
</div>

<h2 id="toc-screenshot">Capturas de pantalla</h2>

<p>El método <code>ctx.drawImage(video, 0, 0)</code> del API de <code>&lt;canvas&gt;</code> hace que resulte muy fácil dibujar fotogramas de <code>&lt;video&gt;</code> en <code>&lt;canvas&gt;</code>. Por supuesto, al obtener la entrada de vídeo a través de <code>getUserMedia()</code>, es igual de fácil crear una aplicación tipo Photo Booth con vídeo en tiempo real:</p>
<pre class="prettyprint"><code>&lt;video autoplay&gt;&lt;/video&gt;
&lt;img src=""&gt;
&lt;canvas style="display:none;"&gt;&lt;/canvas&gt;

var video = document.querySelector('video');
var canvas = document.querySelector('canvas');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function snapshot() {
  if (localMediaStream) {
    ctx.drawImage(video, 0, 0);
    // "image/webp" works in Chrome 18. In other browsers, this will fall back to image/png.
    document.querySelector('img').src = canvas.toDataURL('image/webp');
  }
}

video.addEventListener('click', snapshot, false);

// Not showing vendor prefixes or code that works cross-browser.
navigator.getUserMedia({video: true}, function(stream) {
  video.src = window.URL.createObjectURL(stream);
  localMediaStream = stream;
}, onFailSoHard);
</code></pre>
<div style="text-align:center;">
  <video id="screenshot-stream" class="videostream" autoplay></video>
  <img id="screenshot" src="">
  <canvas id="screenshot-canvas" style="display:none;"></canvas>
  <p><button id="screenshot-button">Capturar</button> <button id="screenshot-stop-button">Detener</button></p>
</div>

<h2 id="toc-effects">Aplicación de efectos</h2>

<h3 id="toc-effects-css">Filtros CSS</h3>

<p class="notice" style="text-align:center">
Actualmente pueden utilizar filtros CSS las últimas versiones de WebKit y Chrome 18 y versiones posteriores.
</p>

<p>Con los <a href="https://dvcs.w3.org/hg/FXTF/raw-file/tip/filters/index.html">filtros CSS</a> podemos aplicar algunos efectos asombrosos en <code>&lt;video&gt;</code> mientras se está capturando el vídeo:</p>
<pre class="prettyprint"><code>&lt;style&gt;
video {
  width: 307px;
  height: 250px;
  background: rgba(255,255,255,0.5);
  border: 1px solid #ccc;
}
.grayscale {
  {% mixin filter: grayscale(1); %}
}
.sepia {
  {% mixin filter: sepia(1); %}
}
.blur {
  {% mixin filter: blur(3px); %}
}
...
&lt;/style&gt;

&lt;video autoplay&gt;&lt;/video&gt;

&lt;script&gt;
var idx = 0;
var filters = ['grayscale', 'sepia', 'blur', 'brightness', 'contrast', 'hue-rotate',
               'hue-rotate2', 'hue-rotate3', 'saturate', 'invert', ''];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length]; // loop through filters.
  if (effect) {
    el.classList.add(effect);
  }
}

document.querySelector('video').addEventListener('click', changeFilter, false);
&lt;/script&gt;
</code></pre>
<div style="text-align:center;">
  <video id="cssfilters-stream" class="videostream" autoplay title="Click me to apply CSS Filters" alt="Click me to apply CSS Filters"></video>
  <p>Haz clic en el vídeo para ver todos los filtros CSS.</p>
  <p><button id="capture-button2">Capturar vídeo</button> <button id="stop-button2">Detener</button></p>
</div>

<h3 id="toc-effects-webgl">Texturas WebGL</h3>

<p>Uno de los usos más increíbles de la captura de vídeo es transferir la entrada de vídeo en directo a la textura WebGL. Como yo no sé absolutamente nada de WebGL, voy a sugerirte que le eches un vistazo al <a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">tutorial</a> y a la <a href="http://learningthreejs.com/data/live-video-in-webgl/">demo</a> de Jerome Etienne. Trata sobre cómo utilizar <code>getUserMedia()</code> y <a href="/tutorials/three/intro/">Three.js</a> para transferir vídeo en directo a WebGL.</p>
<h2 id="toc-webaudio-api">Uso de getUserMedia con el API de audio web</h2>

<p class="notice" style="text-align:center">
En esta sección trataremos posibles mejoras y extensiones del API en el futuro.
</p>

<p>Uno de mis sueños es incorporar AutoTune al navegador únicamente con tecnología web de código abierto. En realidad, no estamos muy lejos de poder hacerlo. Ya tenemos <code>getUserMedia()</code> para la entrada de micrófono. Aplica los efectos en tiempo real del <a href="/tutorials/webaudio/intro/">API de audio web</a> y ya está. Lo que falta es integrar ambos (<a href="http://crbug.com/112404">crbug.com/112404</a>), aunque se está trabajando en una <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/webrtc-integration.html">propuesta preliminar</a> para conseguirlo.</p>
<p>Conectar la entrada de micrófono al API de audio web <em>podría</em> ser algo así algún día:</p>
<pre class="prettyprint"><code>var context = new window.webkitAudioContext();

navigator.webkitGetUserMedia({audio: true}, function(stream) {
  var microphone = context.createMediaStreamSource(stream);
  var filter = context.createBiquadFilter();

  // microphone -&gt; filter -&gt; destination.
  microphone.connect(filter);
  filter.connect(context.destination);
}, onFailSoHard);
</code></pre>
<p>Si quieres ver a <code>getUserMedia()</code> conectado al API de audio web, vota por <a href="http://crbug.com/112404">crbug.com/112404</a>.</p>
<h2 id="toc-conclusion">Conclusión</h2>

<p>En general, el acceso a dispositivos en la Web ha sido un hueso duro de roer. <a href="http://www.slideshare.net/jamesgpearce/mobile-device-apis">Muchos lo han intentado</a>, pero pocos lo han conseguido. La mayoría de las primeras ideas nunca han prosperado fuera del entorno del creador ni se han adoptado ampliamente.</p>
<p>El verdadero problema es que el modelo de seguridad de Internet es <em>muy</em> diferente al entorno nativo. Por ejemplo, probablemente no quiero que el sitio web de cualquiera tenga acceso aleatorio a mi cámara de vídeo. Es muy difícil acertar.</p>
<p>Vincular marcos de trabajo como <a href="http://phonegap.com/">PhoneGap</a> ha ayudado a superar barreras, pero es solo un comienzo y una solución temporal a un problema subyacente. Para que las aplicaciones web sean competitivas respecto a las aplicaciones de escritorio, necesitamos acceder a los dispositivos nativos.</p>
<p><code>getUserMedia()</code> solo es el primer intento de acceder a nuevos tipos de dispositivos. Espero que esto siga desarrollándose en un futuro próximo.</p>
<h2 id="toc-resources">Recursos adicionales</h2>

<ul>
<li><a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">Especificación de W3C</a></li>
<li><a href="http://html5doctor.com/getusermedia/">Artículo sobre HTML5Doctor</a> de Bruce Lawson</li>
<li><a href="http://dev.opera.com/articles/view/getusermedia-access-camera-privacy-ui/">Artículo sobre dev.opera.com</a> de Bruce Lawson</li>
</ul>
<h3 id="toc-demos">Demos</h3>

<ul>
<li><a href="http://html5-demos.appspot.com/static/getusermedia/photobooth.html">Live Photo Booth</a></li>
<li><a href="http://neave.com/webcam/html5/">Efectos WebGL para cámara</a> de Paul Neave</li>
<li><a href="http://html5photobooth.com/">Snapster</a></li>
<li><a href="http://learningthreejs.com/data/live-video-in-webgl/">Vídeo en directo en WebGL</a></li>
</ul>
<script>
function onFailSoHard(e) {
  alert('getUserMedia() not supported in your browser.');
  e.target.src = 'http://www.html5rocks.com/en/tutorials/video/basics/Chrome_ImF.ogv';
}

(function() {
var video = document.querySelector('#basic-stream');
var button = document.querySelector('#capture-button');
var localMediaStream = null;

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      video.controls = true;
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#screenshot-stream');
var button = document.querySelector('#screenshot-button');
var canvas = document.querySelector('#screenshot-canvas');
var img = document.querySelector('#screenshot');
var ctx = canvas.getContext('2d');
var localMediaStream = null;

function sizeCanvas() {
  // video.onloadedmetadata not firing in Chrome. See crbug.com/110938.
  setTimeout(function() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    img.height = video.videoHeight;
    img.width = video.videoWidth;
  }, 50);
}

function snapshot() {
  ctx.drawImage(video, 0, 0);
  img.src = canvas.toDataURL('image/webp');
}

button.addEventListener('click', function(e) {
  if (localMediaStream) {
    snapshot();
    return;
  }

if (navigator.getUserMedia) {
    navigator.getUserMedia('video', function(stream) {
      video.src = stream;
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
      sizeCanvas();
      button.textContent = 'Take Shot';
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

video.addEventListener('click', snapshot, false);

document.querySelector('#screenshot-stop-button').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);
})();

(function() {
var video = document.querySelector('#cssfilters-stream');
var button = document.querySelector('#capture-button2');
var localMediaStream = null;

var idx = 0;
var filters = [
  'grayscale',
  'sepia',
  'blur',
  'brightness',
  'contrast',
  'hue-rotate', 'hue-rotate2', 'hue-rotate3',
  'saturate',
  'invert',
  ''
];

function changeFilter(e) {
  var el = e.target;
  el.className = '';
  var effect = filters[idx++ % filters.length];
  if (effect) {
    el.classList.add(effect);
  }
}

button.addEventListener('click', function(e) {
  if (navigator.getUserMedia) {
    navigator.getUserMedia('video, audio', function(stream) {
      video.src = stream;
      localMediaStream = stream;
    }, onFailSoHard);
  } else if (navigator.webkitGetUserMedia) {
    navigator.webkitGetUserMedia('video', function(stream) {
      video.src = window.webkitURL.createObjectURL(stream);
      localMediaStream = stream;
    }, onFailSoHard);
  } else {
    onFailSoHard({target: video});
  }
}, false);

document.querySelector('#stop-button2').addEventListener('click', function(e) {
  video.pause();
  localMediaStream.stop(); // Doesn't do anything in Chrome.
}, false);

video.addEventListener('click', changeFilter, false);
})();
</script>
{% endblock %}
