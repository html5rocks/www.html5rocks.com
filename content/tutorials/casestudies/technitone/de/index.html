{% extends "tutorial.html" %}

{% block head %}{% endblock %}
{% block onload %}{% endblock %}

{% block iscompatible %}
  return !!Modernizr.webgl && !!window.webkitAudioContext;
{% endblock %}


{% block content %}
<section id='main-text'>

<link href='/tutorials/doodles/lem/styles.css' rel='stylesheet'>

<style type="text/css">
/* Removes unwanted "." in color demo inherited from existing stylesheet */
#main-text .illo ul > li::before {
  content: "";
}
#main-text img, #main-text canvas, div.illo.color-mixed {
  display: block;
  margin-right: auto;
  margin-left: auto;
}
#main-text img { max-width: 100%; }
</style>



  <figure>
    <a href="http://www.technitone.com"><img src="assets/images/technitone-article-header.jpg" alt="Technitone – A web audio experience." /></a>
    <figcaption><a href="http://www.technitone.com">Technitone.com</a></figcaption>
  </figure>

  <p><a href="http://www.technitone.com">Technitone.com</a> ist eine Verschmelzung von WebGL, Canvas, Web Sockets, CSS3, JavaScript, Flash und des neuen <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html">Web Audio API</a> in Chrome.</p>

  <p>Dieser Artikel beschäftigt sich mit sämtlichen Aspekten der Produktion: dem Plan, dem Server, den Sounds, den visuellen Elementen und einem Teil des Workflows, den wir zum Design für eine interaktive Erfahrung nutzen. Die meisten Abschnitte enthalten Code-Snippets, eine Demo und einen Download. Am Ende des Artikels finden Sie einen Download-Link, über den Sie alle Demos in einer ZIP-Datei herunterladen können.</p>

  <img src="assets/images/avatars.png" alt="Das gskinner.com-Produktionsteam." />

  <h2 id="toc-thegig">Der Gig.</h2>

  <p>Wir bei gskinner.com sind keineswegs Toningenieure – doch wenn man uns vor eine Herausforderung stellt, können wir nicht widerstehen und arbeiten einen Plan aus:</p>

  <ul style="padding-left:25px">
    <li>Nutzer <a href="http://www.technitone.com/view/68k21dr24vb">zeichnen Klänge in einem Raster ein</a>, "inspiriert" durch die <a href="http://lab.andre-michelle.com/tonematrix">ToneMatrix</a> von <a href="http://lab.andre-michelle.com/">Andre</a>.</li>
    <li>Die Klänge sind mit gesampelten Instrumenten, Schlagzeugen oder sogar <a href="http://www.technitone.com/view/m923dgxnwbg">eigenen Aufnahmen</a> von Nutzern verknüpft.</li>
    <li>Mehrere miteinander verbundene Nutzer spielen gleichzeitig im selben Raster &hellip;</li>
    <li>&hellip; oder wechseln in den Solomodus, um es allein auszuprobieren.</li>
    <li>Im Rahmen von Einladungssitzungen können Nutzer eine Band organisieren und eine improvisierte Jam-Session abhalten.</li>
  </ul>

  <p>Wir bieten Nutzern die Gelegenheit, das Web Audio API über ein Steuerfeld zu erkunden, in dem sie Audiofilter und Effekte auf ihre Klänge anwenden können.</p>

  <img src="assets/images/technitone-feature-screenshot.png" alt="Technitone von gskinner.com" />

  <p>Außerdem:</p>

  <ul style="padding-left:25px">
    <li>speichern wir die Kompositionen und Effekte von Nutzern als Daten und synchronisieren diese clientübergreifend</li>
    <li>stellen wir einige Farboptionen bereit, sodass Nutzer <a href="http://www.technitone.com/view/8vec1djzfxv">cool aussehende Songs</a> gestalten können</li>
    <li>bieten wir eine Galerie, in der Nutzer die Werke anderer Personen anhören, mögen und sogar bearbeiten können</li>
  </ul>

  <p>Wir haben das bekannte Rasterbild – im 3D-Raum gleitend – aufgegriffen, durch Lichtelemente, Textur und Partikeleffekte ergänzt und es in eine flexible (oder als Vollbild dargestellte) und durch CSS und JavaScript gesteuerte Oberfläche integriert.</p>

  <h2 id="toc-roadtrip">Roadtrip.</h2>

  <p>Instrument-, Effekt- und Rasterdaten werden auf dem Client konsolidiert und serialisiert und anschließend an unser benutzerdefiniertes <a href="http://nodejs.org/">Node.js</a>-Backend gesendet. Auf diese Weise wird es <a href="http://socket.io/">Socket.io</a> entsprechend für mehrere Nutzer aufgelöst. Diese Daten werden mit den integrierten Beiträgen aller Mitwirkenden an den Client zurückgesendet und danach auf die jeweiligen CSS-, WebGL- und WebAudio-Ebenen aufgeteilt, die bei der Wiedergabe für mehrere Nutzer für das Rendering der Benutzeroberfläche, Samples und Effekte sorgen.</p>

  <p>Durch Echtzeitkommunikation mit Sockets werden JavaScript-Daten für den Client und den Server weitergeleitet.</p>

  <img src="assets/images/serverdiagram.png" alt="Technitone-Serverdiagramm" />

  <p>Wir nutzen Node.js für jeden Aspekt des Servers. Er ist zugleich ein statischer Webserver und unser Socket-Server. Letztlich entschieden wir uns für <a href="http://expressjs.com/">Express</a>. Dies ist ein kompletter Webserver, der vollständig für Node.js integriert ist. Er ist höchst skalierbar, sehr anpassbar und verarbeitet die systemnahen Serveraspekte für Sie, wie dies auch bei Apache oder Windows Server der Fall wäre. Auf diese Weise können Sie sich als Entwickler auf die Erstellung Ihrer Anwendung konzentrieren. <a href="assets/demos/ServerDiagram.pdf" class="button-download pdf">Detaillierteres Diagramm zur Client-Server-Kommunikation herunterladen</a></p>

  <h3 id="toc-multiuserdemo">Demo zu mehreren Nutzern (zugegebenermaßen ist dies tatsächlich nur ein Screenshot)</h3>

  <p>Diese Demo muss von einem Knotenserver ausgeführt werden. Da dieser Artikel kein Knotenserver ist, haben wir einen Screenshot eingefügt, dem Sie entnehmen können, wie die Demo nach der Installation von Node.js, der Konfiguration des Webservers und der lokalen Ausführung aussieht. Jedes Mal, wenn ein neuer Nutzer Ihre Demoinstallation besucht, wird ein neues Raster hinzugefügt. So sind die Werke aller für die anderen Nutzer sichtbar.</p>
      
      <img src="assets/images/nodeDemo.gif" alt="Screenshot der Demo zu Node.js" />
      <p><a href="assets/demos/nodejsDemo.zip" class="button-download">Demo zu mehreren Nutzern herunterladen <em>Erfordert Node.js-Server</em></a> Lesen Sie auf jeden Fall die README-Datei. Sie enthält Informationen zur Installation von Node.js, zur Konfiguration des Servers und zur lokalen Ausführung der Demo.</p>
      
      <p>Node.js ist ganz einfach. Mit einer Kombination von Socket.io und benutzerdefinierten POST-Anfragen mussten wir keine komplexen Routinen für die Synchronisierung entwickeln. Socket.io verarbeitet dies transparent. Der Datenaustausch erfolgt über <a href="http://de.wikipedia.org/wiki/JavaScript_Object_Notation">JSON</a>.</p>

  <p>Wie einfach? Schauen Sie.</p>

  <p>Mit drei JavaScript-Zeilen bringen wir einen Webserver mit Express zum Laufen.</p>

    <pre src='code/node_snippets.js#1-8'></pre>
      
    <p>Noch ein paar Zeilen mehr, und schon ist Socket.io für die Echtzeitkommunikation integriert.</p>

    <pre src='code/node_snippets.js#14-20'></pre>
      
    <p>Jetzt warten wir nur noch auf eingehende Verbindungen von der HTML-Seite.</p>
      
      <pre src='code/node_snippets.js#22-32'></pre>
      
      <h2 id="toc-soundcheck">Soundcheck.</h2>

  <p>Ein unbekannter Faktor war der durch die Nutzung von Web Audio API verursachte Aufwand. Unsere anfänglichen Ergebnisse belegten, dass die <a href="http://de.wikipedia.org/wiki/Digitale_Signalverarbeitung">digitale Signalverarbeitung</a> (Digital Signal Processing, DSP) sehr komplex ist und wir der Sache wahrscheinlich überhaupt nicht gewachsen waren. Die zweite Erkenntnis: <a href="http://chromium.googlecode.com/svn/trunk/samples/audio/index.html">Chris Rogers</a> hat die knifflige Arbeit im API bereits erledigt.</p>
  <p>Technitone nutzt keine abgefahrene Mathematik oder hoch spezialisierte Audiotechnik – diese Funktionalität ist für interessierte Entwickler problemlos zugänglich. Wir mussten wirklich nur terminologisch auf den aktuellen Stand kommen und <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html">die Dokumente lesen</a>. Unser Ratschlag? Überfliegen Sie sie nicht. Lesen Sie sie gründlich. Beginnen Sie oben und lesen Sie sie bis zum Ende. Sie sind übervoll mit Diagrammen und Fotos. Die Lektüre lohnt sich wirklich.</p>

  <p>Wenn Sie an dieser Stelle zum ersten Mal von Web Audio API gehört haben oder nicht wissen, welche Funktionsmöglichkeiten es bietet, sehen Sie sich die <a href="http://chromium.googlecode.com/svn/trunk/samples/audio/index.html">Demos</a> von Chris Rogers an. Lust auf Inspiration? Dort finden Sie sie ganz bestimmt.</p>

  <h3 id="toc-webaudiodemo">Demo zu Web Audio API</h3>

  <p>
    <span id="webAudioNotSupportedLabel" style="color: red;">Ihr Browser unterstützt Web Audio API nicht. Führen Sie diese Demo bitte in Chrome aus.<br /></span> <input id="loadSampleBtn" type="button" value="Sample laden"  />
    <label><input class="delay" type="checkbox" disabled="disabled" /> Sample verzögert wiedergeben</label>
    <input id="loadImpulseResponseBtn" type="button" value="Implusantwort laden"  />
    <label style="display:inline-block; vertical-align: text-top;"><input class="impulseResponse" type="checkbox" disabled="disabled" /> Sample mit Faltung wiedergeben <br />(<span style="margin-left: 20px;">mittels Implusantwort</span>)</label>
  </p>

  <p><a href="assets/demos/webAudioDemo.zip" class="button-download">Demo zu Web Audio API herunterladen<em>Funktioniert nur beim Hosting auf einem Server</em></a><p>

  <p><br />Hier erhalten Sie einen Überblick über die Elemente, die Sie in der Quelle finden:</p>

  <p class="note">Sample (Sounddatei) laden &hellip;</p>

  <pre src='code/wa_snippets.js#5-39'></pre>

  <p class="note">&hellip; modulare Weiterleitung einrichten &hellip;</p>

  <pre src='code/wa_snippets.js#46-59'></pre>

  <p class="note">&hellip; Laufzeiteffekt anwenden (Faltung mittels Impulsantwort) &hellip;</p>

  <pre src='code/wa_snippets.js#66-73'></pre>

  <p class="note">&hellip; weiteren Laufzeiteffekt anwenden (Verzögerung) &hellip;</p>

  <pre src='code/wa_snippets.js#80-104'></pre>

  <p class="note">&hellip; und dann den Ton hörbar machen</p>

  <pre src='code/wa_snippets.js#110-126'></pre>

  <p>Unser Wiedergabeansatz in Technitone dreht sich um Planung. Wir legen kein unserem Tempo entsprechendes Timer-Intervall zur taktweisen Verarbeitung von Tönen fest, sondern ein kleineres Intervall, bei dem Töne in einer Wartschlange verwaltet und geplant werden. Auf diese Weise kann das API die Vorarbeit erledigen, also die Audiodaten auflösen sowie Filter und Effekte verarbeiten, bevor sie von der CPU hörbar gemacht werden. Wenn der Takt schließlich ausgegeben wird, ist er bereits mit allen Informationen versehen, die zur Darstellung des Endergebnisses nötig sind.</p>

  <p>Insgesamt musste alles optimiert werden. Als unsere CPUs einer zu hohen Belastung ausgesetzt waren, wurden Prozesse abgebrochen (Knack-, Klick- und Kratzgeräusche), um den Zeitplan einzuhalten. Wir haben größten Wert darauf gelegt, die Wiedergabe anzuhalten, wenn Sie in Chrome zu einem anderen Tab wechseln.</p>

  <h2 id="toc-lightshow">Lightshow.</h2>

  <p>Vorn in der Mitte befinden sich unser Raster und der Partikeltunnel. Dies ist die <a href="http://www.khronos.org/webgl/">WebGL</a>-Ebene von Technitone.</p>

  <p>WebGL bietet eine beträchtlich höhere Leistung als die meisten anderen Ansätze für das Rendering von visuellen Elementen im Web, da die GPU angewiesen wird, in Verbindung mit dem Prozessor zu arbeiten. Dieser Leistungszuwachs geht mit einem erheblich höheren Entwicklungsaufwand, zugleich aber auch mit einer deutlich steileren Lernkurve einher. Nichtsdestoweniger: Wenn Sie von interaktiven Erfahrungen im Web wirklich begeistert sind und möglichst wenige Leistungseinschränkungen in Kauf nehmen möchten, bietet WebGL eine <a href="http://www.airtightinteractive.com/2011/10/stage3d-vs-webgl-performance/">mit Flash vergleichbare</a> Lösung.</p>

  <h3 id="toc-webgldemo">Demo zu WebGL</h3>

  <p>

    <canvas id="webglcanvas" width="750" height="480">
      <font color="#FF0000">Ihr Browser unterstützt leider HTML5 Canvas nicht. Stellen Sie sicher, dass Ihr Browser auf die neueste Version aktualisiert wurde und mit HTML5 Canvas kompatibel ist. <a href="http://support.google.com/chrome/bin/answer.py?hl=de&answer=95346">Empfohlen wird Google Chrome.</a></font>
    </canvas>

    <div id="webglDefault" hidden="true" style="font-style: italic; border: solid 1px; padding: 5px">
      Ihr Browser unterstützt leider WebGL nicht. Stellen Sie sicher, dass Ihr Browser auf die neuste Version aktualisiert wurde und mit WebGL kompatibel ist. <a href="http://support.google.com/chrome/bin/answer.py?hl=de&answer=95346">Empfohlen wird Google Chrome.</a><br />
    </div>

  <select id="webglDemoNumber" onchange="onNewWebGLDemo(event)">
      <option value="1">Demo 1: Ebenen und Würfel</option>
      <option value="2">Demo 2: Lichtelemente</option>
      <option value="3">Demo 3: Texturen</option>
      <option value="4">Demo 4: Partikel</option>
      <option value="5">Demo 5: Normalen</option>
    </select><br />
  <div id="webglDemo1" hidden="true">
    Ebenen werden gezeichnet, indem vier Scheitelpunkte zusammen mit zwei verbundenen Dreiecken zusammengefügt werden. <br />
    <label>
      <input id="wire" type="checkbox" value="false" onchange="onToggleWireframe(event)">
      Drahtgitter
    </label>
  </div>
  <div id="webglDemo2" hidden="true">
    Licht wird erzeugt, indem die Farbe in den Shadern entsprechend dem normalen Scheitelpunkt angepasst wird. <br />
    Lokale Lichtposition: <br />
    X: <input id="inputX" type="text" value="-5" />
    Y: <input id="inputY" type="text" value="-5" />
    Z: <input id="inputZ" type="text" value="-5" />
  </div>
  <div id="webglDemo3" hidden="true">
    Texturen werden durch ihre UV-Koordinaten – von 0 nach 1, von links nach rechts, von oben nach unten – auf Ebenen abgebildet. <br />
    Textur auswählen: <br />
    Kisten: 
    <select id="crateTexture" onchange="onChangeCrateTexture(event)">
      <option value="0">Holz</option>
      <option value="1">Metall</option>
      <option value="2">Holo</option>
    </select>
  </div>
  <div id="webglDemo4" hidden="true">
    Partikel werden jeweils mit zwei Dreiecken und ihrem eigenen Verweis auf eine Textur gezeichnet. Stellen Sie den maximalen Wert von Z auf 1 ein, um sich dies anzusehen. <br />
    Partikelanzahl: <input id="count" type="text" value="10000" />
    Partikelhäufigkeit: <input id="freq" type="text" value="2" /><br />
    Partikelgeschwindigkeit: <br />
    MIN --- X: <input id="minX" type="text" value="-1" />
    Y: <input id="minY" type="text" value="1" />
    Z: <input id="minZ" type="text" value="0" /> <br />
    
    MAX --- X: <input id="maxX" type="text" value="1" />
    Y: <input id="maxY" type="text" value="1" />
    Z: <input id="maxZ" type="text" value="0" />
  </div>
  <div id="webglDemo5" hidden="true">
    Bei Normalen wird eine normale Zuordnung verwendet, um das Licht für jedes Pixel anders zu reflektieren. Dies wird durch einen groben 3D-Effekt erzeugt. <br />
  <input id="useTextureNormal" type="checkbox" checked="false" onchange="onToggleNormal(event)">Texturnormale verwenden</input><br />
  </div>
  </p>

  <p>Die Demo enthält eine Einführung in Schattierung, Texturen, Animation, Partikeleffekte und Interaktivität. Jede Demo baut linear auf dem vorherigen Konzept auf.</p>
  <a href="webgl/WebGL_Demos.zip" class="button-download">Demo zu WebGL herunterladen<em>Texturbasierte Demos funktionieren nur auf einem Server</em></a>

  <p class="note">Hinweis: WebGL entspricht einem Sicherheitsprotokoll, das verhindert, dass es Texturen direkt von einer lokalen Festplatte lädt und bearbeitet.</p>

  <p>WebGL-Inhalte werden auf einem Canvas-Element, dem HTML5 Canvas, gerendert und setzen sich aus folgenden Kernkomponenten zusammen:</p>

   <ul style="padding-left:25px">
    <li>Objektscheitelpunkte (Geometrie)</li>
    <li>Positionsmatrizen (3D-Koordinaten)</li>
      <li>Shader (Beschreibung der Geometriedarstellung, die direkt mit der GPU verknüpft ist)</li>
      <li>Kontext ("Verknüpfungen" zu den Elementen, auf die die GPU verweist)</li>
      <li>Puffer (Pipelines für die Weitergabe von Kontextdaten an die GPU)</li>
      <li>Hauptcode (für die gewünschte interaktive Erfahrung spezifische Geschäftslogik)</li>
      <li>"draw"-Methode (aktiviert die Shader und zeichnet Pixel auf das Canvas-Element)</li>
  </ul>

  <p>Der grundlegende Prozess zum Rendern von WebGL-Inhalten auf dem Bildschirm läuft folgendermaßen ab:</p>

  <ol style="padding-left:25px">
    <li>Stellen Sie die Perspektivenmatrix ein – hierdurch werden Einstellungen für die in den 3D-Raum gerichtete Kamera angepasst, sodass die Bildebene definiert wird.</li>
    <li>Stellen Sie die Positionsmatrix ein – legen Sie in den 3D-Koordinaten einen Ursprung fest, im Verhältnis zu dem Positionen gemessen werden.</li>
    <li>Füllen Sie die Puffer mit Daten wie Position des Scheitelpunkts, Farbe oder Texturen, um die Inhalte durch die Shader weiterzugeben.</li>
    <li>Extrahieren und organisieren Sie mit den Shadern Daten aus den Puffern und geben Sie diese in die GPU weiter.</li>
    <li>Rufen Sie die "draw"-Methode auf, damit der Kontext angewiesen wird, Shader zu aktivieren, mit den Daten ausgeführt zu werden und das Canvas-Element zu aktualisieren.</li>
   </ol>
   
  <p>Dies sieht in Aktion wie folgt aus:</p>

  <p class="note">Perspektivenmatrix einstellen &hellip;</p>

  <pre src='webgl/source/Demo01.js#213-222'></pre>

  <p class="note">&hellip; Positionsmatrix einstellen &hellip;</p>

  <pre src='webgl/source/Demo01.js#224-231'></pre>

  <p class="note">&hellip; Geometrie und Darstellung definieren &hellip;</p>

  <pre src='webgl/source/Demo02.js#124-136'></pre>

  <p class="note">&hellip; Puffer mit Daten füllen und diese an den Kontext weitergeben &hellip;</p>

  <pre src='webgl/source/Demo02.js#138-148'></pre>

  <p class="note">&hellip; und die "draw"-Methode aufrufen</p>

  <pre src='webgl/source/Demo02.js#196-198'></pre>

  <p>Denken Sie bei jedem Frame daran, das Canvas-Element zu leeren, damit alphabasierte visuelle Elemente nicht übereinander gestapelt werden.</p>

  <h2 id="toc-thevenue">Der Ort des Geschehens.</h2>

  <p>Abgesehen vom Raster und dem Partikeltunnel wurden alle anderen Elemente der Benutzeroberfläche in HTML/CSS und interaktive Logik in JavaScript erstellt.</p>

  <p>Wir hatten uns von Anfang an das Ziel gesetzt, dass die Nutzer so schnell wie möglich mit dem Raster interagieren können sollten. Kein Startbildschirm, keine Anleitung, keine Trainings, sondern direkt loslegen. Beim Laden der Oberfläche sollten sie durch nichts aufgehalten werden.</p>

  <p>Daher mussten wir uns sehr genau überlegen, wie wir Erstnutzer durch die Interaktionen führen. Wir integrierten unauffällige Hinweise, beispielsweise die Änderung der CSS-Cursor-Eigenschaft basierend auf der Mausposition des Nutzers im WebGL-Raum. Wenn sich der Cursor über dem Raster befindet, wird er als Handsymbol angezeigt, weil die Nutzer durch das Einzeichnen von Klängen interagieren können. Wird der Cursor im leeren Bereich um das Raster herum positioniert, so verwandelt er sich in einen kreuzförmigen Richtungs-Cursor und zeigt so an, dass die Nutzer das Raster drehen oder in Ebenen auflösen können.</p>

  <h3 id="toc-gettingready">Startklar für die Show?</h3>
  <p><a href="http://lesscss.org/">LESS</a>, ein CSS-Vorprozessor, und <a href="http://incident57.com/codekit/">CodeKit</a> für die Webentwicklung auf Steroiden sorgen für eine erhebliche Verkürzung der Zeit, die für die Übersetzung von Designdateien in HTML/CSS benötigt wird. Mit beiden können wir CSS wesentlich vielseitiger organisieren, schreiben und optimieren. Dabei können Variablen, Mixins (Funktionen) und sogar mathematische Elemente genutzt werden.</p>

  <h3 id="toc-stageeffects">Bühneneffekte</h3>

  <p>Durch <a href="http://www.w3schools.com/css3/css3_transitions.asp">CSS3-Übergänge</a> und <a href="http://documentcloud.github.com/backbone/">Backbone.js</a> erstellten wir wirklich einfache Effekte, durch die die Anwendung lebendiger wirkt und die Nutzer visuelle Abläufe sehen, die das gerade verwendete Instrument darstellen.</p>

  <img src="assets/images/color-shift-ui-01.jpg" alt="Die Farben von Technitone" />

  <p>Durch Backbone.js können wir Farbänderungsereignisse erfassen und die neue Farbe auf die entsprechenden DOM-Elemente (Document Object Model) anwenden. Die Farbstiländerungen wurden durch GPU-beschleunigte CSS3-Übergänge mit geringer oder keinerlei Auswirkung auf die Leistung behandelt.</p>

  <p>Die meisten Farbübergänge für Oberflächenelemente wurden durch Übergänge bei den Hintergrundfarben bewirkt. Über diesen Hintergrundfarbe platzieren wir Hintergrundbilder mit transparenten Bereichen, die so angeordnet sind, dass die Hintergrundfarbe durchscheint.</p>

  <h3 id="toc-colortransdemo">Demo zu Farbübergängen – Wie viele Farben können Sie darstellen?</h3>

  <p>In dieser Demo sehen Sie ein großartiges Beispiel für die Möglichkeiten, die diese Technik bietet. Wählen Sie Farben aus und verfolgen Sie, wie der verrückte Wissenschaftler sie mischt, um eine dritte, neue Farbe herzustellen. </p>

  <img src="assets/images/color-shift-demo-header.png" alt="Demo zur Farbverschiebung unten" style="display:block;" />

  <!-- Color Transition Demo HTML -->
  <div class="illo color-mixed">
      
    <div class="illo color-primary"></div>
    <div class="illo color-secondary"></div>

    <!-- Primary Color Selection -->
    <ul class="picker color-primary">
      <li class="color-1"></li>
      <li class="color-2"></li>
      <li class="color-3"></li>
      <li class="color-4"></li>
      <li class="color-5"></li>
      <li class="color-6 selected"></li>
      <li class="color-7"></li>
      <li class="color-8"></li>
    </ul>

    <!-- Secondary Color Selection -->
    <ul class="picker color-secondary">
      <li class="color-1"></li>
      <li class="color-2"></li>
      <li class="color-3 selected"></li>
      <li class="color-4"></li>
      <li class="color-5"></li>
      <li class="color-6"></li>
      <li class="color-7"></li>
      <li class="color-8"></li>
    </ul>

  </div>
  <!-- END Color Transition Demo HTML -->

  <p><a href="assets/demos/colorShiftDemo.zip" class="button-download">Demo zur Farbverschiebung herunterladen</a></p>

  <p>Schauen wir uns nun die Details in HTML, CSS, JavaScript und die Vorgehensweise zur Vorbereitung von Grafiken auf den Effekt genauer an.</p>

  <h3 id="toc-htmlfound">HTML: Die Basis</h3>

  <p>Für die Demo benötigten wir drei Farbbereiche: zwei vom Nutzer ausgewählte Farbbereiche und einen dritten Bereich für die gemischte Farbe. Wir erstellten für unsere Illustration die einfachste vorstellbare DOM-Struktur zum Support von CSS3-Übergängen mit der geringsten Anzahl von HTTP-Anforderungen.</p>
  <pre>
&lt;!-- Basic HTML Setup -->
&lt;div class="illo color-mixed">   
  &lt;div class="illo color-primary">&lt;/div>
  &lt;div class="illo color-secondary">&lt;/div>
&lt;/div>
  </pre>

  <h3 id="toc-css">CSS: Einfache Struktur mit Stil</h3>

  <p>Wir platzierten die einzelnen Bereiche durch absolute Positionierung am jeweils richtigen Ort und passten die "background-position"-Eigenschaft an, um die Hintergrundillustration in jedem Bereich auszurichten. Hierdurch sehen alle Bereiche – jeder mit demselben Hintergrundbild – wie ein einziges Element aus.</p>

  <pre src='assets/demos/colorShiftDemo/css/styles.css#52-71'></pre>

  <p>Es wurden GPU-beschleunigte Übergänge angewendet, die auf Farbänderungsereignisse horchen. Wir verlängerten die Dauer und <a href="http://cubic-bezier.com/#.78,0,.53,1" title="Ein von Lea Verou entwickeltes, personalisiertes Easing-Tool">änderten das Easing</a> für ".color-mixed", um den Eindruck zu erwecken, dass das Mischen der Farben etwas Zeit in Anspruch nimmt.</p>

  <pre src='assets/demos/colorShiftDemo/css/styles.css#33-49'></pre>

  <p><a href="http://html5please.us/#transition">Besuchen Sie HTML5please, um sich über den Support aktueller Browser und Nutzungsempfehlungen für CSS3-Übergänge zu informieren</a>.</p>

  <h3 id="toc-js">JavaScript: So funktioniert's</h3>

  <p>Die dynamische Zuweisung von Farben ist einfach. Wir suchen das DOM für jedes Element mit unserer Farbklasse und legen die Hintergrundfarbe, "background-color", basierend auf der Farbauswahl des Nutzers fest. Dann wenden wir unseren Übergangseffekt auf jedes Element im DOM an und fügen dazu eine Klasse hinzu.</p>
  <p>Hierdurch wird eine Architektur erstellt, die ressourcensparend, flexibel und skalierbar ist.</p>

  <pre src='assets/demos/colorShiftDemo/js/ColorShifting.js#58-72'></pre>

  <p>Sobald die erste und die zweite Farbe ausgewählt sind, berechnen wir den gemischten Farbwert und weisen den resultierenden Wert auf das entsprechende DOM-Element an.</p>

  <pre src='assets/demos/colorShiftDemo/js/ColorShifting.js#91-107'></pre>

  <h3 id="toc-arch">Illustration für die HTML/CSS-Architektur: Eine persönliche Note für drei Farbverschiebungsfelder</h3>

  <p>Unser Ziel war es, einen witzigen und realistischen Lichteffekt zu schaffen, der auch noch echt wirkte, wenn angrenzende Farbbereiche mit kontrastierenden Farben versehen wurden.</p>

  <p>Durch eine 24-Bit-PNG-Datei kann die Hintergrundfarbe unserer HTML-Elemente durch die transparenten Bereiche des Bilds durchscheinen.</p>

  <img src="assets/images/color-alpha.png" alt="Bildtransparenzen" />
                                          
  <p>Bei den farbigen Feldern entstehen an den Stellen, an denen verschiedene Farben aufeinander treffen, harte Kanten. Dies wirkt sich störend auf realistische Lichteffekte aus und stellte beim Design der Illustration eine der größeren Herausforderungen dar.</p>

  <img src="assets/images/color-regions.png" alt="Farbbereiche" />

  <p>Die Lösung bestand darin, die Illustration so zu gestalten, dass die Kanten der Farbbereiche niemals durch die transparenten Bereiche durchscheinen können.</p>

  <img src="assets/images/color-region-edges.png" alt="Kanten der Farbbereiche" />

  <p>Die Planung des Aufbaus war ein ganz wesentlicher Punkt. In einer schnell anberaumten Planungssitzung mit dem Designer, dem Entwickler und dem Illustrator erhielt das Team den nötigen Überblick darüber, wie alles aufgebaut sein muss, damit nach der Zusammenstellung alles funktioniert.</p>

  <p>Anhand der Photoshop-Datei sehen Sie beispielsweise, dass die Benennung von Ebenen Informationen über den CSS-Aufbau liefern kann.</p>

  <img src="assets/images/color-layer-setup.png" alt="Kanten der Farbbereiche" />

  <p><a href="assets/demos/colorShiftDemo.zip" class="button-download">Demo zur Farbverschiebung herunterladen</a></p>

  <h2 id="toc-encore">Zugabe.</h2>

  <p>Für Nutzer ohne Chrome setzten wir uns das Ziel, die wesentlichen Elemente der Anwendung in einem einzelnen, statischen Bild zusammenzufassen. Dazu wurde der Rasterknoten in den Mittelpunkt gerückt. Die Kacheln im Hintergrund deuten den Zweck der Anwendung an und die in der Reflexion vorhandene Perspektive spielt auf die immersive 3D-Umgebung des Rasters an.</p>

  <a href="http://www.technitone.com"> <img src="assets/images/only-in-chrome.png" alt="Kanten der Farbbereiche" /> </a>

  <p>Wenn Sie mehr über Technitone erfahren möchten, können Sie in unserem <a href="http://www.gskinner.com/blog">Blog auf dem Laufenden bleiben</a>.</p>

  <p><a href="assets/demos/AllDemos.zip" class="button-download">Alle Demos in einer Datei herunterladen</a></p>

  <h2 id="toc-theband">Die Band.</h2>

  <p>Vielen Dank für Ihre Aufmerksamkeit! Vielleicht treffen wir uns bald bei einer <a href="http://www.technitone.com">gemeinsamen Jam-Session</a>!</a></p>





  <!-- WebGL code -->

  <script type="text/javascript" src="webgl/code/shaders/ShaderColor.js"></script>
  <script type="text/javascript" src="webgl/code/shaders/ShaderDetailed.js"></script>
  <script type="text/javascript" src="webgl/code/shaders/ShaderParticle.js"></script>
  <script type="text/javascript" src="webgl/code/shaders/ShaderSolo.js"></script>
  <script type="text/javascript" src="webgl/code/shaders/ShaderTexture.js"></script>
  
  <script type="text/javascript" src="webgl/code/shapes/ColorCube.js"></script>
  <script type="text/javascript" src="webgl/code/shapes/Particle.js"></script>
  <script type="text/javascript" src="webgl/code/shapes/ParticleEmitter.js"></script>
  <script type="text/javascript" src="webgl/code/shapes/Plane.js"></script>
  <script type="text/javascript" src="webgl/code/shapes/TextureCube.js"></script>
  
  <script type="text/javascript" src="webgl/code/utils/glMatrix-0.9.5.min.js"></script>
  <script type="text/javascript" src="webgl/code/utils/webgl-utils.js"></script>
  
  <script type="text/javascript" src="webgl/code/demos/Demo01.js"></script>
  <script type="text/javascript" src="webgl/code/demos/Demo02.js"></script>
  <script type="text/javascript" src="webgl/code/demos/Demo03.js"></script>
  <script type="text/javascript" src="webgl/code/demos/Demo05.js"></script>
  <script type="text/javascript" src="webgl/code/demos/Demo06.js"></script>

  <!-- End of WebGL code. -->
  

  <script type="text/javascript" src="assets/demos/webAudio/js/Voice.js"></script>
  <script type="text/javascript" src="assets/demos/webAudio/js/NodeChain.js"></script>
  <script type="text/javascript" src="assets/demos/webAudio/js/VoiceLoader.js"></script>

  <!-- COLOR SHIFTING DEMO -->
  <link href='assets/demos/colorShiftDemo/css/styles.css' rel='stylesheet'>
  <script type="text/javascript" src="assets/demos/colorShiftDemo/js/ColorShifting.js"></script>
  <script type="text/javascript">
    var loadSampleBtn = null;
    var loadImpulseResponseBtn = null;

    var context = null;
    var compressorNode = null;
    var sampleNodeChain = null;

    var voiceLoader = null;
    var sampleVoice = null;
    var impulseResponseVoice = null;

    function init() {
      // don't double load.
      if (init.run) return;
      init.run = true;

      onNewWebGLDemo();

      if (typeof webkitAudioContext != "function") {
        $("input[type='button']").attr("disabled", "disabled");
      } else {
        $("#webAudioNotSupportedLabel").remove();
      }
      wa_demo1_initWebAudio();
      wa_demo1_configUI();

      sampleVoice = new Voice("painoC4", "Piano", "assets/demos/webAudio/audio/Piano.ff.C4.wav"); // http://theremin.music.uiowa.edu/MISpiano.html
      impulseResponseVoice = new Voice("rythm1", "Rythym", "assets/demos/webAudio/audio/filter-rhythm1.mp3"); // http://chromium.googlecode.com/svn/trunk/samples/audio/impulse-responses/
      voiceLoader = new VoiceLoader();
    }

    function wa_demo1_initWebAudio() {
      context = new webkitAudioContext();

      Voice.CONTEXT = context;
      VoiceLoader.CONTEXT = context;
      NodeChain.CONTEXT = context;

      // Setup Routing:
      compressorNode = context.createDynamicsCompressor();
      compressorNode.connect(context.destination);

      sampleNodeChain = new NodeChain();
      sampleNodeChain.connect(compressorNode);
    }

    function wa_demo1_configUI() {
      loadSampleBtn = $("#loadSampleBtn");
      loadSampleBtn.click(function (event) {
        loadSampleBtn.unbind("click");
        loadSampleBtn.val("Loading Sample...");
        voiceLoader.loadVoice(sampleVoice, wa_demo1_onVoiceSuccess, null, wa_demo1_onVoiceFail);
      });

      loadImpulseResponseBtn = $("#loadImpulseResponseBtn");
      loadImpulseResponseBtn.click(function (event) {
        loadImpulseResponseBtn.unbind("click");
        loadImpulseResponseBtn.val("Loading Impulse Response...");
        voiceLoader.loadVoice(impulseResponseVoice, wa_demo1_onVoiceSuccess, null, wa_demo1_onVoiceFail);
      });

      $(".impulseResponse").change(function (event) {
        sampleNodeChain.convolve = $(event.target)[0].checked;
      });

      $(".delay").change(function (event) {
        sampleNodeChain.delay = $(event.target)[0].checked;
      });
    }

    function wa_demo1_onVoiceSuccess (voice) {
      //TD: I put a short delay in so the users with fast internet connections wouldn't see a quick blinking loading button.
      setTimeout(function () {

        if (voice == sampleVoice) {
          sampleNodeChain.voice = voice;

          loadSampleBtn.val("Play Sample");
          loadSampleBtn.click(function (event) {
            sampleNodeChain.noteOn(0);
          });

          $(".delay").removeAttr("disabled");
          if (impulseResponseVoice.loaded) {
            $(".impulseResponse").removeAttr("disabled");
          }
        } else {
          sampleNodeChain.impulseResponseVoice = voice;

          loadImpulseResponseBtn.val("Play Impulse Response");
          loadImpulseResponseBtn.click(function (event) {
            var sourceNode = context.createBufferSource();
            sourceNode.buffer = impulseResponseVoice.buffer;
            sourceNode.connect(compressorNode);
            sourceNode.noteOn(0);
          });

          if (sampleVoice.loaded) {
            $(".impulseResponse").removeAttr("disabled");
          }
        }

      }, 300);
    }

    function wa_demo1_onVoiceFail (voice) {
      if (voice == sampleVoice) {
        loadSampleBtn.val("Sample Load Fail");
        loadSampleBtn.attr("disabled", "disabled");
      } else {
        loadImpulseResponseBtn.val("Impulse Response Load Fail");
        loadImpulseResponseBtn.attr("disabled", "disabled");
      }
    }
  </script>
  
  <!-- WebGL -->
  
  <script type="text/javascript">      
      function onNewWebGLDemo(event) {
        var canvas = document.getElementById("webglcanvas");
        var webglDemo = parseInt(document.getElementById("webglDemoNumber").value);
        
        document.getElementById("webglDefault").hidden = true;
        document.getElementById("webglDemo1").hidden = true;
        document.getElementById("webglDemo2").hidden = true;
        document.getElementById("webglDemo3").hidden = true;
        document.getElementById("webglDemo4").hidden = true;
        document.getElementById("webglDemo5").hidden = true;
        
        if (this.webglDemo) {
           this.webglDemo.destroy();        
           
           switch (webglDemo) {
             case 1:
               document.getElementById("webglDemo1").hidden = false;
               this.webglDemo = new Demo01(canvas); 
               break;
             case 2:
               document.getElementById("webglDemo2").hidden = false;
               this.webglDemo = new Demo02(canvas); 
               break;
             case 3:
               document.getElementById("webglDemo3").hidden = false;
               this.webglDemo = new Demo03(canvas); 
               break;
             case 4:
               document.getElementById("webglDemo4").hidden = false;
               this.webglDemo = new Demo05(canvas); 
               break;
             case 5:
               document.getElementById("webglDemo5").hidden = false;
               document.getElementById("useTextureNormal").checked = false;
               this.webglDemo = new Demo06(canvas); 
               break;
             default:
               break;
           }
        
           this.webglDemo.paused = false;
           this.webglDemo.tick();
        } else { // Start with Demo01. Otherwise, indicate the browser's not compatable.
          this.webglDemo = new Demo01(canvas);
          document.getElementById("webglDemoNumber").value = 1;
          if (this.webglDemo.gl && this.webglDemo.shader.program) {
            document.getElementById("webglDemo1").hidden = false;
          } else {
        canvas.hidden = true;
        $('#webglDemoNumber').attr("disabled", "disabled");
            document.getElementById("webglDefault").hidden = false;
          }
        }
        
      }
      
      function onKeyboardDown(event) {
        if (!this.webglDemo.paused) {
          this.webglDemo.keyDown(event.keyCode);
        }
      }
      function onKeyboardUp(event) {
        if (!this.webglDemo.paused) {
          this.webglDemo.keyUp(event.keyCode);
        }
      }      
      function onToggleWireframe(event) {
        var toggle = document.getElementById("wire").checked;
        this.webglDemo.wireframe = toggle;
      }
      function onChangeCrateTexture(event) {
          var splr = document.getElementById("crateTexture").value;
          this.webglDemo.setCrateTexture(splr);
        }     
        
      function onToggleNormal(event) {
          this.webglDemo.useNormal = document.getElementById("useTextureNormal").checked;
        }      
     
    </script>




  <script src='/tutorials/doodles/lem/prettify-newer.js'></script>  <!-- //mg: Downloaded from HTML5Rocks.com, Doodle Case Study -->
  <script src='/tutorials/doodles/lem/scripts.js'></script>       <!-- //mg: Downloaded from HTML5Rocks.com, Doodle Case Study -->

  <script>
    initialize(); 
    window.addEventListener('load',init, false);
    setTimeout(function(){
      init();
    }, 7*1000); // random double run to attempt to fix init() not running..
  </script>


</script>
{% endblock %}