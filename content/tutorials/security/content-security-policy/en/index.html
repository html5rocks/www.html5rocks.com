{% extends "tutorial.html" %}

{% block head %}
<script>
function customPrettyPrintLanguage() {
  PR['registerLangHandler'](
    PR['createSimpleLexer'](
      [],
      [
        [PR['PR_PUNCTUATION'], /^;/],
        [PR['PR_TYPE'], /(default|script|object|style|img|media|frame|font|connect|)-src/],
        [PR['PR_TYPE'], /(form-action|sandbox|script-nonce|plugin-types|frame-options|report-uri)/],
        [PR['PR_STRING'], /^'(?:[^']|'')*(?:'|$)/],
        [PR['PR_KEYWORD'], /^[a-zA-Z-]+:[ \r\n]/],
        [PR['PR_PLAIN'], /^\w+/]
      ]), ['csp']);
}
</script>
{% endblock %}

{% block iscompatible %}
{% endblock %}

{% block html5badge %}
<!--
<img src="/static/images/identity/html5-badge-h-multimedia.png" width="133" height="64" alt="This article is powered by HTML5 Graphics, 3D &amp; Effects" title="This article is powered by HTML5 Graphics, 3D &amp; Effects" />
-->
{% endblock %}

{% block content %}

<p>The web&#8217;s security model is rooted in the <a href="http://en.wikipedia.org/wiki/Same_origin_policy"><em>same origin policy</em></a>. Code from <code>https://mybank.com</code> should only have access to <code>https://mybank.com</code>&#8217;s data, and <code>https://evil.example.com</code> should certainly never be allowed access. Each origin is kept isolated from the rest of the web, giving developers a safe sandbox in which to build and play. In theory, this is perfectly brilliant. In practice, attackers have found clever ways to subvert the system.</p>

<p><a href="http://en.wikipedia.org/wiki/Cross-site_scripting">Cross-site scripting (XSS)</a> attacks, for example, bypass the same origin policy by tricking a site into delivering malicious code along with the intended content. This is a huge problem, as browsers trust all of the code that shows up on a page as being legitimately part of that page&#8217;s security origin. The <a href="http://ha.ckers.org/xss.html">XSS Cheat Sheet</a> is an old but representative cross-section of the methods an attacker might use to violate this trust by injecting malicious code. If an attacker successfully injects <em>any</em> code at all, it&#8217;s pretty much game over: user session data is compromised and information that should be kept secret is exfiltrated to The Bad Guys. We&#8217;d obviously like to prevent that if possible.</p>

<p>This tutorial highlights one promising new defense that can significantly reduce the risk and impact of XSS attacks in modern browsers: Content Security Policy (CSP).</p>

<h2 id="source-whitelists">Source Whitelists</h2>

<p>The core issue exploited by XSS attacks is the browser&#8217;s inability to distinguish between script that&#8217;s intended to be part of your application, and script that&#8217;s been maliciously injected by a third-party. For example, the Google +1 button at the top of this article loads and executes code from <code>https://apis.google.com/js/plusone.js</code> in the context of this page&#8217;s origin. We trust that code, but we can&#8217;t expect the browser to figure out on it&#8217;s own that code from <code>apis.google.com</code> is awesome, while code from <code>apis.evil.example.com</code> probably isn&#8217;t. The browser happily downloads and executes any code a page requests, regardless of source.</p>

<p>Instead of blindly trusting <em>everything</em> that a server delivers, CSP defines the <code>Content-Security-Policy</code> HTTP header that allows you to create a whitelist of sources of trusted content, and instructs the browser to only execute or render resources from those sources. Even if an attacker can find a hole through which to inject script, the script won&#8217;t match the whitelist, and therefore won&#8217;t be executed.</p>

<p>Since we trust <code>apis.google.com</code> to deliver valid code, and we trust ourselves to do the same, let&#8217;s define a policy that only allows script to execute when it comes from one of those two sources:</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: script-src 'self' https://apis.google.com
</code></pre>

<p>Simple, right? As you probably guessed, <strong><code>script-src</code></strong> is a directive that controls a set of script-related privileges for a specific page. We&#8217;ve specified <code>'self'</code> as one valid source of script, and <code>https://apis.google.com</code> as another. The browser will dutifully download and execute JavaScript from <code>apis.google.com</code> over HTTPS, as well as from the current page&#8217;s origin.</p>

<p>With this policy defined, the browser will simply throw an error instead of loading script from any other source. When a clever attacker does manage to inject code into your site, she&#8217;ll run headlong into an error message, rather than the success she was expecting:</p>

<p><img src="csp-error.png" alt="Console error: &quot;Refused to load the script 'http://evil.example.com/evil.js' because it violates the following Content Security Policy directive: &quot;script-src 'self' https://apis.google.com&quot;.&quot;" /></p>

<h3 id="policy-applies-to-a-wide-variety-of-resources">Policy applies to a wide variety of resources</h3>

<p>While script resources are the most obvious security risks, CSP provides a rich set of policy directives that enable fairly granular control over the resources that a page is allowed to load. You&#8217;ve already seen <code>script-src</code>, so the concept should be clear. Let&#8217;s quickly walk through the rest of the resource directives:</p>

<ul>
  <li><strong><code>base-uri</code></strong> restricts the URLs that can appear in a page&#8217;s <code>&lt;base&gt;</code> element.</li>
  <li><strong><code>child-src</code></strong> lists the URLs for workers and embedded frame contents. For example: <code>child-src https://youtube.com</code> would enable embedding videos from YouTube but not from other origins. Use this in place of the deprecated <strong><code>frame-src</code></strong> directive.</li>
  <li><strong><code>connect-src</code></strong> limits the origins to which you can connect (via XHR, WebSockets, and EventSource).</li>
  <li><strong><code>font-src</code></strong> specifies the origins that can serve web fonts. Google&#8217;s Web Fonts could be enabled via <code>font-src https://themes.googleusercontent.com</code></li>
  <li><strong><code>form-action</code></strong> lists valid endpoints for submission from <code>&lt;form&gt;</code> tags.</li>
  <li><strong><code>frame-ancestors</code></strong>  specifies the sources that can embed the current page. This directive applies to <code>&lt;frame&gt;</code>, <code>&lt;iframe&gt;</code>, <code>&lt;embed&gt;</code>, and <code>&lt;applet&gt;</code> tags. This directive cant be used in <code>&lt;meta&gt;</code> tags and applies only to non-HTML resources.</li>
  <li><strong><code>frame-src</code></strong> deprecated. Use <strong><code>child-src</code></strong> instead.</li>
  <li><strong><code>img-src</code></strong> defines the origins from which images can be loaded.</li>
  <li><strong><code>media-src</code></strong> restricts the origins allowed to deliver video and audio.</li>
  <li><strong><code>object-src</code></strong> allows control over Flash and other plugins.</li>
  <li><strong><code>plugin-types</code></strong> limits the kinds of plugins a page may invoke.</li>
  <li><strong><code>report-uri</code></strong> specifies a URL where a browser will send reports when a content security policy is violated. This directive cant be used in <code>&lt;meta&gt;</code> tags.</li>
  <li><strong><code>style-src</code></strong> is <code>script-src</code>&#8217;s counterpart for stylesheets.</li>
  <li><strong><code>upgrade-insecure-requests</code></strong> Instructs user agents to rewrite URL schemes, changing HTTP to HTTPS. This directive is for web sites with large numbers of old URLs that need to be rewritten.</li>
</ul>

<p>By default, directives are wide open. If you don&#8217;t set a specific policy for a directive, let&#8217;s say <code>font-src</code>, then that directive behaves by default as though you&#8217;d specified <code>*</code> as the valid source (e.g. you could load fonts from everywhere, without restriction).</p>

<p>You can override this default behavior by specifying a <strong><code>default-src</code></strong> directive. This directive, as you might suspect, defines the defaults for most directives you leave unspecified. Generally, this applies to any directive that ends with <code>-src</code>. If <code>default-src</code> is set to <code>https://example.com</code>, and you fail to specify a <code>font-src</code> directive, then you can load fonts from <code>https://example.com</code>, and nowhere else. We specified only <code>script-src</code> in our earlier examples, which means that images, fonts, and so on can be loaded from any origin.</p>

<p>The following directives don&#8217;t use default-src as a fallback. Remember that failing to set them is the same as allowing anything.
<ul>
  <li><code>base-uri</code></li>
  <li><code>form-action</code></li>
  <li><code>frame-ancestors</code></li>
  <li><code>plugin-types</code></li>
  <li><code>report-uri</code></li>
  <li><code>sandbox</code></li>
</ul>
</p>

<p>You can use as many or as few of these directives as makes sense for your specific application, simply listing each in the HTTP header, separating directives with semicolons. You&#8217;ll want to make sure that you list <em>all</em> required resources of a specific type in a <em>single</em> directive. If wrote something like <pre class="prettyprint"><code>script-src https://host1.com; script-src https://host2.com</code></pre> the second directive would simply be ignored. Something like the following would correctly specify both origins as valid.</p>

<pre class="prettyprint"><code>script-src https://host1.com https://host2.com
</code></pre>

<p>If, for example, you have an application that loads all of its resources from a content delivery network (say, <code>https://cdn.example.net</code>), and know that you don&#8217;t need framed content or any plugins at all, then your policy might look like the following:</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: default-src https://cdn.example.net; child-src 'none'; object-src 'none'
</code></pre>

<h3 id="implementation-details">Implementation Details</h3>

<p>You will see <code>X-WebKit-CSP</code> and <code>X-Content-Security-Policy</code> headers in various tutorials on the web. Going forward, you can and should ignore these prefixed headers. Modern browsers (with the exception of IE) support the unprefixed <code>Content-Security-Policy</code> header. That&#8217;s the header you should use.</p>

<p>Regardless of the header you use, policy is defined on a page-by-page basis: you&#8217;ll need to send the HTTP header along with every response that you&#8217;d like to ensure is protected. This provides a lot of flexibility, as you can fine-tune the policy for specific pages based on their specific needs. Perhaps one set of pages in your site has a +1 button, while others don&#8217;t: you could allow the button code to be loaded only when necessary.</p>

<p>The source list in each directive is fairly flexible. You can specify sources by scheme (<code>data:</code>, <code>https:</code>), or ranging in specificity from hostname-only (<code>example.com</code>, which matches any origin on that host: any scheme, any port) to a fully qualified URI (<code>https://example.com:443</code>, which matches only HTTPS, only <code>example.com</code>, and only port 443). Wildcards are accepted, but only as a scheme, a port, or in the leftmost position of the hostname: <code>*://*.example.com:*</code> would match all subdomains of <code>example.com</code> (but <em>not</em> <code>example.com</code> itself), using any scheme, on any port.</p>

<p>Four keywords are also accepted in the source list:</p>

<ul>
  <li><strong><code>'none'</code></strong>, as you might expect, matches nothing.</li>
  <li><strong><code>'self'</code></strong> matches the current origin, but not its subdomains.</li>
  <li><strong><code>'unsafe-inline'</code></strong> allows inline JavaScript and CSS (we&#8217;ll touch on this in more detail in a bit).</li>
  <li><strong><code>'unsafe-eval'</code></strong> allows text-to-JavaScript mechanisms like <code>eval</code> (we&#8217;ll get to this too).</li>
</ul>

<p>These keywords require single-quotes. <code>script-src 'self'</code> (with quotes) authorizes the execution of JavaScript from the current host. <code>script-src self</code> (no quotes) allows JavaScript from a server named &#8220;<code>self</code>&#8221; (and <em>not</em> from the current host), which probably isn&#8217;t what you meant.</p>

<h3 id="sandboxing">Sandboxing</h3>

<p>There&#8217;s one more directive worth talking about: <strong><code>sandbox</code></strong>. It&#8217;s a bit different than the others we&#8217;ve looked at, as is places restrictions on actions the page can take, rather than on resources that the page can load. If the <code>sandbox</code> directive is present, the page will be treated as though it was loaded inside of an <code>iframe</code> with a <code>sandbox</code> attribute. This can have a wide range of effects on the page: forcing the page into a unique origin, and preventing form submission, among others. It&#8217;s a bit beyond the scope of this article, but you can find full details on valid sandboxing attributes in the <a href="http://www.whatwg.org/specs/web-apps/current-work/multipage/origin-0.html#sandboxing-flag-set">&#8220;sandboxing flag set&#8221; section of the HTML5 spec</a>.</p>

<h3 id="the-meta-tag">The meta Tag</h3>

<p>CSPs preferred delivery mechanism is an HTTP header. It can be useful, however, to set a policy on a page directly in the markup. Do that using a meta tag with an http-equiv attribute:</p>

<pre class="prettyprint"><code>&lt;meta http-equiv="Content-Security-Policy" content="default-src https://cdn.example.net; child-src 'none'; object-src 'none'"&gt;
</code></pre>

<p>This can&#8217;t be used for frame-ancestors, report-uri, or sandbox.</p>

<h2 id="inline-code-considered-harmful">Inline Code Considered Harmful</h2>

<p>It should be clear that CSP is based on whitelisting origins, as that&#8217;s an unambiguous way of instructing the browser to treat specific sets of resources as acceptable and to reject the rest. Origin-based whitelisting doesn&#8217;t, however, solve the biggest threat posed by XSS attacks: inline script injection. If an attacker can inject a script tag that directly contains some malicious payload (<code>&lt;script&gt;sendMyDataToEvilDotCom();&lt;/script&gt;</code>), the browser has no mechanism by which to distinguish it from a legitimate inline script tag. CSP solves this problem by banning inline script entirely: <a href="https://www.youtube.com/watch?v=aCbfMkh940Q">it&#8217;s the only way to be sure</a>.</p>

<p>This ban includes not only scripts embedded directly in <code>script</code> tags, but also inline event handlers and <code>javascript:</code> URLs. You&#8217;ll need to move the content of <code>script</code> tags into an external file, and replace <code>javascript:</code> URLs and <code>&lt;a ... onclick="[JAVASCRIPT]"&gt;</code> with appropriate <code>addEventListener</code> calls. For example, you might rewrite the following from:</p>

<pre class="prettyprint"><code>&lt;script&gt;
  function doAmazingThings() {
    alert('YOU AM AMAZING!');
  }
&lt;/script&gt;
&lt;button onclick='doAmazingThings();'&gt;Am I amazing?&lt;/button&gt;
</code></pre>

<p>to something more like:</p>

<pre class="prettyprint"><code>&lt;!-- amazing.html --&gt;
&lt;script src='amazing.js'&gt;&lt;/script&gt;
&lt;button id='amazing'&gt;Am I amazing?&lt;/button&gt;
</code></pre>
<pre class="prettyprint"><code>// amazing.js
function doAmazingThings() {
  alert('YOU AM AMAZING!');
}
document.addEventListener('DOMContentReady', function () {
  document.getElementById('amazing')
          .addEventListener('click', doAmazingThings);
});
</code></pre>

<p>The rewritten code has a number of advantages above and beyond working well with CSP; it&#8217;s already best practice, regardless of your use of CSP. Inline JavaScript mixes structure and behavior in exactly the way you shouldn&#8217;t. External resources are easier for browsers to cache, more understandable for developers, and conducive to compilation and minification. You&#8217;ll write better code if you do the work to move code into external resources.</p>

<p>Inline style is treated in the same way: both the <code>style</code> attribute and <code>style</code> tags should be consolidated into external stylesheets to protect against a variety of <a href="http://scarybeastsecurity.blogspot.com/2009/12/generic-cross-browser-cross-domain.html">surprisingly clever</a> data exfiltration methods that CSS enables.</p>

<p>If you really, absolutely must have inline script and style, you can enable it by adding <code>'unsafe-inline'</code> as an allowed source in a <code>script-src</code> or <code>style-src</code> directive. You can also use a nonce or a has (see below). But please don&#8217;t. Banning inline script is the biggest security win CSP provides, and banning inline style likewise hardens your application. It&#8217;s a little bit of effort up front to ensure that things work correctly after moving all the code out-of-line, but that&#8217;s a tradeoff that&#8217;s well worth making.</p>

<h3 id="if-you-absolutely-must-use-it">If You Absolutely Must Use It&#8230;</h3>

<p>CSP Level 2 offers backward compatibility for inline scripts by allowing you to whitelist specific inline scripts using either a cryptographic nonce (number used once) or a hash. Although this may be cumbersome in practice, it is useful in a pinch.</p>

<p>To use a nonce, give your script tag a nonce attribute. Its value must match one in the list of trusted sources. For example:</p>

<pre class="prettyprint"><code>&lt;script nonce=EDNnf03nceIOfn39fn3e9h3sdfa&gt;
  //Some inline code I cant remove yet, but need to asap.
&lt;/script&gt;
</code></pre>

<p>Now, add the nonce to your script-src directive appended to the nonce- keyword.</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: script-src 'nonce-EDNnf03nceIOfn39fn3e9h3sdfa'
</code></pre>

<p>Remember that nonces must be regenerated for every page request and they must be unguessable.</p>

<p>Hashes work in much the same way. Instead of adding code to the script tag, create a SHA hash of the script itself and add it to the script-src directive. For example, let&#8217;s say your page contained this:</p>

<pre class="prettyprint"><code>&lt;script&gt;alert('Hello, world.');&lt;/script&gt;
</code></pre>

<p>Your policy would contain this:</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: script-src 'sha256-qznLcsROx4GACP2dm0UCKCzCG-HiZ1guq6ZZDob_Tng='
</code></pre>

<p>There are a few things to note here. The <code>sha*-</code> prefix specifies the algorithm used to generate the hash. In the example above, sha256- is used. CSP also supports sha384- and sha512-. When generating the hash do not include the <code>&lt;script&gt;</code> tags. Also capitalization and whitespace matter, including leading or trailing whitespace.</p>

<p>A Google search on generating SHA hashes will lead you to solutions in any number of languages. Using Chrome 40 or later you can open DevTools then reload your page. The Console tab will contain error messages with the correct sha256 hash for each of your inline scripts.</p>

<h2 id="eval-too">Eval Too</h2>

<p>Even when an attacker can&#8217;t inject script directly, she might be able to trick your application into converting otherwise inert text into executable JavaScript and executing it on her behalf. <code>eval()</code>, <code>new Function()</code>, <code>setTimeout([string], ...)</code>, <code>and setInterval([string], ...)</code> are all vectors through which injected text might end up executing something unexpectedly malicious. CSP&#8217;s default response to this risk is, unsurprisingly, to block all of these vectors completely.</p>

<p>This has more than a few impacts on the way you build applications:</p>

<ul>
  <li>Parse JSON via the built-in <code>JSON.parse</code>, rather than relying on <code>eval</code>. Native JSON operations are available in <a href="http://caniuse.com/#feat=json">every browser since IE8</a>, and they&#8217;re completely safe.</li>
  <li>
    <p>Rewrite any <code>setTimeout</code> or <code>setInterval</code> calls you&#8217;re currently making with inline functions rather than strings. For example:</p>

    <pre class="prettyprint"><code>setTimeout("document.querySelector('a').style.display = 'none';", 10);
</code></pre>

    <p>would be better written as:</p>

    <pre class="prettyprint"><code>setTimeout(function () {
  document.querySelector('a').style.display = 'none';
}, 10);
</code></pre>
  </li>
  <li>Avoid inline templating at runtime: Many templating libraries use <code>new Function()</code> liberally to speed up template generation at runtime. It&#8217;s a nifty application of dynamic programming, but comes at the risk of evaluating malicious text. Some frameworks support CSP out of the box, falling back to a robust parser in the absence of <code>eval</code>; <a href="http://docs.angularjs.org/api/angular.module.ng.$compileProvider.directive.ngCsp">AngularJS&#8217;s ng-csp directive</a> is a good example of this.</li>
</ul>

<p>You&#8217;re even better off, however, if your templating language of choice offers precompilation (<a href="http://handlebarsjs.com/precompilation.html">Handlebars does</a>, for instance). Precompiling your templates can make the user experience even faster than the fastest runtime implementation, and it&#8217;s safer too. Win, win!
If eval and its text-to-JavaScript brethren are completely essential to your application, you can enable them by adding <code>'unsafe-eval'</code> as an allowed source in a <code>script-src</code> directive. But, again, please don&#8217;t. Banning the ability to execute strings makes it much more difficult for an attacker to execute unauthorized code on your site.</p>

<h2 id="reporting">Reporting</h2>

<p>CSP&#8217;s ability to block untrusted resources client-side is a huge win for your users, but it would be quite helpful indeed to get some sort of notification sent back to the server so that you can identify and squash any bugs that allow malicious injection in the first place. To this end, you can instruct the browser to <code>POST</code> JSON-formatted violation reports to a location specified in a <strong><code>report-uri</code></strong> directive.</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: default-src 'self'; ...; report-uri /my_amazing_csp_report_parser;
</code></pre>

<p>Those reports will look something like the following:</p>

<pre class="prettyprint"><code>{
  "csp-report": {
    "document-uri": "http://example.org/page.html",
    "referrer": "http://evil.example.com/",
    "blocked-uri": "http://evil.example.com/evil.js",
    "violated-directive": "script-src 'self' https://apis.google.com",
    "original-policy": "script-src 'self' https://apis.google.com; report-uri http://example.org/my_amazing_csp_report_parser"
  }
}
</code></pre>

<p>It contains a good chunk of information that will help you track down the specific cause of the violation, including the page on which the violation occurred (<strong><code>document-uri</code></strong>), that page&#8217;s referrer (referrer, note that the key is <em>not</em> misspelled), the resource that violated the page&#8217;s policy (<strong><code>blocked-uri</code></strong>), the specific directive it violated (<strong><code>violated-directive</code></strong>), and the page&#8217;s complete policy (<strong><code>original-policy</code></strong>).</p>

<h3 id="report-only">Report-Only</h3>

<p>If you&#8217;re just starting out with CSP, it makes sense to evaluate the current state of your application before rolling out a draconian policy to your users. As a stepping stone to a complete deployment, you can ask the browser to monitor a policy, reporting violations, but not enforcing the restrictions. Instead of sending a <code>Content-Security-Policy</code> header, send a <code>Content-Security-Policy-Report-Only</code> header.</p>

<pre class="prettyprint"><code>Content-Security-Policy-Report-Only: default-src 'self'; ...; report-uri /my_amazing_csp_report_parser;
</code></pre>

<p>The policy specified in report-only mode won&#8217;t block restricted resources, but it will send violation reports to the location you specify. You can even send <em>both</em> headers, enforcing one policy while monitoring another. This is a great way to evaluate the effect of changes to your application&#8217;s CSP: turn on reporting for a new policy, monitor the violation reports and fix any bugs that turn up, then start enforcing the new policy once you&#8217;re satisfied with its effect.</p>

<h2 id="real-world-usage">Real World Usage</h2>

<p>CSP 1 is quite usable in Chrome, Safari, and Firefox, and has (very) limited support in IE 10. You can <a href="http://caniuse.com/#feat=contentsecuritypolicy">view specifics at caniuse.com</a>. CSP Level 2 was available in Chrome with version 40. Massive sites like Twitter and Facebook have deployed the header (<a href="https://blog.twitter.com/2011/improving-browser-security-csp">Twitter&#8217;s case study</a> is worth a read), and the standard is very much ready for you to start deploying on your own sites.</p>

<p>The first step towards crafting a policy for your application is to evaluate the resources you&#8217;re actually loading. Once you think you have a handle on how things are put together in your app, set up a policy based on those requirements. Let&#8217;s walk through a few common use-cases, and determine how we&#8217;d best be able to support them within the protective confines of CSP:</p>

<h3 id="use-case-1-social-media-widgets">Use Case #1: Social media widgets</h3>

<ul>
  <li>
    <p>Google&#8217;s <a href="http://www.google.com/intl/en/webmasters/+1/button/index.html">+1 button</a> includes script from <code>https://apis.google.com</code>, and embeds an <code>iframe</code> from <code>https://plusone.google.com</code>. You&#8217;ll need a policy that includes both these origins in order to embed the button. A minimal policy would be <code>script-src https://apis.google.com; child-src https://plusone.google.com</code>. You&#8217;ll also need to ensure that the snippet of JavaScript that Google provides is pulled out into an external JavaScript file. If you had an existing policy using child-src, you would need to change it to child-src.</p>
  </li>
  <li>
    <p>Facebook&#8217;s <a href="http://developers.facebook.com/docs/reference/plugins/like/">Like button</a> has a number of implementation options. I&#8217;d recommend sticking with the <code>iframe</code> version, as it&#8217;s safely sandboxed from the rest of your site. That would require a <code>child-src https://facebook.com</code> directive to function properly. Note that, by default, the <code>iframe</code> code Facebook provides loads a relative URL, <code>//facebook.com</code>. Please change that to explicitly specify HTTPS: <code>https://facebook.com</code>. There&#8217;s no reason to use HTTP if you don&#8217;t have to.</p>
  </li>
  <li>
    <p>Twitter&#8217;s <a href="https://twitter.com/about/resources/buttons">Tweet button</a> relies on access to a script and frame, both hosted at <code>https://platform.twitter.com</code> (Twitter likewise provides a relative URL by default: please edit the code to specify HTTPS when copy/pasting it locally). You&#8217;ll be all set with <code>script-src https://platform.twitter.com; child-src https://platform.twitter.com</code>, as long as you move the JavaScript snippet Twitter provides out into an external JavaScript file.</p>
  </li>
  <li>
    <p>Other platforms will have similar requirements, and can be addressed similarly. I&#8217;d suggest just setting a <code>default-src</code> of <code>'none'</code>, and watching your console to determine which resources you&#8217;ll need to enable to make the widgets work.</p>
  </li>
</ul>

<p>Including multiple widgets is straightforward: simply combine the policy directives, remembering to merge all resources of a single type into a single directive. If you wanted all three, the policy would look like:</p>

<pre class="prettyprint"><code>script-src https://apis.google.com https://platform.twitter.com; child-src https://plusone.google.com https://facebook.com https://platform.twitter.com
</code></pre>

<h3 id="use-case-2-lockdown">Use Case #2: Lockdown</h3>

<p>Assume for a moment that you run a banking site, and want to make very sure that only those resources you&#8217;ve written yourself can be loaded. In this scenario, start with a default policy that blocks absolutely everything (<code>default-src 'none'</code>), and build up from there.</p>

<p>Let&#8217;s say the bank loads all images, style, and script from a CDN at <code>https://cdn.mybank.net</code>, and connects via XHR to <code>https://api.mybank.com/</code> to pull various bits of data down. Frames are used, but only for pages local to the site (no third-party origins). There&#8217;s no Flash on the site, no fonts, no nothing. The most restrictive CSP header that we could send in this scenario is:</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: default-src 'none'; script-src https://cdn.mybank.net; style-src https://cdn.mybank.net; img-src https://cdn.mybank.net; connect-src https://api.mybank.com; child-src 'self'
</code></pre>

<h3 id="use-case-3-ssl-only">Use Case #3: SSL Only</h3>

<p>A wedding-ring discussion forum admin wants to ensure that all resources are only loaded via secure channels, but doesn&#8217;t really write much code; rewriting large chunks of the third-party forum software that&#8217;s filled to the brim with inline script and style is beyond his abilities. The following policy would be effective:</p>

<pre class="prettyprint lang-csp"><code>Content-Security-Policy: default-src https:; script-src https: 'unsafe-inline'; style-src https: 'unsafe-inline'
</code></pre>

<p>Even though <code>https:</code> was specified in <code>default-src</code>, the script and style directives don&#8217;t automatically inherit that source. Each directive overwrites the default completely for that specific type of resource.</p>

<h2 id="the-future">The Future</h2>

<p>Content Security Policy Level 2 is a <a href="http://www.w3.org/TR/CSP2/">Candidate Recommendation</a>. The W3Cs Web Application Security Working Group isnt lounging around, patting itself on the back; work has already begun on the specifications next iteration. The next version is already under active development.</p>

<p>If you&#8217;re interested in the discussion around these upcoming features, <a href="http://lists.w3.org/Archives/Public/public-webappsec/">skim the public-webappsec@ mailing list archives</a>, or join in yourself.</p>

{% endblock %}
